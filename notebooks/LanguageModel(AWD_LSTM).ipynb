{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ft-Azad/Language-Modeling/blob/main/LanguageModel(AWD_LSTM).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiRseqOJtOMs"
      },
      "source": [
        "#  Import Libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1l3jplbsRcr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8a27300-5c07-4ee8-bdbb-7e8d597ce837"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.3.0+cu121 requires torch==2.3.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.15.1 requires torch==2.0.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.15.1 requires torchdata==0.6.0, but you have torchdata 0.6.1 which is incompatible.\n",
            "torchvision 0.18.0+cu121 requires torch==2.3.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.3.0+cu121 requires torch==2.3.0, but you have torch 2.0.0 which is incompatible.\n",
            "torchvision 0.18.0+cu121 requires torch==2.3.0, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q torchmetrics\n",
        "!pip install -q torchdata==0.6.1\n",
        "!pip install -q 'portalocker>=2.0.0'\n",
        "!pip install -q torchtext==0.15.1\n",
        "!pip install -q comet_ml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXPfyHdktUV2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torchtext\n",
        "from torchtext.datasets import WikiText2\n",
        "from torchdata.datapipes.iter import IterableWrapper, Mapper\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "\n",
        "from torch import optim\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import os\n",
        "import tqdm\n",
        "import torchmetrics as tm\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "from comet_ml import Experiment\n",
        "from comet_ml.integration.pytorch import log_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xed-F0ttyk6",
        "outputId": "614c3665-b5f3-48b2-bae4-322e740afcfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy --> 1.25.2\n",
            "torch --> 2.0.0+cu117\n",
            "torchtext --> 0.15.1+cpu\n",
            "tqdm --> 4.66.4\n"
          ]
        }
      ],
      "source": [
        "for lib in [np, torch, torchtext, tqdm]:\n",
        "  print(lib.__name__, '-->', lib.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtOFbjYdtuXS"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y36SBwzHttlz"
      },
      "outputs": [],
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvkD1SZDt1QU"
      },
      "outputs": [],
      "source": [
        "def num_trainable_params(model):\n",
        "  nums = sum(p.numel() for p in model.parameters() if p.requires_grad)/1e6\n",
        "  return nums"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZwiS0r7t2qm"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  if torch.cuda.is_available():\n",
        "      torch.cuda.manual_seed(seed)\n",
        "      # torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "      # torch.backends.cudnn.deterministic = True\n",
        "      # torch.backends.cudnn.benchmark = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kou_xgQtuSKD"
      },
      "source": [
        "# Arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSqJ0n_guXCL"
      },
      "outputs": [],
      "source": [
        "seed = 8\n",
        "\n",
        "batch_size = 80\n",
        "seq_len = 70\n",
        "\n",
        "embedding_dim = 400\n",
        "\n",
        "num_layers = 3\n",
        "hidden_dim = 1150\n",
        "# dropout_embd = 0.5\n",
        "# dropout_rnn = 0\n",
        "dropoute = 0.1\n",
        "dropouti = 0.65\n",
        "dropouth = 0.3\n",
        "dropouto = 0.4\n",
        "Weight_Drop = 0.5\n",
        "\n",
        "\n",
        "lr = 3\n",
        "wd = 1e-6\n",
        "momentum = 0.9\n",
        "\n",
        "clip = 0.25\n",
        "\n",
        "wandb_enable = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiM52d_Yt5vU"
      },
      "source": [
        "#Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMElZJWSt72c"
      },
      "source": [
        "## Load Dataset and Build Vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ma9kBZCJt9_M"
      },
      "source": [
        "- Loading Iterable Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlZif_l-t45M",
        "outputId": "af6780c2-3dd0-44a5-8e64-57d89bcb2b20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NS6x1w4VuCkU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13abd491-3c17-431c-a012-3f4b811543d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace /content/wikitext-2/wiki.test.tokens? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ],
      "source": [
        "!unzip -q \"/content/drive/MyDrive/LanguageModel/Data/wikitext-2-v1.zip\" -d '/content/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9jSpftfuD9K"
      },
      "outputs": [],
      "source": [
        "with open('/content/wikitext-2/wiki.train.tokens', 'r') as file:\n",
        "    train_iter = file.read().splitlines()\n",
        "\n",
        "with open('/content/wikitext-2/wiki.test.tokens', 'r') as file:\n",
        "    test_iter = file.read().splitlines()\n",
        "\n",
        "with open('/content/wikitext-2/wiki.valid.tokens', 'r') as file:\n",
        "    valid_iter = file.read().splitlines()\n",
        "\n",
        "train_iter = IterableWrapper(train_iter)\n",
        "test_iter = IterableWrapper(test_iter)\n",
        "valid_iter = IterableWrapper(valid_iter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNlDyqOwvItm"
      },
      "source": [
        "- Build Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4QNGKw4vQ2r"
      },
      "outputs": [],
      "source": [
        "tokenizer = get_tokenizer('basic_english')\n",
        "vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=['<unk>'])\n",
        "vocab.set_default_index(vocab['<unk>'])\n",
        "torch.save(vocab, 'vocab.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVsC0d1Qvt6E"
      },
      "source": [
        "## Dataset Prepreation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gEXdvicwTRj"
      },
      "source": [
        "- Creat Target Array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_FC_QFzvtcL"
      },
      "outputs": [],
      "source": [
        "def data_process(raw_text_iter, seq_len):\n",
        "  data = torch.cat([torch.LongTensor(vocab(tokenizer(line))) for line in raw_text_iter])\n",
        "\n",
        "  M = len(data) // seq_len\n",
        "\n",
        "  r = len(data) % seq_len\n",
        "  data = torch.cat((data, torch.LongTensor([0]))) if r==0 else data\n",
        "\n",
        "  inputs = data[:M*seq_len]\n",
        "  targets = data[1:M*seq_len+1]\n",
        "\n",
        "  inputs = inputs.reshape(-1, seq_len)\n",
        "  targets = targets.reshape(-1, seq_len)\n",
        "\n",
        "  return inputs, targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYP0TPqcvz_L",
        "outputId": "6fa9e45d-ff4f-419c-df5d-1878c0403f81"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([29285, 70]),\n",
              " torch.Size([29285, 70]),\n",
              " torch.Size([3063, 70]),\n",
              " torch.Size([3063, 70]),\n",
              " torch.Size([3455, 70]),\n",
              " torch.Size([3455, 70]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "X_train, y_train = data_process(train_iter, seq_len)\n",
        "X_valid, y_valid = data_process(valid_iter, seq_len)\n",
        "X_test, y_test = data_process(test_iter, seq_len)\n",
        "\n",
        "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape, X_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJbQ1Nh0wXyy"
      },
      "source": [
        "- Custom Dataset Class Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkQQ934CxF21"
      },
      "outputs": [],
      "source": [
        "class LanguageModelDataset(Dataset):\n",
        "\n",
        "  def __init__(self, inputs, targets):\n",
        "    self.inputs = inputs\n",
        "    self.targets = targets\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.inputs.shape[0]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.inputs[idx], self.targets[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56QXULMExJJ9"
      },
      "outputs": [],
      "source": [
        "train_set = LanguageModelDataset(X_train, y_train)\n",
        "valid_set = LanguageModelDataset(X_valid, y_valid)\n",
        "test_set = LanguageModelDataset(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_QgbAMixKn7",
        "outputId": "df31c0a9-d898-4ef1-82f8-7c236dad0223"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([    9,  3849,  3869,   881,     9, 20000,    83,  3849,    88,     0,\n",
              "          3869,    21,   780, 28780,     2,  6182,     3,  3849,     4,     1,\n",
              "          5023,    88,    20,     2,  1837,  1018,     7,    14,  3849,  3869,\n",
              "           881,   629,   976,     2,    23,     8,  5790,   299,    12,   575,\n",
              "           232,    67,   452,    19, 13722,     5,   757,     3,  2500,    17,\n",
              "             1,  1767,  5637,     3,   155,     6,   246,   354,     6,   976,\n",
              "             2,    24,    23,     1,   237,    67,     6,     1,  3849,    93]),\n",
              " tensor([ 3849,  3869,   881,     9, 20000,    83,  3849,    88,     0,  3869,\n",
              "            21,   780, 28780,     2,  6182,     3,  3849,     4,     1,  5023,\n",
              "            88,    20,     2,  1837,  1018,     7,    14,  3849,  3869,   881,\n",
              "           629,   976,     2,    23,     8,  5790,   299,    12,   575,   232,\n",
              "            67,   452,    19, 13722,     5,   757,     3,  2500,    17,     1,\n",
              "          1767,  5637,     3,   155,     6,   246,   354,     6,   976,     2,\n",
              "            24,    23,     1,   237,    67,     6,     1,  3849,    93,     3]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "train_set[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZkza2MYxOnk"
      },
      "source": [
        "- Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gz_hP05xRt8"
      },
      "outputs": [],
      "source": [
        "set_seed(seed)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQ1eIKZLxUOz",
        "outputId": "d2bed3ab-1f99-4803-a759-df5fc450ebcd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([80, 70]), torch.Size([80, 70]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "x_batch, y_batch = next(iter(train_loader))\n",
        "x_batch.shape, y_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwbPWDxTxvrO",
        "outputId": "59cf1f0f-79d3-445b-edb2-b317aade2c0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1985) tensor(13)\n"
          ]
        }
      ],
      "source": [
        "set_seed(seed)\n",
        "\n",
        "for inputs, targets in train_loader:\n",
        "  print(inputs[0, 0], targets[0, 0])\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMYLSVQWx2W8"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class WeightDrop(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, module, weights, dropout=0):\n",
        "    super(WeightDrop, self).__init__()\n",
        "    self.module = module\n",
        "    self.weights = weights\n",
        "    self.dropout = dropout\n",
        "    self._setup()\n",
        "\n",
        "  def widget_demagnetizer_y2k_edition(*args, **kwargs):\n",
        "    return\n",
        "\n",
        "  def _setup(self):\n",
        "    if issubclass(type(self.module), torch.nn.RNNBase):\n",
        "      self.module.flatten_parameters = self.widget_demagnetizer_y2k_edition\n",
        "\n",
        "      for name_w in self.weights:\n",
        "        print('Applying weight drop of {} to {}'.format(self.dropout, name_w))\n",
        "        w = getattr(self.module, name_w)\n",
        "        del self.module._parameters[name_w]\n",
        "        self.module.register_parameter(name_w + '_raw', nn.Parameter(w.data))\n",
        "\n",
        "  def _setweights(self):\n",
        "    for name_w in self.weights:\n",
        "      raw_w = getattr(self.module, name_w + '_raw')\n",
        "      w = None\n",
        "      # w = torch.nn.functional.dropout(raw_w, p=self.dropout, training=self.training)\n",
        "      mask = torch.nn.functional.dropout(torch.ones_like(raw_w), p=self.dropout, training=True) * (1 - self.dropout)\n",
        "      setattr(self.module, name_w, raw_w * mask)\n",
        "\n",
        "\n",
        "  def forward(self, *args):\n",
        "    self._setweights()\n",
        "    return self.module.forward(*args)"
      ],
      "metadata": {
        "id": "Xd8qwS0FZPku",
        "outputId": "7eed4928-ff14-4da4-c348-1bb90b7136ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a33e44ef352d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mWeightDrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWeightDrop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def embedded_dropout(embed, words, dropout=0.1, scale=None):\n",
        "  if dropout:\n",
        "    mask = embed.weight.data.new().resize_((embed.weight.size(0), 1)).bernoulli_(1 - dropout).expand_as(\n",
        "        embed.weight) / (1 - dropout)\n",
        "    masked_embed_weight = mask * embed.weight\n",
        "  else:\n",
        "    masked_embed_weight = embed.weight\n",
        "  if scale:\n",
        "    masked_embed_weight = scale.expand_as(masked_embed_weight) * masked_embed_weight\n",
        "\n",
        "  padding_idx = embed.padding_idx\n",
        "  if padding_idx is None:\n",
        "    padding_idx = -1\n",
        "\n",
        "  embedding = torch.nn.functional.embedding(words, masked_embed_weight,\n",
        "                                            padding_idx, embed.max_norm, embed.norm_type,\n",
        "                                            embed.scale_grad_by_freq, embed.sparse)\n",
        "  return embedding"
      ],
      "metadata": {
        "id": "Strd7xNYHh5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LockedDropout(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LockedDropout, self).__init__()\n",
        "\n",
        "  def forward(self, x, dropout):\n",
        "    if not self.training or not dropout:\n",
        "      return x\n",
        "    m = x.data.new(1, x.size(1), x.size(2)).bernoulli_(1 - dropout)\n",
        "    mask = m.requires_grad_(False) / (1 - dropout)\n",
        "    mask = mask.expand_as(x)\n",
        "    return mask * x"
      ],
      "metadata": {
        "id": "vqMQxMONHiz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdlAzoEcx2FM"
      },
      "outputs": [],
      "source": [
        "class LanguageModel(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers,\n",
        "                dropoute=0.2, dropouti=0.2, dropouth=0.2, dropouto=0.2, weight_drop=0.5):\n",
        "    super().__init__()\n",
        "    self.num_layers = num_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.embedding_dim = embedding_dim\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.embedding.weight.data.uniform_(-0.1, 0.1)\n",
        "    # self.dropout = nn.Dropout(p=dropout_embd)\n",
        "\n",
        "    self.lstms = []\n",
        "    self.lstms.append(nn.LSTM(embedding_dim, hidden_dim, num_layers=1, dropout=0, batch_first=False))\n",
        "    self.lstms.append(nn.LSTM(hidden_dim, hidden_dim, num_layers=1, dropout=0, batch_first=False))\n",
        "    self.lstms.append(nn.LSTM(hidden_dim, embedding_dim, num_layers=1, dropout=0, batch_first=False))\n",
        "    if weight_drop > 0:\n",
        "      self.lstms = [WeightDrop(lstm, ['weight_hh_l0'], dropout=weight_drop) for lstm in self.lstms]\n",
        "    self.lstms = nn.ModuleList(self.lstms)\n",
        "\n",
        "    self.fc = nn.Linear(embedding_dim, vocab_size)\n",
        "\n",
        "    self.fc.weight = self.embedding.weight\n",
        "\n",
        "    self.lockdrop = LockedDropout()\n",
        "    self.dropoute = dropoute\n",
        "    self.dropouti = dropouti\n",
        "    self.dropouth = dropouth\n",
        "    self.dropouto = dropouto\n",
        "\n",
        "  def forward(self, src):\n",
        "    # embedding = self.dropout(self.embedding(src))\n",
        "    embedding = embedded_dropout(self.embedding, src, dropout=self.dropoute if self.training else 0)\n",
        "    embedding = self.lockdrop(embedding, self.dropouti)\n",
        "\n",
        "    # new_hiddens = []\n",
        "    for l, lstm in enumerate(self.lstms):\n",
        "      embedding, _ = lstm(embedding)\n",
        "      if l != self.num_layers-1:\n",
        "        embedding = self.lockdrop(embedding, self.dropouth)\n",
        "\n",
        "    embedding = self.lockdrop(embedding, self.dropouto)\n",
        "\n",
        "    prediction = self.fc(embedding)\n",
        "    return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJotksm3x-cU",
        "outputId": "3876c66e-a150-44a3-9749-f86113ffe4a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying weight drop of 0.5 to weight_hh_l0\n",
            "Applying weight drop of 0.5 to weight_hh_l0\n",
            "Applying weight drop of 0.5 to weight_hh_l0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageModel(\n",
              "  (embedding): Embedding(28782, 400)\n",
              "  (lstms): ModuleList(\n",
              "    (0): WeightDrop(\n",
              "      (module): LSTM(400, 1150)\n",
              "    )\n",
              "    (1): WeightDrop(\n",
              "      (module): LSTM(1150, 1150)\n",
              "    )\n",
              "    (2): WeightDrop(\n",
              "      (module): LSTM(1150, 400)\n",
              "    )\n",
              "  )\n",
              "  (fc): Linear(in_features=400, out_features=28782, bias=True)\n",
              "  (lockdrop): LockedDropout()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "set_seed(seed)\n",
        "\n",
        "model = LanguageModel(vocab_size=len(vocab),\n",
        "                      embedding_dim=embedding_dim,\n",
        "                      hidden_dim=hidden_dim,\n",
        "                      num_layers=num_layers,\n",
        "                      dropoute=dropoute, dropouti=dropouti,\n",
        "                      dropouth=dropouth, dropouto=dropouto)\n",
        "model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNdI-5pVyOKk"
      },
      "source": [
        "# Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "PGCd-Dm-yNhM",
        "outputId": "b1a326ea-1caf-4426-e1d3-1edf5a6d46bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hd19NFFNyUFk"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "metric = tm.text.Perplexity().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6Oy3pH0RgAt"
      },
      "outputs": [],
      "source": [
        "key_file = \"/content/drive/MyDrive/LanguageModel/key.txt\"\n",
        "\n",
        "if os.path.exists(key_file):\n",
        "    with open(key_file) as f:\n",
        "        key = f.readline().strip()\n",
        "else:\n",
        "    print(\"Key file does not exist. Please create the key file with your wandb API key.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfY7_5XZc4qk",
        "outputId": "308a5245-7169-4251-89c8-965a5729c689"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please input the WandB argument (run) name:Weight-Drop2\n"
          ]
        }
      ],
      "source": [
        "wandb_arg_name = input('Please input the WandB argument (run) name:')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_APSWaGyc5Iw"
      },
      "outputs": [],
      "source": [
        "# comet_ml.init(project_name=\"LM_AWD-LSTM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAsopugofMzN",
        "outputId": "d028377c-e2b2-4c20-c2c6-aeab82e091af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/ft-azad/lm-awd-lstm/287d779ad93b49a1b6e1375279bc4ce5\n",
            "\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n"
          ]
        }
      ],
      "source": [
        "experiment = Experiment(\n",
        "  api_key=key,\n",
        "  project_name=\"LM_AWD-LSTM\",\n",
        ")\n",
        "experiment.set_name(wandb_arg_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_1sWWHVy7Kk"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxTkh6JGy9Kj"
      },
      "source": [
        "## Train and Evaluate Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1dAZfqLy850"
      },
      "outputs": [],
      "source": [
        "# Train Functions\n",
        "def train_one_epoch(model, train_loader, loss_fn, optimizer, metric, epoch=None):\n",
        "  model.train()\n",
        "  loss_train = AverageMeter()\n",
        "  metric.reset()\n",
        "\n",
        "  with tqdm.tqdm(train_loader, unit='batch') as tepoch:\n",
        "    for inputs, targets in tepoch:\n",
        "      if epoch:\n",
        "        tepoch.set_description(f'Epoch {epoch}')\n",
        "\n",
        "      inputs = inputs.t().to(device)\n",
        "      targets = targets.t().to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      loss = loss_fn(outputs.reshape(-1, outputs.shape[-1]), targets.flatten())\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      nn.utils.clip_grad.clip_grad_norm_(model.parameters(), max_norm=clip)\n",
        "\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      loss_train.update(loss.item(), n=len(targets))\n",
        "      metric.update(outputs, targets)\n",
        "\n",
        "      tepoch.set_postfix(loss=loss_train.avg, metric=metric.compute().item())\n",
        "\n",
        "  return model, loss_train.avg, metric.compute().item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ma-DFi9XzE1s"
      },
      "outputs": [],
      "source": [
        "# Evaluate Function\n",
        "def evaluate(model, test_loader, loss_fn, metric):\n",
        "  model.eval()\n",
        "  loss_eval = AverageMeter()\n",
        "  metric.reset()\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for inputs, targets in test_loader:\n",
        "      inputs = inputs.t().to(device)\n",
        "      targets = targets.t().to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      loss = loss_fn(outputs.reshape(-1, outputs.shape[-1]), targets.flatten())\n",
        "      loss_eval.update(loss.item(), n=len(targets))\n",
        "\n",
        "      metric(outputs, targets)\n",
        "\n",
        "  return loss_eval.avg, metric.compute().item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKkW_4FBz1ac"
      },
      "source": [
        "## Train Process and Tunning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FYTauriz3RL"
      },
      "source": [
        "### Finding Hyper-parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaPsJriFz4i7"
      },
      "source": [
        "- Calculating the loss for untrained model using a few batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIebaKmbz5xj",
        "outputId": "4ab612a6-f559-475f-e2b0-c1a9ea7320e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(10.2711, device='cuda:0')\n",
            "tensor(10.2717, device='cuda:0')\n",
            "tensor(10.2653, device='cuda:0')\n",
            "tensor(10.2671, device='cuda:0')\n",
            "tensor(10.2690, device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "for iter_num in range(5):\n",
        "  model = LanguageModel(len(vocab), embedding_dim=embedding_dim,\n",
        "                      hidden_dim=hidden_dim, num_layers=num_layers,\n",
        "                      dropoute=dropoute, dropouti=dropouti,\n",
        "                      dropouth=dropouth, dropouto=dropouto).to(device)\n",
        "\n",
        "  inputs, targets = next(iter(train_loader))\n",
        "  inputs = inputs.to(device)\n",
        "  targets = targets.to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    outputs = model(inputs)\n",
        "    loss = loss_fn(outputs.reshape(-1, outputs.shape[-1]), targets.flatten())\n",
        "\n",
        "  print(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14lWNR0Jz8VQ"
      },
      "source": [
        "- Train and try to overfit the model on a small subset of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pg26Lvdb0G8I"
      },
      "outputs": [],
      "source": [
        "model = LanguageModel(len(vocab), embedding_dim=embedding_dim,\n",
        "                      hidden_dim=hidden_dim, num_layers=num_layers,\n",
        "                      dropoute=dropoute, dropouti=dropouti,\n",
        "                      dropouth=dropouth, dropouto=dropouto).to(device)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.9, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2XIZjef0IG5"
      },
      "outputs": [],
      "source": [
        "mini_train_size = 1000\n",
        "_, mini_train_dataset = random_split(train_set, (len(train_set)-mini_train_size, mini_train_size))\n",
        "mini_train_loader = DataLoader(mini_train_dataset, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VEtGlnyl0JHy",
        "outputId": "3b64a994-8e4f-4ffa-e410-4dd711a0079c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:01<00:00, 26.48batch/s, loss=8.33, metric=4.15e+3]\n",
            "Epoch 1: 100%|██████████| 50/50 [00:01<00:00, 25.97batch/s, loss=7.18, metric=1.31e+3]\n",
            "Epoch 2: 100%|██████████| 50/50 [00:01<00:00, 25.92batch/s, loss=7, metric=1.1e+3]\n",
            "Epoch 3: 100%|██████████| 50/50 [00:01<00:00, 25.80batch/s, loss=6.93, metric=1.02e+3]\n",
            "Epoch 4: 100%|██████████| 50/50 [00:01<00:00, 25.78batch/s, loss=6.84, metric=937]\n",
            "Epoch 5: 100%|██████████| 50/50 [00:01<00:00, 25.14batch/s, loss=6.72, metric=832]\n",
            "Epoch 6: 100%|██████████| 50/50 [00:02<00:00, 24.81batch/s, loss=6.61, metric=740]\n",
            "Epoch 7: 100%|██████████| 50/50 [00:01<00:00, 25.30batch/s, loss=6.51, metric=672]\n",
            "Epoch 8: 100%|██████████| 50/50 [00:01<00:00, 25.30batch/s, loss=6.43, metric=619]\n",
            "Epoch 9: 100%|██████████| 50/50 [00:01<00:00, 25.16batch/s, loss=6.35, metric=572]\n",
            "Epoch 10: 100%|██████████| 50/50 [00:01<00:00, 25.14batch/s, loss=6.27, metric=529]\n",
            "Epoch 11: 100%|██████████| 50/50 [00:01<00:00, 25.29batch/s, loss=6.2, metric=493]\n",
            "Epoch 12: 100%|██████████| 50/50 [00:02<00:00, 24.81batch/s, loss=6.12, metric=456]\n",
            "Epoch 13: 100%|██████████| 50/50 [00:02<00:00, 24.73batch/s, loss=6.05, metric=426]\n",
            "Epoch 14: 100%|██████████| 50/50 [00:02<00:00, 24.76batch/s, loss=5.98, metric=396]\n",
            "Epoch 15: 100%|██████████| 50/50 [00:02<00:00, 24.74batch/s, loss=5.91, metric=367]\n",
            "Epoch 16: 100%|██████████| 50/50 [00:02<00:00, 24.94batch/s, loss=5.83, metric=339]\n",
            "Epoch 17: 100%|██████████| 50/50 [00:01<00:00, 25.20batch/s, loss=5.74, metric=312]\n",
            "Epoch 18: 100%|██████████| 50/50 [00:01<00:00, 25.08batch/s, loss=5.65, metric=283]\n",
            "Epoch 19: 100%|██████████| 50/50 [00:02<00:00, 24.73batch/s, loss=5.55, metric=257]\n",
            "Epoch 20: 100%|██████████| 50/50 [00:02<00:00, 24.73batch/s, loss=5.45, metric=234]\n",
            "Epoch 21: 100%|██████████| 50/50 [00:02<00:00, 24.90batch/s, loss=5.36, metric=213]\n",
            "Epoch 22: 100%|██████████| 50/50 [00:01<00:00, 25.25batch/s, loss=5.27, metric=194]\n",
            "Epoch 23: 100%|██████████| 50/50 [00:01<00:00, 25.29batch/s, loss=5.18, metric=178]\n",
            "Epoch 24: 100%|██████████| 50/50 [00:01<00:00, 25.29batch/s, loss=5.09, metric=162]\n",
            "Epoch 25: 100%|██████████| 50/50 [00:01<00:00, 25.38batch/s, loss=4.99, metric=146]\n",
            "Epoch 26: 100%|██████████| 50/50 [00:01<00:00, 25.51batch/s, loss=4.88, metric=132]\n",
            "Epoch 27: 100%|██████████| 50/50 [00:02<00:00, 24.77batch/s, loss=4.79, metric=121]\n",
            "Epoch 28: 100%|██████████| 50/50 [00:02<00:00, 24.55batch/s, loss=4.69, metric=109]\n",
            "Epoch 29: 100%|██████████| 50/50 [00:01<00:00, 25.48batch/s, loss=4.57, metric=97]\n",
            "Epoch 30: 100%|██████████| 50/50 [00:01<00:00, 25.48batch/s, loss=4.45, metric=86]\n",
            "Epoch 31: 100%|██████████| 50/50 [00:01<00:00, 25.58batch/s, loss=4.34, metric=76.5]\n",
            "Epoch 32: 100%|██████████| 50/50 [00:01<00:00, 25.46batch/s, loss=4.23, metric=68.8]\n",
            "Epoch 33: 100%|██████████| 50/50 [00:01<00:00, 25.51batch/s, loss=4.13, metric=62]\n",
            "Epoch 34: 100%|██████████| 50/50 [00:02<00:00, 24.97batch/s, loss=4.02, metric=55.6]\n",
            "Epoch 35: 100%|██████████| 50/50 [00:01<00:00, 25.13batch/s, loss=3.93, metric=51.1]\n",
            "Epoch 36: 100%|██████████| 50/50 [00:01<00:00, 25.71batch/s, loss=3.85, metric=47]\n",
            "Epoch 37: 100%|██████████| 50/50 [00:01<00:00, 25.54batch/s, loss=3.75, metric=42.7]\n",
            "Epoch 38: 100%|██████████| 50/50 [00:01<00:00, 25.13batch/s, loss=3.67, metric=39.2]\n",
            "Epoch 39: 100%|██████████| 50/50 [00:01<00:00, 25.34batch/s, loss=3.61, metric=37]\n",
            "Epoch 40: 100%|██████████| 50/50 [00:01<00:00, 25.20batch/s, loss=3.55, metric=34.8]\n",
            "Epoch 41: 100%|██████████| 50/50 [00:01<00:00, 25.27batch/s, loss=3.45, metric=31.5]\n",
            "Epoch 42: 100%|██████████| 50/50 [00:02<00:00, 24.61batch/s, loss=3.36, metric=28.7]\n",
            "Epoch 43: 100%|██████████| 50/50 [00:02<00:00, 24.40batch/s, loss=3.25, metric=25.7]\n",
            "Epoch 44: 100%|██████████| 50/50 [00:02<00:00, 24.98batch/s, loss=3.12, metric=22.7]\n",
            "Epoch 45: 100%|██████████| 50/50 [00:01<00:00, 25.05batch/s, loss=3.01, metric=20.2]\n",
            "Epoch 46: 100%|██████████| 50/50 [00:01<00:00, 25.55batch/s, loss=2.87, metric=17.6]\n",
            "Epoch 47: 100%|██████████| 50/50 [00:01<00:00, 25.45batch/s, loss=2.75, metric=15.6]\n",
            "Epoch 48: 100%|██████████| 50/50 [00:01<00:00, 25.30batch/s, loss=2.64, metric=14.1]\n",
            "Epoch 49: 100%|██████████| 50/50 [00:01<00:00, 25.07batch/s, loss=2.55, metric=12.7]\n",
            "Epoch 50: 100%|██████████| 50/50 [00:01<00:00, 25.28batch/s, loss=2.46, metric=11.8]\n",
            "Epoch 51: 100%|██████████| 50/50 [00:01<00:00, 25.60batch/s, loss=2.41, metric=11.2]\n",
            "Epoch 52: 100%|██████████| 50/50 [00:01<00:00, 25.61batch/s, loss=2.33, metric=10.3]\n",
            "Epoch 53: 100%|██████████| 50/50 [00:01<00:00, 25.33batch/s, loss=2.25, metric=9.44]\n",
            "Epoch 54: 100%|██████████| 50/50 [00:01<00:00, 25.53batch/s, loss=2.14, metric=8.54]\n",
            "Epoch 55: 100%|██████████| 50/50 [00:01<00:00, 25.22batch/s, loss=2.05, metric=7.77]\n",
            "Epoch 56:  62%|██████▏   | 31/50 [00:01<00:00, 24.28batch/s, loss=1.98, metric=7.23]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-7579defe06ba>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-29-870050b25dc7>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_loader, loss_fn, optimizer, metric, epoch)\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m       \u001b[0mloss_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m       \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "  model, _, _ = train_one_epoch(model, mini_train_loader, loss_fn, optimizer, metric, epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfegeAIT0L70"
      },
      "source": [
        "-  Train the model for a limited number of epochs, experimenting with various learning rates to find best value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZDUK09T0VGO"
      },
      "outputs": [],
      "source": [
        "num_epochs = 2\n",
        "\n",
        "for lr in [12, 8, 4, 2, 0.9]:\n",
        "  print(f'LR={lr}')\n",
        "\n",
        "  model = LanguageModel(len(vocab), embedding_dim=embedding_dim,\n",
        "                        hidden_dim=hidden_dim, num_layers=num_layers,\n",
        "                        dropoute=dropoute, dropouti=dropouti,\n",
        "                      dropouth=dropouth, dropouto=dropouto).to(device)\n",
        "  # model = torch.load('model.pt')\n",
        "\n",
        "  optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=momentum)\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    model, _, _ = train_one_epoch(model, train_loader, loss_fn, optimizer, metric, epoch)\n",
        "\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-dy-qYP0Zwd"
      },
      "source": [
        "- Creat a small grid search to find exact value of lr and weight decay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyxZLxkm0drG"
      },
      "outputs": [],
      "source": [
        "num_epochs = 1\n",
        "\n",
        "for lr in [7, 8, 14, 13, 12, 11, 10, 9]:\n",
        "  for wd in [1.2e-6]:\n",
        "    print(f'LR={lr}, WD={wd}')\n",
        "\n",
        "    model = LanguageModel(len(vocab), embedding_dim=embedding_dim,\n",
        "                      hidden_dim=hidden_dim, num_layers=num_layers,\n",
        "                      dropoute=dropoute, dropouti=dropouti,\n",
        "                      dropouth=dropouth, dropouto=dropouto).to(device)\n",
        "\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=0.9)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      model, _, _ = train_one_epoch(model, train_loader, loss_fn, optimizer, metric, epoch)\n",
        "\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ3Q1xfn0jft"
      },
      "source": [
        "- Train model for more epochs using the best hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUxTmYsn0lK-",
        "outputId": "8c5cf7df-80a3-4449-a4c3-6130942b8dde"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LanguageModel(\n",
              "  (embedding): Embedding(28782, 300)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (lstm): LSTM(300, 512, num_layers=2, batch_first=True, dropout=0.2)\n",
              "  (fc): Linear(in_features=512, out_features=28782, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = LanguageModel(len(vocab), embedding_dim=embedding_dim,\n",
        "                      hidden_dim=hidden_dim, num_layers=num_layers,\n",
        "                      dropoute=dropoute, dropouti=dropouti,\n",
        "                      dropouth=dropouth, dropouto=dropouto).to(device)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "0yA4xkdo0pg1",
        "outputId": "63c94ccf-65d9-4b11-f715-8ccd1426c3d3"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/model-ppl_133.pt'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-6ef75991a85f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/model-ppl_133.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/model-ppl_133.pt'"
          ]
        }
      ],
      "source": [
        "model = torch.load('/content/model-ppl_133.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsBrL69h0q89",
        "outputId": "90a0c044-163e-42fc-dc10-fc91d667d29a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SGD (\n",
              "Parameter Group 0\n",
              "    dampening: 0\n",
              "    differentiable: False\n",
              "    foreach: None\n",
              "    lr: 8\n",
              "    maximize: False\n",
              "    momentum: 0.9\n",
              "    nesterov: False\n",
              "    weight_decay: 1e-06\n",
              ")"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lr = 8\n",
        "wd = 1e-6\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=0.9)\n",
        "optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8LL1uHv0sSN"
      },
      "outputs": [],
      "source": [
        "loss_train_hist = []\n",
        "loss_valid_hist = []\n",
        "\n",
        "metric_train_hist = []\n",
        "metric_valid_hist = []\n",
        "\n",
        "best_loss_valid = torch.inf\n",
        "epoch_counter = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqRODsU90wKV"
      },
      "outputs": [],
      "source": [
        "num_epochs = 30\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "  # WandB\n",
        "  # run = wandb.init(\n",
        "  #       project=\"language-modeling-lstms\",\n",
        "  #       config={\n",
        "  #           \"learning_rate\": lr,\n",
        "  #           \"epochs\": num_epochs,\n",
        "  #       })\n",
        "\n",
        "  # Train\n",
        "  model, loss_train, metric_train = train_one_epoch(model,\n",
        "                                                    train_loader,\n",
        "                                                    loss_fn,\n",
        "                                                    optimizer,\n",
        "                                                    metric,\n",
        "                                                    epoch)\n",
        "  # Validation\n",
        "  loss_valid, metric_valid = evaluate(model,\n",
        "                                      valid_loader,\n",
        "                                      loss_fn,\n",
        "                                      metric)\n",
        "\n",
        "  loss_train_hist.append(loss_train)\n",
        "  loss_valid_hist.append(loss_valid)\n",
        "\n",
        "  metric_train_hist.append(metric_train)\n",
        "  metric_valid_hist.append(metric_valid)\n",
        "\n",
        "  if loss_valid < best_loss_valid:\n",
        "    torch.save(model, f'model.pt')\n",
        "    best_loss_valid = loss_valid\n",
        "    print('Model Saved!')\n",
        "\n",
        "  print(f'Valid: Loss = {loss_valid:.4}, Metric = {metric_valid:.4}')\n",
        "  print()\n",
        "\n",
        "  epoch_counter += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V-sSI1-02P9"
      },
      "source": [
        "### Main Train Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-H0Trq9804lf"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eu3JG-706fn"
      },
      "outputs": [],
      "source": [
        "set_seed(seed)\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFu74yBI08c9",
        "outputId": "8840a33f-4743-4266-a35c-55f562639b8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying weight drop of 0.5 to weight_hh_l0\n",
            "Applying weight drop of 0.5 to weight_hh_l0\n",
            "Applying weight drop of 0.5 to weight_hh_l0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageModel(\n",
              "  (embedding): Embedding(28782, 400)\n",
              "  (lstms): ModuleList(\n",
              "    (0): WeightDrop(\n",
              "      (module): LSTM(400, 1150)\n",
              "    )\n",
              "    (1): WeightDrop(\n",
              "      (module): LSTM(1150, 1150)\n",
              "    )\n",
              "    (2): WeightDrop(\n",
              "      (module): LSTM(1150, 400)\n",
              "    )\n",
              "  )\n",
              "  (fc): Linear(in_features=400, out_features=28782, bias=True)\n",
              "  (lockdrop): LockedDropout()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "set_seed(seed)\n",
        "\n",
        "model = LanguageModel(len(vocab), embedding_dim=embedding_dim,\n",
        "                      hidden_dim=hidden_dim, num_layers=num_layers,\n",
        "                      dropoute=dropoute, dropouti=dropouti,\n",
        "                      dropouth=dropouth, dropouto=dropouto).to(device)\n",
        "\n",
        "# model = LanguageModel(vocab_size=len(vocab), embedding_dim=embedding_dim,\n",
        "#                       hidden_dim=hidden_dim, num_layers=num_layers,\n",
        "#                       dropoute=dropoute, dropouti=dropouti,\n",
        "#                       dropouth=dropouth, dropouto=dropouto,\n",
        "#                       weight_drop=weight_drop, pretrained=pretrained).to(device)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spHIVlf_1I_5"
      },
      "outputs": [],
      "source": [
        "model = torch.load('model.pt')\n",
        "# epoch_counter = best_epoch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil"
      ],
      "metadata": {
        "id": "a2ckN9ecdQnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "AskOAQl1HQXI",
        "outputId": "ba510d40-9649-49cb-ab4a-bb018621d50e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/LanguageModel/model-ppl100.3epoch29.pt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "shutil.copyfile(\"model.pt\", \"/content/drive/MyDrive/LanguageModel/model-ppl100.3epoch29.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ys-oQE1F1Obg",
        "outputId": "de45594b-6468-47d0-9bb2-46cab3d6a7e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGD (\n",
              "Parameter Group 0\n",
              "    dampening: 0\n",
              "    differentiable: False\n",
              "    foreach: None\n",
              "    lr: 7.5\n",
              "    maximize: False\n",
              "    momentum: 0.9\n",
              "    nesterov: False\n",
              "    weight_decay: 1e-06\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "set_seed(seed)\n",
        "\n",
        "lr = 7.5\n",
        "wd = 1e-6\n",
        "# momentum = 0.9\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=momentum)\n",
        "# optimizer = optim.SGD([{'params': model.embedding.parameters(), 'lr': 0.1*lr},\n",
        "#                        {'params': model.lstms.parameters(), 'lr': lr}],\n",
        "#                       weight_decay=wd, momentum=momentum)\n",
        "optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jgfektma1RUo"
      },
      "outputs": [],
      "source": [
        "if wandb_enable:\n",
        "\n",
        "      config={\n",
        "          'lr': lr,\n",
        "          'momentum': momentum,\n",
        "          'batch_size': batch_size,\n",
        "          'seq_len': seq_len,\n",
        "          'hidden_dim': hidden_dim,\n",
        "          'embedding_dim': embedding_dim,\n",
        "          'num_layers': num_layers,\n",
        "          # 'dropout_embd': dropout_embd,\n",
        "          # 'dropout_rnn': dropout_rnn,\n",
        "          'dropout_embed': dropoute,\n",
        "          'dropout_in_lstm': dropouti,\n",
        "          'dropout_h_lstm': dropouth,\n",
        "          'dropout_out_lstm': dropouto,\n",
        "          'Weight_Drop': Weight_Drop,\n",
        "          'clip': clip,\n",
        "      }\n",
        "\n",
        "      experiment.log_parameters(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BTiIsVt1Vc9"
      },
      "outputs": [],
      "source": [
        "loss_train_hist = []\n",
        "loss_valid_hist = []\n",
        "\n",
        "metric_train_hist = []\n",
        "metric_valid_hist = []\n",
        "\n",
        "best_loss_valid = torch.inf\n",
        "epoch_counter = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "FLMefkng1X32",
        "outputId": "c8579c7e-8e05-4193-fd06-38349610dd5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 367/367 [02:29<00:00,  2.46batch/s, loss=10.3, metric=2.87e+4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 10.26, Metric = 2.869e+04\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 367/367 [02:28<00:00,  2.47batch/s, loss=10.3, metric=2.87e+4]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-3260ecaf0661>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mloss_valid\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_loss_valid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'model.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'/content/drive/MyDrive/LanguageModel/model.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mbest_loss_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_valid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# Now that it is on the CPU we can directly copy it into the zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0mnum_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m         \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "set_seed(seed)\n",
        "num_epochs = 45\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "  # Train\n",
        "  model, loss_train, metric_train = train_one_epoch(model,\n",
        "                                                    train_loader,\n",
        "                                                    loss_fn,\n",
        "                                                    optimizer,\n",
        "                                                    metric,\n",
        "                                                    epoch)\n",
        "  # Validation\n",
        "  loss_valid, metric_valid = evaluate(model,\n",
        "                                      valid_loader,\n",
        "                                      loss_fn,\n",
        "                                      metric)\n",
        "\n",
        "  loss_train_hist.append(loss_train)\n",
        "  loss_valid_hist.append(loss_valid)\n",
        "\n",
        "  metric_train_hist.append(metric_train)\n",
        "  metric_valid_hist.append(metric_valid)\n",
        "\n",
        "  if loss_valid < best_loss_valid:\n",
        "    torch.save(model, f'model.pt')\n",
        "    torch.save(model, f'/content/drive/MyDrive/LanguageModel/model.pt')\n",
        "    best_loss_valid = loss_valid\n",
        "    best_epoch = epoch_counter\n",
        "    print('Model Saved!')\n",
        "\n",
        "  print(f'Valid: Loss = {loss_valid:.4}, Metric = {metric_valid:.4}')\n",
        "  print()\n",
        "\n",
        "  if wandb_enable:\n",
        "    experiment.log_metrics({\"metric_train\": metric_train, \"loss_train\": loss_train,\n",
        "                \"metric_valid\": metric_valid, \"loss_valid\": loss_valid}, epoch=epoch_counter)\n",
        "\n",
        "  epoch_counter += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQ4Y-_Uc1bSk",
        "outputId": "5bd4c726-0660-4316-f622-442246420936"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : embd&lock-drop\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/ft-azad/lm-awd-lstm/7aeb69dee61b4328a5d0c0800cd9c783\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss_train [58]   : (3.8949986699491497, 6.684415862735675)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss_valid [58]   : (4.509146775954809, 5.797027367811936)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metric_train [58] : (49.26998519897461, 800.5197143554688)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metric_valid [58] : (91.26468658447266, 330.65228271484375)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name : embd&lock-drop\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch_size       : 80\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clip             : 0.25\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout_embed    : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout_h_lstm   : 0.3\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout_in_lstm  : 0.65\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout_out_lstm : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embedding_dim    : 400\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hidden_dim       : 1150\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr               : 7.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum         : 0.9\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_layers       : 3\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seq_len          : 70\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n"
          ]
        }
      ],
      "source": [
        "experiment.end()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxRYKNUC1hoe"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCTHcn7t1hWO"
      },
      "outputs": [],
      "source": [
        "model_path = 'model.pt'\n",
        "model = torch.load(model_path)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELNfyJcB1oPN"
      },
      "outputs": [],
      "source": [
        "loss_valid, metric_valid = evaluate(model, valid_loader, loss_fn, metric)\n",
        "metric_valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZ6UaE8N1pQl"
      },
      "outputs": [],
      "source": [
        "loss_test, metric_test = evaluate(model, test_loader, loss_fn, metric)\n",
        "metric_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mez84S5y1roU"
      },
      "source": [
        "# Generate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTXlQSO91wyl"
      },
      "outputs": [],
      "source": [
        "model_path = 'model.pt'\n",
        "model = torch.load(model_path)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0JuNPDq15M7"
      },
      "outputs": [],
      "source": [
        "def generate(prompt, max_seq_len, temperature, model, tokenizer, vocab, seed=None):\n",
        "\n",
        "  indices = vocab(tokenizer(prompt))\n",
        "  itos = vocab.get_itos()\n",
        "\n",
        "  for i in range(max_seq_len):\n",
        "    src = torch.LongTensor(indices).to(device)\n",
        "    with torch.no_grad():\n",
        "      prediction = model(src)\n",
        "\n",
        "    # Low values like 0.1 for temperature, Makes softmax like argmax more\n",
        "    probs = torch.softmax(prediction[-1]/temperature, dim = 0)\n",
        "    idx = vocab[\"<ukn>\"]\n",
        "    while idx == vocab[\"<ukn>\"]:\n",
        "      idx = torch.multinomial(probs, num_samples =1).item()\n",
        "    indices.append(idx)\n",
        "    prompt += \" \" + itos[idx]\n",
        "    # print(prompt)\n",
        "\n",
        "    if idx == vocab[\".\"]:\n",
        "      return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9zBXRrr2C2y"
      },
      "outputs": [],
      "source": [
        "prompt = \"as i know about this subject,\"\n",
        "generate(prompt, 40, 0.5, model, tokenizer, vocab, seed=None)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "xtOFbjYdtuXS"
      ],
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}