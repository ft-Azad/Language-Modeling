{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "xtOFbjYdtuXS"
      ],
      "gpuType": "T4",
      "mount_file_id": "1u9FXu85BotAuf2SsUviy8zqdx--emNma",
      "authorship_tag": "ABX9TyMGYZh2QJoW7vgfHlCTBd0l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ft-Azad/Language-Modeling/blob/main/LanguageModel(AWD_LSTM).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Import Libs"
      ],
      "metadata": {
        "id": "XiRseqOJtOMs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1l3jplbsRcr",
        "outputId": "5fd03a5b-1e08-4b3c-afe0-1c38af3df849"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.3.0+cu121 requires torch==2.3.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.18.0+cu121 requires torch==2.3.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting portalocker>=2.0.0\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: portalocker\n",
            "Successfully installed portalocker-2.8.2\n",
            "Collecting torchtext==0.15.1\n",
            "  Downloading torchtext-0.15.1-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.1) (4.66.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.1) (2.31.0)\n",
            "Collecting torch==2.0.0 (from torchtext==0.15.1)\n",
            "  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.1) (1.25.2)\n",
            "Collecting torchdata==0.6.0 (from torchtext==0.15.1)\n",
            "  Downloading torchdata-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (2.0.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.6.0->torchtext==0.15.1) (2.0.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchtext==0.15.1) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchtext==0.15.1) (0.43.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->torchtext==0.15.1) (3.27.9)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->torchtext==0.15.1) (18.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.15.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.15.1) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.15.1) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0->torchtext==0.15.1) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0->torchtext==0.15.1) (1.3.0)\n",
            "Installing collected packages: torch, torchdata, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1\n",
            "    Uninstalling torch-2.0.1:\n",
            "      Successfully uninstalled torch-2.0.1\n",
            "  Attempting uninstall: torchdata\n",
            "    Found existing installation: torchdata 0.6.1\n",
            "    Uninstalling torchdata-0.6.1:\n",
            "      Successfully uninstalled torchdata-0.6.1\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.18.0\n",
            "    Uninstalling torchtext-0.18.0:\n",
            "      Successfully uninstalled torchtext-0.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.3.0+cu121 requires torch==2.3.0, but you have torch 2.0.0 which is incompatible.\n",
            "torchvision 0.18.0+cu121 requires torch==2.3.0, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.0.0 torchdata-0.6.0 torchtext-0.15.1\n",
            "Collecting comet_ml\n",
            "  Downloading comet_ml-3.43.1-py3-none-any.whl (675 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m675.8/675.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting everett[ini]<3.2.0,>=1.0.1 (from comet_ml)\n",
            "  Downloading everett-3.1.0-py2.py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (4.19.2)\n",
            "Requirement already satisfied: psutil>=5.6.3 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (5.9.5)\n",
            "Collecting python-box<7.0.0 (from comet_ml)\n",
            "  Downloading python_box-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests-toolbelt>=0.8.0 (from comet_ml)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (2.31.0)\n",
            "Collecting semantic-version>=2.8.0 (from comet_ml)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting sentry-sdk>=1.1.0 (from comet_ml)\n",
            "  Downloading sentry_sdk-2.5.1-py2.py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.6/289.6 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting simplejson (from comet_ml)\n",
            "  Downloading simplejson-3.19.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (2.0.7)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (1.14.1)\n",
            "Collecting wurlitzer>=1.0.2 (from comet_ml)\n",
            "  Downloading wurlitzer-3.1.1-py3-none-any.whl (8.6 kB)\n",
            "Collecting dulwich!=0.20.33,>=0.20.6 (from comet_ml)\n",
            "  Downloading dulwich-0.22.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (979 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m979.1/979.1 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rich>=13.3.2 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (13.7.1)\n",
            "Collecting configobj (from everett[ini]<3.2.0,>=1.0.1->comet_ml)\n",
            "  Downloading configobj-5.0.8-py2.py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.18.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet_ml) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet_ml) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet_ml) (2024.6.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet_ml) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet_ml) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.3.2->comet_ml) (0.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from configobj->everett[ini]<3.2.0,>=1.0.1->comet_ml) (1.16.0)\n",
            "Installing collected packages: everett, wurlitzer, simplejson, sentry-sdk, semantic-version, python-box, dulwich, configobj, requests-toolbelt, comet_ml\n",
            "  Attempting uninstall: python-box\n",
            "    Found existing installation: python-box 7.1.1\n",
            "    Uninstalling python-box-7.1.1:\n",
            "      Successfully uninstalled python-box-7.1.1\n",
            "Successfully installed comet_ml-3.43.1 configobj-5.0.8 dulwich-0.22.1 everett-3.1.0 python-box-6.1.0 requests-toolbelt-1.0.0 semantic-version-2.10.0 sentry-sdk-2.5.1 simplejson-3.19.2 wurlitzer-3.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -q torchmetrics\n",
        "!pip install -q torchdata==0.6.1\n",
        "!pip install 'portalocker>=2.0.0'\n",
        "!pip install torchtext==0.15.1\n",
        "!pip install comet_ml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torchtext\n",
        "from torchtext.datasets import WikiText2\n",
        "from torchdata.datapipes.iter import IterableWrapper, Mapper\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "\n",
        "from torch import optim\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import os\n",
        "import tqdm\n",
        "import torchmetrics as tm\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "from comet_ml import Experiment\n",
        "from comet_ml.integration.pytorch import log_model"
      ],
      "metadata": {
        "id": "YXPfyHdktUV2"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for lib in [np, torch, torchtext, tqdm]:\n",
        "  print(lib.__name__, '-->', lib.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xed-F0ttyk6",
        "outputId": "99faba10-6fe5-41d3-ff03-e4ddaeb63bb5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy --> 1.25.2\n",
            "torch --> 2.0.0+cu117\n",
            "torchtext --> 0.15.1+cpu\n",
            "tqdm --> 4.66.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "xtOFbjYdtuXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "metadata": {
        "id": "Y36SBwzHttlz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def num_trainable_params(model):\n",
        "  nums = sum(p.numel() for p in model.parameters() if p.requires_grad)/1e6\n",
        "  return nums"
      ],
      "metadata": {
        "id": "jvkD1SZDt1QU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed):\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  if torch.cuda.is_available():\n",
        "      torch.cuda.manual_seed(seed)\n",
        "      # torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "      # torch.backends.cudnn.deterministic = True\n",
        "      # torch.backends.cudnn.benchmark = False\n"
      ],
      "metadata": {
        "id": "mZwiS0r7t2qm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Arguments"
      ],
      "metadata": {
        "id": "Kou_xgQtuSKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 8\n",
        "\n",
        "batch_size = 20\n",
        "seq_len = 35\n",
        "\n",
        "embedding_dim = 300\n",
        "\n",
        "num_layers = 2\n",
        "hidden_dim = 512\n",
        "dropout_embd = 0.5\n",
        "dropout_rnn = 0.2\n",
        "\n",
        "\n",
        "lr = 3\n",
        "wd = 1e-6\n",
        "momentum = 0.9\n",
        "\n",
        "clip = 0.25\n",
        "\n",
        "wandb_enable = True"
      ],
      "metadata": {
        "id": "PSqJ0n_guXCL"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset"
      ],
      "metadata": {
        "id": "IiM52d_Yt5vU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Dataset and Build Vocab"
      ],
      "metadata": {
        "id": "rMElZJWSt72c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Loading Iterable Data"
      ],
      "metadata": {
        "id": "ma9kBZCJt9_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlZif_l-t45M",
        "outputId": "d4088e1f-0be1-4a0e-b942-4de7e3905341"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q \"/content/drive/MyDrive/LanguageModel/Data/wikitext-2-v1.zip\" -d '/content/'"
      ],
      "metadata": {
        "id": "NS6x1w4VuCkU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/wikitext-2/wiki.train.tokens', 'r') as file:\n",
        "    train_iter = file.read().splitlines()\n",
        "\n",
        "with open('/content/wikitext-2/wiki.test.tokens', 'r') as file:\n",
        "    test_iter = file.read().splitlines()\n",
        "\n",
        "with open('/content/wikitext-2/wiki.valid.tokens', 'r') as file:\n",
        "    valid_iter = file.read().splitlines()\n",
        "\n",
        "train_iter = IterableWrapper(train_iter)\n",
        "test_iter = IterableWrapper(test_iter)\n",
        "valid_iter = IterableWrapper(valid_iter)"
      ],
      "metadata": {
        "id": "S9jSpftfuD9K"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Build Vocabulary"
      ],
      "metadata": {
        "id": "gNlDyqOwvItm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = get_tokenizer('basic_english')\n",
        "vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=['<unk>'])\n",
        "vocab.set_default_index(vocab['<unk>'])\n",
        "torch.save(vocab, 'vocab.pt')"
      ],
      "metadata": {
        "id": "o4QNGKw4vQ2r"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Prepreation"
      ],
      "metadata": {
        "id": "TVsC0d1Qvt6E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Creat Target Array"
      ],
      "metadata": {
        "id": "2gEXdvicwTRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_process(raw_text_iter, seq_len):\n",
        "  data = torch.cat([torch.LongTensor(vocab(tokenizer(line))) for line in raw_text_iter])\n",
        "\n",
        "  M = len(data) // seq_len\n",
        "\n",
        "  r = len(data) % seq_len\n",
        "  data = torch.cat((data, torch.LongTensor([0]))) if r==0 else data\n",
        "\n",
        "  inputs = data[:M*seq_len]\n",
        "  targets = data[1:M*seq_len+1]\n",
        "\n",
        "  inputs = inputs.reshape(-1, seq_len)\n",
        "  targets = targets.reshape(-1, seq_len)\n",
        "\n",
        "  return inputs, targets"
      ],
      "metadata": {
        "id": "i_FC_QFzvtcL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = data_process(train_iter, seq_len)\n",
        "X_valid, y_valid = data_process(valid_iter, seq_len)\n",
        "X_test, y_test = data_process(test_iter, seq_len)\n",
        "\n",
        "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape, X_test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYP0TPqcvz_L",
        "outputId": "c34c5cb5-f250-4b95-e7e2-abd803a93ee2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([58571, 35]),\n",
              " torch.Size([58571, 35]),\n",
              " torch.Size([6126, 35]),\n",
              " torch.Size([6126, 35]),\n",
              " torch.Size([6910, 35]),\n",
              " torch.Size([6910, 35]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Custom Dataset Class Definition"
      ],
      "metadata": {
        "id": "aJbQ1Nh0wXyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LanguageModelDataset(Dataset):\n",
        "\n",
        "  def __init__(self, inputs, targets):\n",
        "    self.inputs = inputs\n",
        "    self.targets = targets\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.inputs.shape[0]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.inputs[idx], self.targets[idx]"
      ],
      "metadata": {
        "id": "BkQQ934CxF21"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = LanguageModelDataset(X_train, y_train)\n",
        "valid_set = LanguageModelDataset(X_valid, y_valid)\n",
        "test_set = LanguageModelDataset(X_test, y_test)"
      ],
      "metadata": {
        "id": "56QXULMExJJ9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_QgbAMixKn7",
        "outputId": "3f036a86-cad4-460c-8eb4-ef8191bebb51"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([    9,  3849,  3869,   881,     9, 20000,    83,  3849,    88,     0,\n",
              "          3869,    21,   780, 28780,     2,  6182,     3,  3849,     4,     1,\n",
              "          5023,    88,    20,     2,  1837,  1018,     7,    14,  3849,  3869,\n",
              "           881,   629,   976,     2,    23]),\n",
              " tensor([ 3849,  3869,   881,     9, 20000,    83,  3849,    88,     0,  3869,\n",
              "            21,   780, 28780,     2,  6182,     3,  3849,     4,     1,  5023,\n",
              "            88,    20,     2,  1837,  1018,     7,    14,  3849,  3869,   881,\n",
              "           629,   976,     2,    23,     8]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Data Loader"
      ],
      "metadata": {
        "id": "NZkza2MYxOnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(seed)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "4gz_hP05xRt8"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_batch, y_batch = next(iter(train_loader))\n",
        "x_batch.shape, y_batch.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQ1eIKZLxUOz",
        "outputId": "0f1e844d-b6d9-470d-b414-56bca6ca95de"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([20, 35]), torch.Size([20, 35]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(seed)\n",
        "\n",
        "for inputs, targets in train_loader:\n",
        "  print(inputs[0, 0], targets[0, 0])\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwbPWDxTxvrO",
        "outputId": "59b5c312-19ec-4ede-c832-3203a708cc08"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3444) tensor(201)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "vMYLSVQWx2W8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LanguageModel(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers,\n",
        "                dropout_embd=0.5, dropout_rnn=0.5):\n",
        "    super().__init__()\n",
        "    self.num_layers = num_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.embedding_dim = embedding_dim\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.embedding.weight.data.uniform_(-0.1, 0.1)\n",
        "    self.dropout = nn.Dropout(p=dropout_embd)\n",
        "\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers,\n",
        "                        dropout=dropout_rnn, batch_first=True)\n",
        "\n",
        "    self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "  def forward(self, src):\n",
        "    embedding = self.dropout(self.embedding(src))\n",
        "    output, hidden = self.lstm(embedding)\n",
        "    prediction = self.fc(output)\n",
        "    return prediction"
      ],
      "metadata": {
        "id": "vdlAzoEcx2FM"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(seed)\n",
        "\n",
        "model = LanguageModel(vocab_size=len(vocab),\n",
        "                      embedding_dim=embedding_dim,\n",
        "                      hidden_dim=hidden_dim,\n",
        "                      num_layers=num_layers,\n",
        "                      dropout_embd=dropout_embd,\n",
        "                      dropout_rnn=dropout_rnn)\n",
        "model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJotksm3x-cU",
        "outputId": "d7394138-d0e5-4305-aa28-bc0e57c6e03c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageModel(\n",
              "  (embedding): Embedding(28782, 300)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (lstm): LSTM(300, 512, num_layers=2, batch_first=True, dropout=0.2)\n",
              "  (fc): Linear(in_features=512, out_features=28782, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuration"
      ],
      "metadata": {
        "id": "QNdI-5pVyOKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "PGCd-Dm-yNhM",
        "outputId": "9c92cc52-3c47-4731-c41d-1f8d7b887a4d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "metric = tm.text.Perplexity().to(device)"
      ],
      "metadata": {
        "id": "hd19NFFNyUFk"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key_file = \"/content/drive/MyDrive/LanguageModel/key.txt\"\n",
        "\n",
        "if os.path.exists(key_file):\n",
        "    with open(key_file) as f:\n",
        "        key = f.readline().strip()\n",
        "else:\n",
        "    print(\"Key file does not exist. Please create the key file with your wandb API key.\")"
      ],
      "metadata": {
        "id": "_6Oy3pH0RgAt"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb_arg_name = input('Please input the WandB argument (run) name:')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfY7_5XZc4qk",
        "outputId": "334e212a-334f-4bd9-b263-cccf6e082286"
      },
      "execution_count": 88,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please input the WandB argument (run) name:Base-Model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# comet_ml.init(project_name=\"LM_AWD-LSTM\")"
      ],
      "metadata": {
        "id": "_APSWaGyc5Iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment = Experiment(\n",
        "  api_key=key,\n",
        "  project_name=\"LM_AWD-LSTM\",\n",
        ")\n",
        "experiment.set_name(wandb_arg_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAsopugofMzN",
        "outputId": "647451ef-053e-4e0b-fb69-926e83467daf"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : base_model\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/ft-azad/lm-awd-lstm/3458ca9b061e4086a702e226aeb246ed\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss_train [8]   : (4.078268378952146, 5.890382317533928)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss_valid [8]   : (6.029867288732373, 6.170265618675306)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metric_train [8] : (59.043067932128906, 361.54278564453125)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metric_valid [8] : (415.9185485839844, 478.6871337890625)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name : base_model\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch_size    : 20\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clip          : 0.25\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embedding_dim : 300\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hidden_dim    : 512\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr            : 3\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum      : 0.9\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_layers    : 2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seq_len       : 35\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/ft-azad/lm-awd-lstm/4919e87f14cd4f18ac925d0c393f074d\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "U_1sWWHVy7Kk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and Evaluate Functions"
      ],
      "metadata": {
        "id": "OxTkh6JGy9Kj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Functions\n",
        "def train_one_epoch(model, train_loader, loss_fn, optimizer, metric, epoch=None):\n",
        "  model.train()\n",
        "  loss_train = AverageMeter()\n",
        "  metric.reset()\n",
        "\n",
        "  with tqdm.tqdm(train_loader, unit='batch') as tepoch:\n",
        "    for inputs, targets in tepoch:\n",
        "      if epoch:\n",
        "        tepoch.set_description(f'Epoch {epoch}')\n",
        "\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      loss = loss_fn(outputs.reshape(-1, outputs.shape[-1]), targets.flatten())\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      nn.utils.clip_grad.clip_grad_norm_(model.parameters(), max_norm=clip)\n",
        "\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      loss_train.update(loss.item(), n=len(targets))\n",
        "      metric.update(outputs, targets)\n",
        "\n",
        "      tepoch.set_postfix(loss=loss_train.avg, metric=metric.compute().item())\n",
        "\n",
        "  return model, loss_train.avg, metric.compute().item()"
      ],
      "metadata": {
        "id": "v1dAZfqLy850"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Function\n",
        "def evaluate(model, test_loader, loss_fn, metric):\n",
        "  model.eval()\n",
        "  loss_eval = AverageMeter()\n",
        "  metric.reset()\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for inputs, targets in test_loader:\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      loss = loss_fn(outputs.reshape(-1, outputs.shape[-1]), targets.flatten())\n",
        "      loss_eval.update(loss.item(), n=len(targets))\n",
        "\n",
        "      metric(outputs, targets)\n",
        "\n",
        "  return loss_eval.avg, metric.compute().item()"
      ],
      "metadata": {
        "id": "ma-DFi9XzE1s"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Process and Tunning"
      ],
      "metadata": {
        "id": "LKkW_4FBz1ac"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding Hyper-parameters"
      ],
      "metadata": {
        "id": "2FYTauriz3RL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Calculating the loss for untrained model using a few batches"
      ],
      "metadata": {
        "id": "BaPsJriFz4i7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for iter_num in range(5):\n",
        "  model = LanguageModel(len(vocab), embedding_dim=embedding_dim,\n",
        "                      hidden_dim=hidden_dim, num_layers=num_layers,\n",
        "                      dropout_embd=dropout_embd, dropout_rnn=dropout_rnn).to(device)\n",
        "\n",
        "  inputs, targets = next(iter(train_loader))\n",
        "  inputs = inputs.to(device)\n",
        "  targets = targets.to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    outputs = model(inputs)\n",
        "    loss = loss_fn(outputs.reshape(-1, outputs.shape[-1]), targets.flatten())\n",
        "\n",
        "  print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIebaKmbz5xj",
        "outputId": "4ab612a6-f559-475f-e2b0-c1a9ea7320e3"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.2711, device='cuda:0')\n",
            "tensor(10.2717, device='cuda:0')\n",
            "tensor(10.2653, device='cuda:0')\n",
            "tensor(10.2671, device='cuda:0')\n",
            "tensor(10.2690, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Train and try to overfit the model on a small subset of the dataset."
      ],
      "metadata": {
        "id": "14lWNR0Jz8VQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LanguageModel(len(vocab), embedding_dim=embedding_dim,\n",
        "                      hidden_dim=hidden_dim, num_layers=num_layers,\n",
        "                      dropout_embd=dropout_embd, dropout_rnn=dropout_rnn).to(device)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.9, momentum=0.9)"
      ],
      "metadata": {
        "id": "pg26Lvdb0G8I"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mini_train_size = 1000\n",
        "_, mini_train_dataset = random_split(train_set, (len(train_set)-mini_train_size, mini_train_size))\n",
        "mini_train_loader = DataLoader(mini_train_dataset, 20)"
      ],
      "metadata": {
        "id": "p2XIZjef0IG5"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "  model, _, _ = train_one_epoch(model, mini_train_loader, loss_fn, optimizer, metric, epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VEtGlnyl0JHy",
        "outputId": "3b64a994-8e4f-4ffa-e410-4dd711a0079c"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:01<00:00, 26.48batch/s, loss=8.33, metric=4.15e+3]\n",
            "Epoch 1: 100%|██████████| 50/50 [00:01<00:00, 25.97batch/s, loss=7.18, metric=1.31e+3]\n",
            "Epoch 2: 100%|██████████| 50/50 [00:01<00:00, 25.92batch/s, loss=7, metric=1.1e+3]\n",
            "Epoch 3: 100%|██████████| 50/50 [00:01<00:00, 25.80batch/s, loss=6.93, metric=1.02e+3]\n",
            "Epoch 4: 100%|██████████| 50/50 [00:01<00:00, 25.78batch/s, loss=6.84, metric=937]\n",
            "Epoch 5: 100%|██████████| 50/50 [00:01<00:00, 25.14batch/s, loss=6.72, metric=832]\n",
            "Epoch 6: 100%|██████████| 50/50 [00:02<00:00, 24.81batch/s, loss=6.61, metric=740]\n",
            "Epoch 7: 100%|██████████| 50/50 [00:01<00:00, 25.30batch/s, loss=6.51, metric=672]\n",
            "Epoch 8: 100%|██████████| 50/50 [00:01<00:00, 25.30batch/s, loss=6.43, metric=619]\n",
            "Epoch 9: 100%|██████████| 50/50 [00:01<00:00, 25.16batch/s, loss=6.35, metric=572]\n",
            "Epoch 10: 100%|██████████| 50/50 [00:01<00:00, 25.14batch/s, loss=6.27, metric=529]\n",
            "Epoch 11: 100%|██████████| 50/50 [00:01<00:00, 25.29batch/s, loss=6.2, metric=493]\n",
            "Epoch 12: 100%|██████████| 50/50 [00:02<00:00, 24.81batch/s, loss=6.12, metric=456]\n",
            "Epoch 13: 100%|██████████| 50/50 [00:02<00:00, 24.73batch/s, loss=6.05, metric=426]\n",
            "Epoch 14: 100%|██████████| 50/50 [00:02<00:00, 24.76batch/s, loss=5.98, metric=396]\n",
            "Epoch 15: 100%|██████████| 50/50 [00:02<00:00, 24.74batch/s, loss=5.91, metric=367]\n",
            "Epoch 16: 100%|██████████| 50/50 [00:02<00:00, 24.94batch/s, loss=5.83, metric=339]\n",
            "Epoch 17: 100%|██████████| 50/50 [00:01<00:00, 25.20batch/s, loss=5.74, metric=312]\n",
            "Epoch 18: 100%|██████████| 50/50 [00:01<00:00, 25.08batch/s, loss=5.65, metric=283]\n",
            "Epoch 19: 100%|██████████| 50/50 [00:02<00:00, 24.73batch/s, loss=5.55, metric=257]\n",
            "Epoch 20: 100%|██████████| 50/50 [00:02<00:00, 24.73batch/s, loss=5.45, metric=234]\n",
            "Epoch 21: 100%|██████████| 50/50 [00:02<00:00, 24.90batch/s, loss=5.36, metric=213]\n",
            "Epoch 22: 100%|██████████| 50/50 [00:01<00:00, 25.25batch/s, loss=5.27, metric=194]\n",
            "Epoch 23: 100%|██████████| 50/50 [00:01<00:00, 25.29batch/s, loss=5.18, metric=178]\n",
            "Epoch 24: 100%|██████████| 50/50 [00:01<00:00, 25.29batch/s, loss=5.09, metric=162]\n",
            "Epoch 25: 100%|██████████| 50/50 [00:01<00:00, 25.38batch/s, loss=4.99, metric=146]\n",
            "Epoch 26: 100%|██████████| 50/50 [00:01<00:00, 25.51batch/s, loss=4.88, metric=132]\n",
            "Epoch 27: 100%|██████████| 50/50 [00:02<00:00, 24.77batch/s, loss=4.79, metric=121]\n",
            "Epoch 28: 100%|██████████| 50/50 [00:02<00:00, 24.55batch/s, loss=4.69, metric=109]\n",
            "Epoch 29: 100%|██████████| 50/50 [00:01<00:00, 25.48batch/s, loss=4.57, metric=97]\n",
            "Epoch 30: 100%|██████████| 50/50 [00:01<00:00, 25.48batch/s, loss=4.45, metric=86]\n",
            "Epoch 31: 100%|██████████| 50/50 [00:01<00:00, 25.58batch/s, loss=4.34, metric=76.5]\n",
            "Epoch 32: 100%|██████████| 50/50 [00:01<00:00, 25.46batch/s, loss=4.23, metric=68.8]\n",
            "Epoch 33: 100%|██████████| 50/50 [00:01<00:00, 25.51batch/s, loss=4.13, metric=62]\n",
            "Epoch 34: 100%|██████████| 50/50 [00:02<00:00, 24.97batch/s, loss=4.02, metric=55.6]\n",
            "Epoch 35: 100%|██████████| 50/50 [00:01<00:00, 25.13batch/s, loss=3.93, metric=51.1]\n",
            "Epoch 36: 100%|██████████| 50/50 [00:01<00:00, 25.71batch/s, loss=3.85, metric=47]\n",
            "Epoch 37: 100%|██████████| 50/50 [00:01<00:00, 25.54batch/s, loss=3.75, metric=42.7]\n",
            "Epoch 38: 100%|██████████| 50/50 [00:01<00:00, 25.13batch/s, loss=3.67, metric=39.2]\n",
            "Epoch 39: 100%|██████████| 50/50 [00:01<00:00, 25.34batch/s, loss=3.61, metric=37]\n",
            "Epoch 40: 100%|██████████| 50/50 [00:01<00:00, 25.20batch/s, loss=3.55, metric=34.8]\n",
            "Epoch 41: 100%|██████████| 50/50 [00:01<00:00, 25.27batch/s, loss=3.45, metric=31.5]\n",
            "Epoch 42: 100%|██████████| 50/50 [00:02<00:00, 24.61batch/s, loss=3.36, metric=28.7]\n",
            "Epoch 43: 100%|██████████| 50/50 [00:02<00:00, 24.40batch/s, loss=3.25, metric=25.7]\n",
            "Epoch 44: 100%|██████████| 50/50 [00:02<00:00, 24.98batch/s, loss=3.12, metric=22.7]\n",
            "Epoch 45: 100%|██████████| 50/50 [00:01<00:00, 25.05batch/s, loss=3.01, metric=20.2]\n",
            "Epoch 46: 100%|██████████| 50/50 [00:01<00:00, 25.55batch/s, loss=2.87, metric=17.6]\n",
            "Epoch 47: 100%|██████████| 50/50 [00:01<00:00, 25.45batch/s, loss=2.75, metric=15.6]\n",
            "Epoch 48: 100%|██████████| 50/50 [00:01<00:00, 25.30batch/s, loss=2.64, metric=14.1]\n",
            "Epoch 49: 100%|██████████| 50/50 [00:01<00:00, 25.07batch/s, loss=2.55, metric=12.7]\n",
            "Epoch 50: 100%|██████████| 50/50 [00:01<00:00, 25.28batch/s, loss=2.46, metric=11.8]\n",
            "Epoch 51: 100%|██████████| 50/50 [00:01<00:00, 25.60batch/s, loss=2.41, metric=11.2]\n",
            "Epoch 52: 100%|██████████| 50/50 [00:01<00:00, 25.61batch/s, loss=2.33, metric=10.3]\n",
            "Epoch 53: 100%|██████████| 50/50 [00:01<00:00, 25.33batch/s, loss=2.25, metric=9.44]\n",
            "Epoch 54: 100%|██████████| 50/50 [00:01<00:00, 25.53batch/s, loss=2.14, metric=8.54]\n",
            "Epoch 55: 100%|██████████| 50/50 [00:01<00:00, 25.22batch/s, loss=2.05, metric=7.77]\n",
            "Epoch 56:  62%|██████▏   | 31/50 [00:01<00:00, 24.28batch/s, loss=1.98, metric=7.23]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-7579defe06ba>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-29-870050b25dc7>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_loader, loss_fn, optimizer, metric, epoch)\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m       \u001b[0mloss_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m       \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  Train the model for a limited number of epochs, experimenting with various learning rates to find best value"
      ],
      "metadata": {
        "id": "CfegeAIT0L70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 2\n",
        "\n",
        "for lr in [12, 8, 4, 2, 0.9]:\n",
        "  print(f'LR={lr}')\n",
        "\n",
        "  model = LanguageModel(len(vocab), embedding_dim=embedding_dim,\n",
        "                        hidden_dim=hidden_dim, num_layers=num_layers,\n",
        "                        dropout_embd=dropout_embd, dropout_rnn=dropout_rnn).to(device)\n",
        "  # model = torch.load('model.pt')\n",
        "\n",
        "  optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=momentum)\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    model, _, _ = train_one_epoch(model, train_loader, loss_fn, optimizer, metric, epoch)\n",
        "\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "OZDUK09T0VGO",
        "outputId": "004e1f99-1068-49b3-9b8a-83e69b1307ff"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR=12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2929/2929 [01:55<00:00, 25.42batch/s, loss=5.98, metric=394]\n",
            "Epoch 1:  90%|████████▉ | 2624/2929 [01:47<00:12, 24.32batch/s, loss=5.65, metric=284]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-f9cf261326ce>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-870050b25dc7>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_loader, loss_fn, optimizer, metric, epoch)\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m       \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouped_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforeach\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mforeach\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_has_foreach_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_mul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_coef_clamped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-overload]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mforeach\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'foreach=True was passed, but can\\'t use the foreach API on {device.type} tensors'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Creat a small grid search to find exact value of lr and weight decay"
      ],
      "metadata": {
        "id": "c-dy-qYP0Zwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 1\n",
        "\n",
        "for lr in [7, 8, 14, 13, 12, 11, 10, 9]:\n",
        "  for wd in [1.2e-6]:\n",
        "    print(f'LR={lr}, WD={wd}')\n",
        "\n",
        "    model = LanguageModel(len(vocab), embedding_dim=embedding_dim,\n",
        "                      hidden_dim=hidden_dim, num_layers=num_layers,\n",
        "                      dropout_embd=dropout_embd, dropout_rnn=dropout_rnn).to(device)\n",
        "\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=0.9)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      model, _, _ = train_one_epoch(model, train_loader, loss_fn, optimizer, metric, epoch)\n",
        "\n",
        "    print()"
      ],
      "metadata": {
        "id": "PyxZLxkm0drG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Train model for more epochs using the best hyperparameters"
      ],
      "metadata": {
        "id": "nJ3Q1xfn0jft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LanguageModel(len(vocab), embedding_dim=embedding_dim,\n",
        "                      hidden_dim=hidden_dim, num_layers=num_layers,\n",
        "                      dropout_embd=dropout_embd, dropout_rnn=dropout_rnn).to(device)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUxTmYsn0lK-",
        "outputId": "8c5cf7df-80a3-4449-a4c3-6130942b8dde"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageModel(\n",
              "  (embedding): Embedding(28782, 300)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (lstm): LSTM(300, 512, num_layers=2, batch_first=True, dropout=0.2)\n",
              "  (fc): Linear(in_features=512, out_features=28782, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('/content/model-ppl_133.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "0yA4xkdo0pg1",
        "outputId": "63c94ccf-65d9-4b11-f715-8ccd1426c3d3"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/model-ppl_133.pt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-6ef75991a85f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/model-ppl_133.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/model-ppl_133.pt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 8\n",
        "wd = 1e-6\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=0.9)\n",
        "optimizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsBrL69h0q89",
        "outputId": "90a0c044-163e-42fc-dc10-fc91d667d29a"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGD (\n",
              "Parameter Group 0\n",
              "    dampening: 0\n",
              "    differentiable: False\n",
              "    foreach: None\n",
              "    lr: 8\n",
              "    maximize: False\n",
              "    momentum: 0.9\n",
              "    nesterov: False\n",
              "    weight_decay: 1e-06\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_train_hist = []\n",
        "loss_valid_hist = []\n",
        "\n",
        "metric_train_hist = []\n",
        "metric_valid_hist = []\n",
        "\n",
        "best_loss_valid = torch.inf\n",
        "epoch_counter = 0"
      ],
      "metadata": {
        "id": "B8LL1uHv0sSN"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "  # WandB\n",
        "  # run = wandb.init(\n",
        "  #       project=\"language-modeling-lstms\",\n",
        "  #       config={\n",
        "  #           \"learning_rate\": lr,\n",
        "  #           \"epochs\": num_epochs,\n",
        "  #       })\n",
        "\n",
        "  # Train\n",
        "  model, loss_train, metric_train = train_one_epoch(model,\n",
        "                                                    train_loader,\n",
        "                                                    loss_fn,\n",
        "                                                    optimizer,\n",
        "                                                    metric,\n",
        "                                                    epoch)\n",
        "  # Validation\n",
        "  loss_valid, metric_valid = evaluate(model,\n",
        "                                      valid_loader,\n",
        "                                      loss_fn,\n",
        "                                      metric)\n",
        "\n",
        "  loss_train_hist.append(loss_train)\n",
        "  loss_valid_hist.append(loss_valid)\n",
        "\n",
        "  metric_train_hist.append(metric_train)\n",
        "  metric_valid_hist.append(metric_valid)\n",
        "\n",
        "  if loss_valid < best_loss_valid:\n",
        "    torch.save(model, f'model.pt')\n",
        "    best_loss_valid = loss_valid\n",
        "    print('Model Saved!')\n",
        "\n",
        "  print(f'Valid: Loss = {loss_valid:.4}, Metric = {metric_valid:.4}')\n",
        "  print()\n",
        "\n",
        "  epoch_counter += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 769
        },
        "id": "KqRODsU90wKV",
        "outputId": "00489a5f-cb0e-4aef-ed47-aaa1b7dcccea"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 2929/2929 [01:59<00:00, 24.46batch/s, loss=5.88, metric=360]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 6.046, Metric = 422.9\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 2929/2929 [01:59<00:00, 24.49batch/s, loss=5.24, metric=188]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 6.027, Metric = 414.9\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 2929/2929 [01:59<00:00, 24.48batch/s, loss=4.96, metric=143]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 6.042, Metric = 421.1\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 2929/2929 [01:59<00:00, 24.52batch/s, loss=4.78, metric=119]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 6.064, Metric = 430.6\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 2929/2929 [01:59<00:00, 24.45batch/s, loss=4.65, metric=105]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 6.068, Metric = 432.1\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6:  40%|████      | 1177/2929 [00:48<01:11, 24.51batch/s, loss=4.5, metric=90]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-ed6d696242c2>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   model, loss_train, metric_train = train_one_epoch(model,\n\u001b[0m\u001b[1;32m     14\u001b[0m                                                     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                                                     \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-870050b25dc7>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_loader, loss_fn, optimizer, metric, epoch)\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m       \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouped_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforeach\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mforeach\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_has_foreach_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_mul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_coef_clamped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-overload]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mforeach\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'foreach=True was passed, but can\\'t use the foreach API on {device.type} tensors'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main Train Loop"
      ],
      "metadata": {
        "id": "7V-sSI1-02P9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "-H0Trq9804lf"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(seed)\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "6eu3JG-706fn"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(seed)\n",
        "\n",
        "model = LanguageModel(len(vocab), embedding_dim=embedding_dim,\n",
        "                      hidden_dim=hidden_dim, num_layers=num_layers,\n",
        "                      dropout_embd=dropout_embd, dropout_rnn=dropout_rnn).to(device)\n",
        "\n",
        "# model = LanguageModel(vocab_size=len(vocab), embedding_dim=embedding_dim,\n",
        "#                       hidden_dim=hidden_dim, num_layers=num_layers,\n",
        "#                       dropoute=dropoute, dropouti=dropouti,\n",
        "#                       dropouth=dropouth, dropouto=dropouto,\n",
        "#                       weight_drop=weight_drop, pretrained=pretrained).to(device)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFu74yBI08c9",
        "outputId": "56053d0b-df68-49fc-ef83-4edb955eec55"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageModel(\n",
              "  (embedding): Embedding(28782, 300)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (lstm): LSTM(300, 512, num_layers=2, batch_first=True, dropout=0.2)\n",
              "  (fc): Linear(in_features=512, out_features=28782, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('model.pt')"
      ],
      "metadata": {
        "id": "spHIVlf_1I_5"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil"
      ],
      "metadata": {
        "id": "zEnZPm1YHeUZ"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.copyfile(\"model-ppl130.8.pt\", \"/content/drive/MyDrive/LanguageModel/model-ppl130.8.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "AskOAQl1HQXI",
        "outputId": "2be0560f-a324-403b-f00e-acef53b07edf"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/LanguageModel/model-ppl130.8.pt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(seed)\n",
        "\n",
        "lr = 0.5\n",
        "wd = 1e-6\n",
        "# momentum = 0.9\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=momentum)\n",
        "# optimizer = optim.SGD([{'params': model.embedding.parameters(), 'lr': 0.1*lr},\n",
        "#                        {'params': model.lstms.parameters(), 'lr': lr}],\n",
        "#                       weight_decay=wd, momentum=momentum)\n",
        "optimizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ys-oQE1F1Obg",
        "outputId": "6a289961-b250-492f-ab00-ba880f038583"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGD (\n",
              "Parameter Group 0\n",
              "    dampening: 0\n",
              "    differentiable: False\n",
              "    foreach: None\n",
              "    lr: 0.5\n",
              "    maximize: False\n",
              "    momentum: 0.9\n",
              "    nesterov: False\n",
              "    weight_decay: 1e-06\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if wandb_enable:\n",
        "\n",
        "      config={\n",
        "          'lr': lr,\n",
        "          'momentum': momentum,\n",
        "          'batch_size': batch_size,\n",
        "          'seq_len': seq_len,\n",
        "          'hidden_dim': hidden_dim,\n",
        "          'embedding_dim': embedding_dim,\n",
        "          'num_layers': num_layers,\n",
        "          # 'dropout_embed': dropoute,\n",
        "          # 'dropout_in_lstm': dropouti,\n",
        "          # 'dropout_h_lstm': dropouth,\n",
        "          # 'dropout_out_lstm': dropouto,\n",
        "          'clip': clip,\n",
        "      }\n",
        "\n",
        "      experiment.log_parameters(config)"
      ],
      "metadata": {
        "id": "Jgfektma1RUo"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_train_hist = []\n",
        "loss_valid_hist = []\n",
        "\n",
        "metric_train_hist = []\n",
        "metric_valid_hist = []\n",
        "\n",
        "best_loss_valid = torch.inf\n",
        "epoch_counter = 0"
      ],
      "metadata": {
        "id": "_BTiIsVt1Vc9"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(seed)\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "  # Train\n",
        "  model, loss_train, metric_train = train_one_epoch(model,\n",
        "                                                    train_loader,\n",
        "                                                    loss_fn,\n",
        "                                                    optimizer,\n",
        "                                                    metric,\n",
        "                                                    epoch)\n",
        "  # Validation\n",
        "  loss_valid, metric_valid = evaluate(model,\n",
        "                                      valid_loader,\n",
        "                                      loss_fn,\n",
        "                                      metric)\n",
        "\n",
        "  loss_train_hist.append(loss_train)\n",
        "  loss_valid_hist.append(loss_valid)\n",
        "\n",
        "  metric_train_hist.append(metric_train)\n",
        "  metric_valid_hist.append(metric_valid)\n",
        "\n",
        "  if loss_valid < best_loss_valid:\n",
        "    torch.save(model, f'model.pt')\n",
        "    best_loss_valid = loss_valid\n",
        "    print('Model Saved!')\n",
        "\n",
        "  print(f'Valid: Loss = {loss_valid:.4}, Metric = {metric_valid:.4}')\n",
        "  print()\n",
        "\n",
        "  if wandb_enable:\n",
        "    experiment.log_metrics({\"metric_train\": metric_train, \"loss_train\": loss_train,\n",
        "                \"metric_valid\": metric_valid, \"loss_valid\": loss_valid}, epoch=epoch)\n",
        "\n",
        "  epoch_counter += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "id": "FLMefkng1X32",
        "outputId": "2861fe93-f306-448d-e2c9-1bbc291213c6"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 2929/2929 [01:59<00:00, 24.57batch/s, loss=4.08, metric=59]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 4.877, Metric = 131.2\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 2929/2929 [01:59<00:00, 24.50batch/s, loss=3.97, metric=53]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 4.873, Metric = 130.8\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 2929/2929 [01:59<00:00, 24.55batch/s, loss=3.91, metric=49.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 4.877, Metric = 131.3\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 2929/2929 [01:59<00:00, 24.53batch/s, loss=3.86, metric=47.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 4.884, Metric = 132.1\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  86%|████████▋ | 2528/2929 [01:42<00:16, 24.56batch/s, loss=3.81, metric=45]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-107-8da08e459f37>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   model, loss_train, metric_train = train_one_epoch(model,\n\u001b[0m\u001b[1;32m      7\u001b[0m                                                     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                                     \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-870050b25dc7>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_loader, loss_fn, optimizer, metric, epoch)\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m       \u001b[0mloss_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m       \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "experiment.end()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQ4Y-_Uc1bSk",
        "outputId": "9f857411-b4ed-41d2-9b56-916eb77aef2d"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : Base-Model\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/ft-azad/lm-awd-lstm/4919e87f14cd4f18ac925d0c393f074d\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss_train [14]   : (3.8577467093173246, 5.890382317533928)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss_valid [14]   : (4.8733019167171205, 5.337851555176977)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metric_train [14] : (47.358543395996094, 361.54278564453125)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metric_valid [14] : (130.7518768310547, 208.06472778320312)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name : Base-Model\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch_size    : 20\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clip          : 0.25\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embedding_dim : 300\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hidden_dim    : 512\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr            : 3\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum      : 0.9\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_layers    : 2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seq_len       : 35\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for metadata to finish uploading (timeout is 3600 seconds)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Uploading 2483 metrics, params and output messages\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "PxRYKNUC1hoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = 'model.pt'\n",
        "model = torch.load(model_path)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "uCTHcn7t1hWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_valid, metric_valid = evaluate(model, valid_loader, loss_fn, metric)\n",
        "metric_valid"
      ],
      "metadata": {
        "id": "ELNfyJcB1oPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_test, metric_test = evaluate(model, test_loader, loss_fn, metric)\n",
        "metric_test"
      ],
      "metadata": {
        "id": "RZ6UaE8N1pQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate"
      ],
      "metadata": {
        "id": "mez84S5y1roU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = 'model.pt'\n",
        "model = torch.load(model_path)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "tTXlQSO91wyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(prompt, max_seq_len, temperature, model, tokenizer, vocab, seed=None):\n",
        "\n",
        "  indices = vocab(tokenizer(prompt))\n",
        "  itos = vocab.get_itos()\n",
        "\n",
        "  for i in range(max_seq_len):\n",
        "    src = torch.LongTensor(indices).to(device)\n",
        "    with torch.no_grad():\n",
        "      prediction = model(src)\n",
        "\n",
        "    # Low values like 0.1 for temperature, Makes softmax like argmax more\n",
        "    probs = torch.softmax(prediction[-1]/temperature, dim = 0)\n",
        "    idx = vocab[\"<ukn>\"]\n",
        "    while idx == vocab[\"<ukn>\"]:\n",
        "      idx = torch.multinomial(probs, num_samples =1).item()\n",
        "    indices.append(idx)\n",
        "    prompt += \" \" + itos[idx]\n",
        "    # print(prompt)\n",
        "\n",
        "    if idx == vocab[\".\"]:\n",
        "      return prompt"
      ],
      "metadata": {
        "id": "v0JuNPDq15M7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"as i know about this subject,\"\n",
        "generate(prompt, 40, 0.5, model, tokenizer, vocab, seed=None)"
      ],
      "metadata": {
        "id": "I9zBXRrr2C2y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}