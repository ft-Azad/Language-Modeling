{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ft-Azad/Language-Modeling/blob/main/LanguageModel(AWD_LSTM).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiRseqOJtOMs"
      },
      "source": [
        "#  Import Libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1l3jplbsRcr"
      },
      "outputs": [],
      "source": [
        "!pip install -q torchmetrics\n",
        "!pip install -q torchdata==0.6.1\n",
        "!pip install -q 'portalocker>=2.0.0'\n",
        "!pip install -q torchtext==0.15.1\n",
        "!pip install -q comet_ml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YXPfyHdktUV2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torchtext\n",
        "from torchtext.datasets import WikiText2\n",
        "from torchdata.datapipes.iter import IterableWrapper, Mapper\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "\n",
        "from torch import optim\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import os\n",
        "import tqdm\n",
        "import torchmetrics as tm\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "from comet_ml import Experiment\n",
        "from comet_ml.integration.pytorch import log_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xed-F0ttyk6",
        "outputId": "57efccc4-c806-42d0-c5e8-6bb664b62f22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy --> 1.25.2\n",
            "torch --> 2.0.0+cu117\n",
            "torchtext --> 0.15.1+cpu\n",
            "tqdm --> 4.66.4\n"
          ]
        }
      ],
      "source": [
        "for lib in [np, torch, torchtext, tqdm]:\n",
        "  print(lib.__name__, '-->', lib.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtOFbjYdtuXS"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Y36SBwzHttlz"
      },
      "outputs": [],
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jvkD1SZDt1QU"
      },
      "outputs": [],
      "source": [
        "def num_trainable_params(model):\n",
        "  nums = sum(p.numel() for p in model.parameters() if p.requires_grad)/1e6\n",
        "  return nums"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mZwiS0r7t2qm"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  if torch.cuda.is_available():\n",
        "      torch.cuda.manual_seed(seed)\n",
        "      # torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "      # torch.backends.cudnn.deterministic = True\n",
        "      # torch.backends.cudnn.benchmark = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kou_xgQtuSKD"
      },
      "source": [
        "# Arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PSqJ0n_guXCL"
      },
      "outputs": [],
      "source": [
        "seed = 8\n",
        "\n",
        "batch_size = 80\n",
        "seq_len = 70\n",
        "\n",
        "embedding_dim = 400\n",
        "\n",
        "num_layers = 3\n",
        "hidden_dim = 1150\n",
        "dropout_embd = 0.5\n",
        "dropout_rnn = 0\n",
        "\n",
        "\n",
        "lr = 3\n",
        "wd = 1e-6\n",
        "momentum = 0.9\n",
        "\n",
        "clip = 0.25\n",
        "\n",
        "wandb_enable = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiM52d_Yt5vU"
      },
      "source": [
        "#Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMElZJWSt72c"
      },
      "source": [
        "## Load Dataset and Build Vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ma9kBZCJt9_M"
      },
      "source": [
        "- Loading Iterable Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlZif_l-t45M",
        "outputId": "5d649a7a-78ae-4bf9-e88c-7f32497f4b1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "NS6x1w4VuCkU"
      },
      "outputs": [],
      "source": [
        "!unzip -q \"/content/drive/MyDrive/LanguageModel/Data/wikitext-2-v1.zip\" -d '/content/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "S9jSpftfuD9K"
      },
      "outputs": [],
      "source": [
        "with open('/content/wikitext-2/wiki.train.tokens', 'r') as file:\n",
        "    train_iter = file.read().splitlines()\n",
        "\n",
        "with open('/content/wikitext-2/wiki.test.tokens', 'r') as file:\n",
        "    test_iter = file.read().splitlines()\n",
        "\n",
        "with open('/content/wikitext-2/wiki.valid.tokens', 'r') as file:\n",
        "    valid_iter = file.read().splitlines()\n",
        "\n",
        "train_iter = IterableWrapper(train_iter)\n",
        "test_iter = IterableWrapper(test_iter)\n",
        "valid_iter = IterableWrapper(valid_iter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNlDyqOwvItm"
      },
      "source": [
        "- Build Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "o4QNGKw4vQ2r"
      },
      "outputs": [],
      "source": [
        "tokenizer = get_tokenizer('basic_english')\n",
        "vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=['<unk>'])\n",
        "vocab.set_default_index(vocab['<unk>'])\n",
        "torch.save(vocab, 'vocab.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVsC0d1Qvt6E"
      },
      "source": [
        "## Dataset Prepreation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gEXdvicwTRj"
      },
      "source": [
        "- Creat Target Array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "i_FC_QFzvtcL"
      },
      "outputs": [],
      "source": [
        "def data_process(raw_text_iter, seq_len):\n",
        "  data = torch.cat([torch.LongTensor(vocab(tokenizer(line))) for line in raw_text_iter])\n",
        "\n",
        "  M = len(data) // seq_len\n",
        "\n",
        "  r = len(data) % seq_len\n",
        "  data = torch.cat((data, torch.LongTensor([0]))) if r==0 else data\n",
        "\n",
        "  inputs = data[:M*seq_len]\n",
        "  targets = data[1:M*seq_len+1]\n",
        "\n",
        "  inputs = inputs.reshape(-1, seq_len)\n",
        "  targets = targets.reshape(-1, seq_len)\n",
        "\n",
        "  return inputs, targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYP0TPqcvz_L",
        "outputId": "0e7b054c-ccff-4de6-b4a2-a69137742317"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([29285, 70]),\n",
              " torch.Size([29285, 70]),\n",
              " torch.Size([3063, 70]),\n",
              " torch.Size([3063, 70]),\n",
              " torch.Size([3455, 70]),\n",
              " torch.Size([3455, 70]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "X_train, y_train = data_process(train_iter, seq_len)\n",
        "X_valid, y_valid = data_process(valid_iter, seq_len)\n",
        "X_test, y_test = data_process(test_iter, seq_len)\n",
        "\n",
        "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape, X_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJbQ1Nh0wXyy"
      },
      "source": [
        "- Custom Dataset Class Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "BkQQ934CxF21"
      },
      "outputs": [],
      "source": [
        "class LanguageModelDataset(Dataset):\n",
        "\n",
        "  def __init__(self, inputs, targets):\n",
        "    self.inputs = inputs\n",
        "    self.targets = targets\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.inputs.shape[0]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.inputs[idx], self.targets[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "56QXULMExJJ9"
      },
      "outputs": [],
      "source": [
        "train_set = LanguageModelDataset(X_train, y_train)\n",
        "valid_set = LanguageModelDataset(X_valid, y_valid)\n",
        "test_set = LanguageModelDataset(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_QgbAMixKn7",
        "outputId": "fefb2fee-4c07-4458-9c4a-1f5f0bb386f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([    9,  3849,  3869,   881,     9, 20000,    83,  3849,    88,     0,\n",
              "          3869,    21,   780, 28780,     2,  6182,     3,  3849,     4,     1,\n",
              "          5023,    88,    20,     2,  1837,  1018,     7,    14,  3849,  3869,\n",
              "           881,   629,   976,     2,    23,     8,  5790,   299,    12,   575,\n",
              "           232,    67,   452,    19, 13722,     5,   757,     3,  2500,    17,\n",
              "             1,  1767,  5637,     3,   155,     6,   246,   354,     6,   976,\n",
              "             2,    24,    23,     1,   237,    67,     6,     1,  3849,    93]),\n",
              " tensor([ 3849,  3869,   881,     9, 20000,    83,  3849,    88,     0,  3869,\n",
              "            21,   780, 28780,     2,  6182,     3,  3849,     4,     1,  5023,\n",
              "            88,    20,     2,  1837,  1018,     7,    14,  3849,  3869,   881,\n",
              "           629,   976,     2,    23,     8,  5790,   299,    12,   575,   232,\n",
              "            67,   452,    19, 13722,     5,   757,     3,  2500,    17,     1,\n",
              "          1767,  5637,     3,   155,     6,   246,   354,     6,   976,     2,\n",
              "            24,    23,     1,   237,    67,     6,     1,  3849,    93,     3]))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "train_set[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZkza2MYxOnk"
      },
      "source": [
        "- Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "4gz_hP05xRt8"
      },
      "outputs": [],
      "source": [
        "set_seed(seed)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQ1eIKZLxUOz",
        "outputId": "38194bee-f7a2-40e0-9feb-795bc4a7d312"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([80, 70]), torch.Size([80, 70]))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "x_batch, y_batch = next(iter(train_loader))\n",
        "x_batch.shape, y_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwbPWDxTxvrO",
        "outputId": "d5b94ba2-92e1-4556-cf17-8757a2b4532c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1985) tensor(13)\n"
          ]
        }
      ],
      "source": [
        "set_seed(seed)\n",
        "\n",
        "for inputs, targets in train_loader:\n",
        "  print(inputs[0, 0], targets[0, 0])\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMYLSVQWx2W8"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "vdlAzoEcx2FM"
      },
      "outputs": [],
      "source": [
        "class LanguageModel(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers,\n",
        "                dropout_embd=0.5, dropout_rnn=0.5):\n",
        "    super().__init__()\n",
        "    self.num_layers = num_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.embedding_dim = embedding_dim\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.embedding.weight.data.uniform_(-0.1, 0.1)\n",
        "    self.dropout = nn.Dropout(p=dropout_embd)\n",
        "\n",
        "    self.lstms = []\n",
        "    self.lstms.append(nn.LSTM(embedding_dim, hidden_dim, num_layers=1, dropout=0, batch_first=True))\n",
        "    self.lstms.append(nn.LSTM(hidden_dim, hidden_dim, num_layers=1, dropout=0, batch_first=True))\n",
        "    self.lstms.append(nn.LSTM(hidden_dim, embedding_dim, num_layers=1, dropout=0, batch_first=True))\n",
        "    self.lstms = nn.ModuleList(self.lstms)\n",
        "\n",
        "    self.fc = nn.Linear(embedding_dim, vocab_size)\n",
        "\n",
        "    self.fc.weight = self.embedding.weight\n",
        "\n",
        "  def forward(self, src):\n",
        "    embedding = self.dropout(self.embedding(src))\n",
        "\n",
        "    # new_hiddens = []\n",
        "    for l, lstm in enumerate(self.lstms):\n",
        "      embedding, _ = lstm(embedding)\n",
        "\n",
        "    prediction = self.fc(embedding)\n",
        "    return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJotksm3x-cU",
        "outputId": "7f1100cb-2817-4f94-9008-0000adcb9442"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageModel(\n",
              "  (embedding): Embedding(28782, 400)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (lstms): ModuleList(\n",
              "    (0): LSTM(400, 1150, batch_first=True)\n",
              "    (1): LSTM(1150, 1150, batch_first=True)\n",
              "    (2): LSTM(1150, 400, batch_first=True)\n",
              "  )\n",
              "  (fc): Linear(in_features=400, out_features=28782, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "set_seed(seed)\n",
        "\n",
        "model = LanguageModel(vocab_size=len(vocab),\n",
        "                      embedding_dim=embedding_dim,\n",
        "                      hidden_dim=hidden_dim,\n",
        "                      num_layers=num_layers,\n",
        "                      dropout_embd=dropout_embd,\n",
        "                      dropout_rnn=dropout_rnn)\n",
        "model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNdI-5pVyOKk"
      },
      "source": [
        "# Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "PGCd-Dm-yNhM",
        "outputId": "f2566e4f-c027-4d6a-8b2d-1929a44ee236"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "hd19NFFNyUFk"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "metric = tm.text.Perplexity().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "_6Oy3pH0RgAt"
      },
      "outputs": [],
      "source": [
        "key_file = \"/content/drive/MyDrive/LanguageModel/key.txt\"\n",
        "\n",
        "if os.path.exists(key_file):\n",
        "    with open(key_file) as f:\n",
        "        key = f.readline().strip()\n",
        "else:\n",
        "    print(\"Key file does not exist. Please create the key file with your wandb API key.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfY7_5XZc4qk",
        "outputId": "c091df18-ddd2-4632-c454-91084cf39531"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please input the WandB argument (run) name:Weight-Tying\n"
          ]
        }
      ],
      "source": [
        "wandb_arg_name = input('Please input the WandB argument (run) name:')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "_APSWaGyc5Iw"
      },
      "outputs": [],
      "source": [
        "# comet_ml.init(project_name=\"LM_AWD-LSTM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAsopugofMzN",
        "outputId": "e1f1280a-a7cd-4a43-b2ca-75084652c7f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/ft-azad/lm-awd-lstm/10b4fa44a0994699add9a22de50af0ba\n",
            "\n"
          ]
        }
      ],
      "source": [
        "experiment = Experiment(\n",
        "  api_key=key,\n",
        "  project_name=\"LM_AWD-LSTM\",\n",
        ")\n",
        "experiment.set_name(wandb_arg_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_1sWWHVy7Kk"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxTkh6JGy9Kj"
      },
      "source": [
        "## Train and Evaluate Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "v1dAZfqLy850"
      },
      "outputs": [],
      "source": [
        "# Train Functions\n",
        "def train_one_epoch(model, train_loader, loss_fn, optimizer, metric, epoch=None):\n",
        "  model.train()\n",
        "  loss_train = AverageMeter()\n",
        "  metric.reset()\n",
        "\n",
        "  with tqdm.tqdm(train_loader, unit='batch') as tepoch:\n",
        "    for inputs, targets in tepoch:\n",
        "      if epoch:\n",
        "        tepoch.set_description(f'Epoch {epoch}')\n",
        "\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      loss = loss_fn(outputs.reshape(-1, outputs.shape[-1]), targets.flatten())\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      nn.utils.clip_grad.clip_grad_norm_(model.parameters(), max_norm=clip)\n",
        "\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      loss_train.update(loss.item(), n=len(targets))\n",
        "      metric.update(outputs, targets)\n",
        "\n",
        "      tepoch.set_postfix(loss=loss_train.avg, metric=metric.compute().item())\n",
        "\n",
        "  return model, loss_train.avg, metric.compute().item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ma-DFi9XzE1s"
      },
      "outputs": [],
      "source": [
        "# Evaluate Function\n",
        "def evaluate(model, test_loader, loss_fn, metric):\n",
        "  model.eval()\n",
        "  loss_eval = AverageMeter()\n",
        "  metric.reset()\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for inputs, targets in test_loader:\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      loss = loss_fn(outputs.reshape(-1, outputs.shape[-1]), targets.flatten())\n",
        "      loss_eval.update(loss.item(), n=len(targets))\n",
        "\n",
        "      metric(outputs, targets)\n",
        "\n",
        "  return loss_eval.avg, metric.compute().item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKkW_4FBz1ac"
      },
      "source": [
        "## Train Process and Tunning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FYTauriz3RL"
      },
      "source": [
        "### Finding Hyper-parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaPsJriFz4i7"
      },
      "source": [
        "- Calculating the loss for untrained model using a few batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIebaKmbz5xj",
        "outputId": "4ab612a6-f559-475f-e2b0-c1a9ea7320e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(10.2711, device='cuda:0')\n",
            "tensor(10.2717, device='cuda:0')\n",
            "tensor(10.2653, device='cuda:0')\n",
            "tensor(10.2671, device='cuda:0')\n",
            "tensor(10.2690, device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "for iter_num in range(5):\n",
        "  model = LanguageModel(len(vocab), embedding_dim=embedding_dim,\n",
        "                      hidden_dim=hidden_dim, num_layers=num_layers,\n",
        "                      dropout_embd=dropout_embd, dropout_rnn=dropout_rnn).to(device)\n",
        "\n",
        "  inputs, targets = next(iter(train_loader))\n",
        "  inputs = inputs.to(device)\n",
        "  targets = targets.to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    outputs = model(inputs)\n",
        "    loss = loss_fn(outputs.reshape(-1, outputs.shape[-1]), targets.flatten())\n",
        "\n",
        "  print(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14lWNR0Jz8VQ"
      },
      "source": [
        "- Train and try to overfit the model on a small subset of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pg26Lvdb0G8I"
      },
      "outputs": [],
      "source": [
        "model = LanguageModel(len(vocab), embedding_dim=embedding_dim,\n",
        "                      hidden_dim=hidden_dim, num_layers=num_layers,\n",
        "                      dropout_embd=dropout_embd, dropout_rnn=dropout_rnn).to(device)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.9, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2XIZjef0IG5"
      },
      "outputs": [],
      "source": [
        "mini_train_size = 1000\n",
        "_, mini_train_dataset = random_split(train_set, (len(train_set)-mini_train_size, mini_train_size))\n",
        "mini_train_loader = DataLoader(mini_train_dataset, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VEtGlnyl0JHy",
        "outputId": "3b64a994-8e4f-4ffa-e410-4dd711a0079c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:01<00:00, 26.48batch/s, loss=8.33, metric=4.15e+3]\n",
            "Epoch 1: 100%|██████████| 50/50 [00:01<00:00, 25.97batch/s, loss=7.18, metric=1.31e+3]\n",
            "Epoch 2: 100%|██████████| 50/50 [00:01<00:00, 25.92batch/s, loss=7, metric=1.1e+3]\n",
            "Epoch 3: 100%|██████████| 50/50 [00:01<00:00, 25.80batch/s, loss=6.93, metric=1.02e+3]\n",
            "Epoch 4: 100%|██████████| 50/50 [00:01<00:00, 25.78batch/s, loss=6.84, metric=937]\n",
            "Epoch 5: 100%|██████████| 50/50 [00:01<00:00, 25.14batch/s, loss=6.72, metric=832]\n",
            "Epoch 6: 100%|██████████| 50/50 [00:02<00:00, 24.81batch/s, loss=6.61, metric=740]\n",
            "Epoch 7: 100%|██████████| 50/50 [00:01<00:00, 25.30batch/s, loss=6.51, metric=672]\n",
            "Epoch 8: 100%|██████████| 50/50 [00:01<00:00, 25.30batch/s, loss=6.43, metric=619]\n",
            "Epoch 9: 100%|██████████| 50/50 [00:01<00:00, 25.16batch/s, loss=6.35, metric=572]\n",
            "Epoch 10: 100%|██████████| 50/50 [00:01<00:00, 25.14batch/s, loss=6.27, metric=529]\n",
            "Epoch 11: 100%|██████████| 50/50 [00:01<00:00, 25.29batch/s, loss=6.2, metric=493]\n",
            "Epoch 12: 100%|██████████| 50/50 [00:02<00:00, 24.81batch/s, loss=6.12, metric=456]\n",
            "Epoch 13: 100%|██████████| 50/50 [00:02<00:00, 24.73batch/s, loss=6.05, metric=426]\n",
            "Epoch 14: 100%|██████████| 50/50 [00:02<00:00, 24.76batch/s, loss=5.98, metric=396]\n",
            "Epoch 15: 100%|██████████| 50/50 [00:02<00:00, 24.74batch/s, loss=5.91, metric=367]\n",
            "Epoch 16: 100%|██████████| 50/50 [00:02<00:00, 24.94batch/s, loss=5.83, metric=339]\n",
            "Epoch 17: 100%|██████████| 50/50 [00:01<00:00, 25.20batch/s, loss=5.74, metric=312]\n",
            "Epoch 18: 100%|██████████| 50/50 [00:01<00:00, 25.08batch/s, loss=5.65, metric=283]\n",
            "Epoch 19: 100%|██████████| 50/50 [00:02<00:00, 24.73batch/s, loss=5.55, metric=257]\n",
            "Epoch 20: 100%|██████████| 50/50 [00:02<00:00, 24.73batch/s, loss=5.45, metric=234]\n",
            "Epoch 21: 100%|██████████| 50/50 [00:02<00:00, 24.90batch/s, loss=5.36, metric=213]\n",
            "Epoch 22: 100%|██████████| 50/50 [00:01<00:00, 25.25batch/s, loss=5.27, metric=194]\n",
            "Epoch 23: 100%|██████████| 50/50 [00:01<00:00, 25.29batch/s, loss=5.18, metric=178]\n",
            "Epoch 24: 100%|██████████| 50/50 [00:01<00:00, 25.29batch/s, loss=5.09, metric=162]\n",
            "Epoch 25: 100%|██████████| 50/50 [00:01<00:00, 25.38batch/s, loss=4.99, metric=146]\n",
            "Epoch 26: 100%|██████████| 50/50 [00:01<00:00, 25.51batch/s, loss=4.88, metric=132]\n",
            "Epoch 27: 100%|██████████| 50/50 [00:02<00:00, 24.77batch/s, loss=4.79, metric=121]\n",
            "Epoch 28: 100%|██████████| 50/50 [00:02<00:00, 24.55batch/s, loss=4.69, metric=109]\n",
            "Epoch 29: 100%|██████████| 50/50 [00:01<00:00, 25.48batch/s, loss=4.57, metric=97]\n",
            "Epoch 30: 100%|██████████| 50/50 [00:01<00:00, 25.48batch/s, loss=4.45, metric=86]\n",
            "Epoch 31: 100%|██████████| 50/50 [00:01<00:00, 25.58batch/s, loss=4.34, metric=76.5]\n",
            "Epoch 32: 100%|██████████| 50/50 [00:01<00:00, 25.46batch/s, loss=4.23, metric=68.8]\n",
            "Epoch 33: 100%|██████████| 50/50 [00:01<00:00, 25.51batch/s, loss=4.13, metric=62]\n",
            "Epoch 34: 100%|██████████| 50/50 [00:02<00:00, 24.97batch/s, loss=4.02, metric=55.6]\n",
            "Epoch 35: 100%|██████████| 50/50 [00:01<00:00, 25.13batch/s, loss=3.93, metric=51.1]\n",
            "Epoch 36: 100%|██████████| 50/50 [00:01<00:00, 25.71batch/s, loss=3.85, metric=47]\n",
            "Epoch 37: 100%|██████████| 50/50 [00:01<00:00, 25.54batch/s, loss=3.75, metric=42.7]\n",
            "Epoch 38: 100%|██████████| 50/50 [00:01<00:00, 25.13batch/s, loss=3.67, metric=39.2]\n",
            "Epoch 39: 100%|██████████| 50/50 [00:01<00:00, 25.34batch/s, loss=3.61, metric=37]\n",
            "Epoch 40: 100%|██████████| 50/50 [00:01<00:00, 25.20batch/s, loss=3.55, metric=34.8]\n",
            "Epoch 41: 100%|██████████| 50/50 [00:01<00:00, 25.27batch/s, loss=3.45, metric=31.5]\n",
            "Epoch 42: 100%|██████████| 50/50 [00:02<00:00, 24.61batch/s, loss=3.36, metric=28.7]\n",
            "Epoch 43: 100%|██████████| 50/50 [00:02<00:00, 24.40batch/s, loss=3.25, metric=25.7]\n",
            "Epoch 44: 100%|██████████| 50/50 [00:02<00:00, 24.98batch/s, loss=3.12, metric=22.7]\n",
            "Epoch 45: 100%|██████████| 50/50 [00:01<00:00, 25.05batch/s, loss=3.01, metric=20.2]\n",
            "Epoch 46: 100%|██████████| 50/50 [00:01<00:00, 25.55batch/s, loss=2.87, metric=17.6]\n",
            "Epoch 47: 100%|██████████| 50/50 [00:01<00:00, 25.45batch/s, loss=2.75, metric=15.6]\n",
            "Epoch 48: 100%|██████████| 50/50 [00:01<00:00, 25.30batch/s, loss=2.64, metric=14.1]\n",
            "Epoch 49: 100%|██████████| 50/50 [00:01<00:00, 25.07batch/s, loss=2.55, metric=12.7]\n",
            "Epoch 50: 100%|██████████| 50/50 [00:01<00:00, 25.28batch/s, loss=2.46, metric=11.8]\n",
            "Epoch 51: 100%|██████████| 50/50 [00:01<00:00, 25.60batch/s, loss=2.41, metric=11.2]\n",
            "Epoch 52: 100%|██████████| 50/50 [00:01<00:00, 25.61batch/s, loss=2.33, metric=10.3]\n",
            "Epoch 53: 100%|██████████| 50/50 [00:01<00:00, 25.33batch/s, loss=2.25, metric=9.44]\n",
            "Epoch 54: 100%|██████████| 50/50 [00:01<00:00, 25.53batch/s, loss=2.14, metric=8.54]\n",
            "Epoch 55: 100%|██████████| 50/50 [00:01<00:00, 25.22batch/s, loss=2.05, metric=7.77]\n",
            "Epoch 56:  62%|██████▏   | 31/50 [00:01<00:00, 24.28batch/s, loss=1.98, metric=7.23]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-7579defe06ba>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-29-870050b25dc7>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_loader, loss_fn, optimizer, metric, epoch)\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m       \u001b[0mloss_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m       \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "  model, _, _ = train_one_epoch(model, mini_train_loader, loss_fn, optimizer, metric, epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfegeAIT0L70"
      },
      "source": [
        "-  Train the model for a limited number of epochs, experimenting with various learning rates to find best value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "OZDUK09T0VGO",
        "outputId": "004e1f99-1068-49b3-9b8a-83e69b1307ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LR=12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2929/2929 [01:55<00:00, 25.42batch/s, loss=5.98, metric=394]\n",
            "Epoch 1:  90%|████████▉ | 2624/2929 [01:47<00:12, 24.32batch/s, loss=5.65, metric=284]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-f9cf261326ce>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-870050b25dc7>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_loader, loss_fn, optimizer, metric, epoch)\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m       \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouped_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforeach\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mforeach\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_has_foreach_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_mul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_coef_clamped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-overload]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mforeach\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'foreach=True was passed, but can\\'t use the foreach API on {device.type} tensors'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "num_epochs = 2\n",
        "\n",
        "for lr in [12, 8, 4, 2, 0.9]:\n",
        "  print(f'LR={lr}')\n",
        "\n",
        "  model = LanguageModel(len(vocab), embedding_dim=embedding_dim,\n",
        "                        hidden_dim=hidden_dim, num_layers=num_layers,\n",
        "                        dropout_embd=dropout_embd, dropout_rnn=dropout_rnn).to(device)\n",
        "  # model = torch.load('model.pt')\n",
        "\n",
        "  optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=momentum)\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    model, _, _ = train_one_epoch(model, train_loader, loss_fn, optimizer, metric, epoch)\n",
        "\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-dy-qYP0Zwd"
      },
      "source": [
        "- Creat a small grid search to find exact value of lr and weight decay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyxZLxkm0drG"
      },
      "outputs": [],
      "source": [
        "num_epochs = 1\n",
        "\n",
        "for lr in [7, 8, 14, 13, 12, 11, 10, 9]:\n",
        "  for wd in [1.2e-6]:\n",
        "    print(f'LR={lr}, WD={wd}')\n",
        "\n",
        "    model = LanguageModel(len(vocab), embedding_dim=embedding_dim,\n",
        "                      hidden_dim=hidden_dim, num_layers=num_layers,\n",
        "                      dropout_embd=dropout_embd, dropout_rnn=dropout_rnn).to(device)\n",
        "\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=0.9)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      model, _, _ = train_one_epoch(model, train_loader, loss_fn, optimizer, metric, epoch)\n",
        "\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ3Q1xfn0jft"
      },
      "source": [
        "- Train model for more epochs using the best hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUxTmYsn0lK-",
        "outputId": "8c5cf7df-80a3-4449-a4c3-6130942b8dde"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LanguageModel(\n",
              "  (embedding): Embedding(28782, 300)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (lstm): LSTM(300, 512, num_layers=2, batch_first=True, dropout=0.2)\n",
              "  (fc): Linear(in_features=512, out_features=28782, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = LanguageModel(len(vocab), embedding_dim=embedding_dim,\n",
        "                      hidden_dim=hidden_dim, num_layers=num_layers,\n",
        "                      dropout_embd=dropout_embd, dropout_rnn=dropout_rnn).to(device)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "0yA4xkdo0pg1",
        "outputId": "63c94ccf-65d9-4b11-f715-8ccd1426c3d3"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/model-ppl_133.pt'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-6ef75991a85f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/model-ppl_133.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/model-ppl_133.pt'"
          ]
        }
      ],
      "source": [
        "model = torch.load('/content/model-ppl_133.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsBrL69h0q89",
        "outputId": "90a0c044-163e-42fc-dc10-fc91d667d29a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SGD (\n",
              "Parameter Group 0\n",
              "    dampening: 0\n",
              "    differentiable: False\n",
              "    foreach: None\n",
              "    lr: 8\n",
              "    maximize: False\n",
              "    momentum: 0.9\n",
              "    nesterov: False\n",
              "    weight_decay: 1e-06\n",
              ")"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lr = 8\n",
        "wd = 1e-6\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=0.9)\n",
        "optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8LL1uHv0sSN"
      },
      "outputs": [],
      "source": [
        "loss_train_hist = []\n",
        "loss_valid_hist = []\n",
        "\n",
        "metric_train_hist = []\n",
        "metric_valid_hist = []\n",
        "\n",
        "best_loss_valid = torch.inf\n",
        "epoch_counter = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 769
        },
        "id": "KqRODsU90wKV",
        "outputId": "00489a5f-cb0e-4aef-ed47-aaa1b7dcccea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 2929/2929 [01:59<00:00, 24.46batch/s, loss=5.88, metric=360]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 6.046, Metric = 422.9\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 2929/2929 [01:59<00:00, 24.49batch/s, loss=5.24, metric=188]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 6.027, Metric = 414.9\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|██████████| 2929/2929 [01:59<00:00, 24.48batch/s, loss=4.96, metric=143]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid: Loss = 6.042, Metric = 421.1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|██████████| 2929/2929 [01:59<00:00, 24.52batch/s, loss=4.78, metric=119]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid: Loss = 6.064, Metric = 430.6\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5: 100%|██████████| 2929/2929 [01:59<00:00, 24.45batch/s, loss=4.65, metric=105]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid: Loss = 6.068, Metric = 432.1\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6:  40%|████      | 1177/2929 [00:48<01:11, 24.51batch/s, loss=4.5, metric=90]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-ed6d696242c2>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   model, loss_train, metric_train = train_one_epoch(model,\n\u001b[0m\u001b[1;32m     14\u001b[0m                                                     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                                                     \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-870050b25dc7>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_loader, loss_fn, optimizer, metric, epoch)\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m       \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouped_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforeach\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mforeach\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_has_foreach_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_mul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_coef_clamped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-overload]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mforeach\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'foreach=True was passed, but can\\'t use the foreach API on {device.type} tensors'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "num_epochs = 30\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "  # WandB\n",
        "  # run = wandb.init(\n",
        "  #       project=\"language-modeling-lstms\",\n",
        "  #       config={\n",
        "  #           \"learning_rate\": lr,\n",
        "  #           \"epochs\": num_epochs,\n",
        "  #       })\n",
        "\n",
        "  # Train\n",
        "  model, loss_train, metric_train = train_one_epoch(model,\n",
        "                                                    train_loader,\n",
        "                                                    loss_fn,\n",
        "                                                    optimizer,\n",
        "                                                    metric,\n",
        "                                                    epoch)\n",
        "  # Validation\n",
        "  loss_valid, metric_valid = evaluate(model,\n",
        "                                      valid_loader,\n",
        "                                      loss_fn,\n",
        "                                      metric)\n",
        "\n",
        "  loss_train_hist.append(loss_train)\n",
        "  loss_valid_hist.append(loss_valid)\n",
        "\n",
        "  metric_train_hist.append(metric_train)\n",
        "  metric_valid_hist.append(metric_valid)\n",
        "\n",
        "  if loss_valid < best_loss_valid:\n",
        "    torch.save(model, f'model.pt')\n",
        "    best_loss_valid = loss_valid\n",
        "    print('Model Saved!')\n",
        "\n",
        "  print(f'Valid: Loss = {loss_valid:.4}, Metric = {metric_valid:.4}')\n",
        "  print()\n",
        "\n",
        "  epoch_counter += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V-sSI1-02P9"
      },
      "source": [
        "### Main Train Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "-H0Trq9804lf"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "6eu3JG-706fn"
      },
      "outputs": [],
      "source": [
        "set_seed(seed)\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFu74yBI08c9",
        "outputId": "b4ec192b-f8c1-44c1-d8dc-c1c5fa9b73ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageModel(\n",
              "  (embedding): Embedding(28782, 400)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (lstms): ModuleList(\n",
              "    (0): LSTM(400, 1150, batch_first=True)\n",
              "    (1): LSTM(1150, 1150, batch_first=True)\n",
              "    (2): LSTM(1150, 400, batch_first=True)\n",
              "  )\n",
              "  (fc): Linear(in_features=400, out_features=28782, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "set_seed(seed)\n",
        "\n",
        "model = LanguageModel(len(vocab), embedding_dim=embedding_dim,\n",
        "                      hidden_dim=hidden_dim, num_layers=num_layers,\n",
        "                      dropout_embd=dropout_embd, dropout_rnn=dropout_rnn).to(device)\n",
        "\n",
        "# model = LanguageModel(vocab_size=len(vocab), embedding_dim=embedding_dim,\n",
        "#                       hidden_dim=hidden_dim, num_layers=num_layers,\n",
        "#                       dropoute=dropoute, dropouti=dropouti,\n",
        "#                       dropouth=dropouth, dropouto=dropouto,\n",
        "#                       weight_drop=weight_drop, pretrained=pretrained).to(device)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "spHIVlf_1I_5"
      },
      "outputs": [],
      "source": [
        "model = torch.load('model.pt')\n",
        "# epoch_counter = best_epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "AskOAQl1HQXI",
        "outputId": "2be0560f-a324-403b-f00e-acef53b07edf"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/LanguageModel/model-ppl130.8.pt'"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "shutil.copyfile(\"model-ppl130.8.pt\", \"/content/drive/MyDrive/LanguageModel/model-ppl130.8.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ys-oQE1F1Obg",
        "outputId": "678c3404-af4e-4458-ef6b-1df3243ad599"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGD (\n",
              "Parameter Group 0\n",
              "    dampening: 0\n",
              "    differentiable: False\n",
              "    foreach: None\n",
              "    lr: 1.25\n",
              "    maximize: False\n",
              "    momentum: 0.9\n",
              "    nesterov: False\n",
              "    weight_decay: 1e-06\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "set_seed(seed)\n",
        "\n",
        "lr = 1.25\n",
        "wd = 1e-6\n",
        "# momentum = 0.9\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=momentum)\n",
        "# optimizer = optim.SGD([{'params': model.embedding.parameters(), 'lr': 0.1*lr},\n",
        "#                        {'params': model.lstms.parameters(), 'lr': lr}],\n",
        "#                       weight_decay=wd, momentum=momentum)\n",
        "optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "Jgfektma1RUo"
      },
      "outputs": [],
      "source": [
        "if wandb_enable:\n",
        "\n",
        "      config={\n",
        "          'lr': lr,\n",
        "          'momentum': momentum,\n",
        "          'batch_size': batch_size,\n",
        "          'seq_len': seq_len,\n",
        "          'hidden_dim': hidden_dim,\n",
        "          'embedding_dim': embedding_dim,\n",
        "          'num_layers': num_layers,\n",
        "          'dropout_embd': dropout_embd,\n",
        "          'dropout_rnn': dropout_rnn,\n",
        "          # 'dropout_embed': dropoute,\n",
        "          # 'dropout_in_lstm': dropouti,\n",
        "          # 'dropout_h_lstm': dropouth,\n",
        "          # 'dropout_out_lstm': dropouto,\n",
        "          'clip': clip,\n",
        "      }\n",
        "\n",
        "      experiment.log_parameters(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "_BTiIsVt1Vc9"
      },
      "outputs": [],
      "source": [
        "loss_train_hist = []\n",
        "loss_valid_hist = []\n",
        "\n",
        "metric_train_hist = []\n",
        "metric_valid_hist = []\n",
        "\n",
        "best_loss_valid = torch.inf\n",
        "epoch_counter = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLMefkng1X32",
        "outputId": "13d3b7c4-819f-4e2e-f7cc-33f4479b7651"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 367/367 [02:34<00:00,  2.37batch/s, loss=4.04, metric=56.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 4.73, Metric = 113.3\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 367/367 [02:34<00:00,  2.37batch/s, loss=3.93, metric=50.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 4.74, Metric = 114.4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 367/367 [02:35<00:00,  2.37batch/s, loss=3.86, metric=47.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 4.754, Metric = 116.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 367/367 [02:34<00:00,  2.37batch/s, loss=3.8, metric=44.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 4.769, Metric = 117.8\n",
            "\n"
          ]
        }
      ],
      "source": [
        "set_seed(seed)\n",
        "num_epochs = 4\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "  # Train\n",
        "  model, loss_train, metric_train = train_one_epoch(model,\n",
        "                                                    train_loader,\n",
        "                                                    loss_fn,\n",
        "                                                    optimizer,\n",
        "                                                    metric,\n",
        "                                                    epoch)\n",
        "  # Validation\n",
        "  loss_valid, metric_valid = evaluate(model,\n",
        "                                      valid_loader,\n",
        "                                      loss_fn,\n",
        "                                      metric)\n",
        "\n",
        "  loss_train_hist.append(loss_train)\n",
        "  loss_valid_hist.append(loss_valid)\n",
        "\n",
        "  metric_train_hist.append(metric_train)\n",
        "  metric_valid_hist.append(metric_valid)\n",
        "\n",
        "  if loss_valid < best_loss_valid:\n",
        "    torch.save(model, f'model.pt')\n",
        "    best_loss_valid = loss_valid\n",
        "    best_epoch = epoch_counter\n",
        "    print('Model Saved!')\n",
        "\n",
        "  print(f'Valid: Loss = {loss_valid:.4}, Metric = {metric_valid:.4}')\n",
        "  print()\n",
        "\n",
        "  if wandb_enable:\n",
        "    experiment.log_metrics({\"metric_train\": metric_train, \"loss_train\": loss_train,\n",
        "                \"metric_valid\": metric_valid, \"loss_valid\": loss_valid}, epoch=epoch_counter)\n",
        "\n",
        "  epoch_counter += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQ4Y-_Uc1bSk",
        "outputId": "0f359ae0-1894-4137-e423-8390d422560d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : Weight-Tying\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/ft-azad/lm-awd-lstm/10b4fa44a0994699add9a22de50af0ba\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss_train [14]   : (3.7961325479363834, 6.5045131098314295)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss_valid [14]   : (4.729722857747714, 5.689316993984879)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metric_train [14] : (44.528602600097656, 668.1500854492188)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metric_valid [14] : (113.26423645019531, 295.691650390625)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name : Weight-Tying\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch_size    : 80\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clip          : 0.25\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout_embd  : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout_rnn   : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embedding_dim : 400\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hidden_dim    : 1150\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr            : 7.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum      : 0.9\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_layers    : 3\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seq_len       : 70\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n"
          ]
        }
      ],
      "source": [
        "experiment.end()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxRYKNUC1hoe"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCTHcn7t1hWO"
      },
      "outputs": [],
      "source": [
        "model_path = 'model.pt'\n",
        "model = torch.load(model_path)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELNfyJcB1oPN"
      },
      "outputs": [],
      "source": [
        "loss_valid, metric_valid = evaluate(model, valid_loader, loss_fn, metric)\n",
        "metric_valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZ6UaE8N1pQl"
      },
      "outputs": [],
      "source": [
        "loss_test, metric_test = evaluate(model, test_loader, loss_fn, metric)\n",
        "metric_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mez84S5y1roU"
      },
      "source": [
        "# Generate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTXlQSO91wyl"
      },
      "outputs": [],
      "source": [
        "model_path = 'model.pt'\n",
        "model = torch.load(model_path)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0JuNPDq15M7"
      },
      "outputs": [],
      "source": [
        "def generate(prompt, max_seq_len, temperature, model, tokenizer, vocab, seed=None):\n",
        "\n",
        "  indices = vocab(tokenizer(prompt))\n",
        "  itos = vocab.get_itos()\n",
        "\n",
        "  for i in range(max_seq_len):\n",
        "    src = torch.LongTensor(indices).to(device)\n",
        "    with torch.no_grad():\n",
        "      prediction = model(src)\n",
        "\n",
        "    # Low values like 0.1 for temperature, Makes softmax like argmax more\n",
        "    probs = torch.softmax(prediction[-1]/temperature, dim = 0)\n",
        "    idx = vocab[\"<ukn>\"]\n",
        "    while idx == vocab[\"<ukn>\"]:\n",
        "      idx = torch.multinomial(probs, num_samples =1).item()\n",
        "    indices.append(idx)\n",
        "    prompt += \" \" + itos[idx]\n",
        "    # print(prompt)\n",
        "\n",
        "    if idx == vocab[\".\"]:\n",
        "      return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9zBXRrr2C2y"
      },
      "outputs": [],
      "source": [
        "prompt = \"as i know about this subject,\"\n",
        "generate(prompt, 40, 0.5, model, tokenizer, vocab, seed=None)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "xtOFbjYdtuXS"
      ],
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}