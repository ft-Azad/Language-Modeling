{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ft-Azad/Language-Modeling/blob/main/LanguageModel(AWD_LSTM).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiRseqOJtOMs"
      },
      "source": [
        "#  Import Libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1l3jplbsRcr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f125033a-d4c0-4de1-826c-58d758f85458"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.3.0+cu121 requires torch==2.3.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.18.0+cu121 requires torch==2.3.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m107.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.3.0+cu121 requires torch==2.3.0, but you have torch 2.0.0 which is incompatible.\n",
            "torchvision 0.18.0+cu121 requires torch==2.3.0, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m675.8/675.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.1/296.1 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m979.1/979.1 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q torchmetrics\n",
        "!pip install -q torchdata==0.6.1\n",
        "!pip install -q 'portalocker>=2.0.0'\n",
        "!pip install -q torchtext==0.15.1\n",
        "!pip install -q comet_ml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXPfyHdktUV2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torchtext\n",
        "from torchtext.datasets import WikiText2\n",
        "from torchdata.datapipes.iter import IterableWrapper, Mapper\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "\n",
        "from torch import optim\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import os\n",
        "import tqdm\n",
        "import torchmetrics as tm\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "from comet_ml import Experiment\n",
        "from comet_ml.integration.pytorch import log_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xed-F0ttyk6",
        "outputId": "2463ec73-8f81-4b96-ac37-7ebec5d7e803"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy --> 1.25.2\n",
            "torch --> 2.0.0+cu117\n",
            "torchtext --> 0.15.1+cpu\n",
            "tqdm --> 4.66.4\n"
          ]
        }
      ],
      "source": [
        "for lib in [np, torch, torchtext, tqdm]:\n",
        "  print(lib.__name__, '-->', lib.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtOFbjYdtuXS"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y36SBwzHttlz"
      },
      "outputs": [],
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvkD1SZDt1QU"
      },
      "outputs": [],
      "source": [
        "def num_trainable_params(model):\n",
        "  nums = sum(p.numel() for p in model.parameters() if p.requires_grad)/1e6\n",
        "  return nums"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZwiS0r7t2qm"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  if torch.cuda.is_available():\n",
        "      torch.cuda.manual_seed(seed)\n",
        "      # torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "      # torch.backends.cudnn.deterministic = True\n",
        "      # torch.backends.cudnn.benchmark = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kou_xgQtuSKD"
      },
      "source": [
        "# Arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSqJ0n_guXCL"
      },
      "outputs": [],
      "source": [
        "seed = 8\n",
        "\n",
        "batch_size = 80\n",
        "seq_len = 70\n",
        "\n",
        "embedding_dim = 400\n",
        "\n",
        "num_layers = 3\n",
        "hidden_dim = 1150\n",
        "# dropout_embd = 0.5\n",
        "# dropout_rnn = 0\n",
        "dropoute = 0.1\n",
        "dropouti = 0.65\n",
        "dropouth = 0.3\n",
        "dropouto = 0.4\n",
        "\n",
        "\n",
        "lr = 3\n",
        "wd = 1e-6\n",
        "momentum = 0.9\n",
        "\n",
        "clip = 0.25\n",
        "\n",
        "wandb_enable = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiM52d_Yt5vU"
      },
      "source": [
        "#Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMElZJWSt72c"
      },
      "source": [
        "## Load Dataset and Build Vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ma9kBZCJt9_M"
      },
      "source": [
        "- Loading Iterable Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlZif_l-t45M",
        "outputId": "adea608d-92c0-4a77-bf18-a311fa9ef897"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NS6x1w4VuCkU"
      },
      "outputs": [],
      "source": [
        "!unzip -q \"/content/drive/MyDrive/LanguageModel/Data/wikitext-2-v1.zip\" -d '/content/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9jSpftfuD9K"
      },
      "outputs": [],
      "source": [
        "with open('/content/wikitext-2/wiki.train.tokens', 'r') as file:\n",
        "    train_iter = file.read().splitlines()\n",
        "\n",
        "with open('/content/wikitext-2/wiki.test.tokens', 'r') as file:\n",
        "    test_iter = file.read().splitlines()\n",
        "\n",
        "with open('/content/wikitext-2/wiki.valid.tokens', 'r') as file:\n",
        "    valid_iter = file.read().splitlines()\n",
        "\n",
        "train_iter = IterableWrapper(train_iter)\n",
        "test_iter = IterableWrapper(test_iter)\n",
        "valid_iter = IterableWrapper(valid_iter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNlDyqOwvItm"
      },
      "source": [
        "- Build Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4QNGKw4vQ2r"
      },
      "outputs": [],
      "source": [
        "tokenizer = get_tokenizer('basic_english')\n",
        "vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=['<unk>'])\n",
        "vocab.set_default_index(vocab['<unk>'])\n",
        "torch.save(vocab, 'vocab.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVsC0d1Qvt6E"
      },
      "source": [
        "## Dataset Prepreation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gEXdvicwTRj"
      },
      "source": [
        "- Creat Target Array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_FC_QFzvtcL"
      },
      "outputs": [],
      "source": [
        "def data_process(raw_text_iter, seq_len):\n",
        "  data = torch.cat([torch.LongTensor(vocab(tokenizer(line))) for line in raw_text_iter])\n",
        "\n",
        "  M = len(data) // seq_len\n",
        "\n",
        "  r = len(data) % seq_len\n",
        "  data = torch.cat((data, torch.LongTensor([0]))) if r==0 else data\n",
        "\n",
        "  inputs = data[:M*seq_len]\n",
        "  targets = data[1:M*seq_len+1]\n",
        "\n",
        "  inputs = inputs.reshape(-1, seq_len)\n",
        "  targets = targets.reshape(-1, seq_len)\n",
        "\n",
        "  return inputs, targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYP0TPqcvz_L",
        "outputId": "3026f834-0136-462b-fca4-f9bb739479e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([29285, 70]),\n",
              " torch.Size([29285, 70]),\n",
              " torch.Size([3063, 70]),\n",
              " torch.Size([3063, 70]),\n",
              " torch.Size([3455, 70]),\n",
              " torch.Size([3455, 70]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "X_train, y_train = data_process(train_iter, seq_len)\n",
        "X_valid, y_valid = data_process(valid_iter, seq_len)\n",
        "X_test, y_test = data_process(test_iter, seq_len)\n",
        "\n",
        "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape, X_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJbQ1Nh0wXyy"
      },
      "source": [
        "- Custom Dataset Class Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkQQ934CxF21"
      },
      "outputs": [],
      "source": [
        "class LanguageModelDataset(Dataset):\n",
        "\n",
        "  def __init__(self, inputs, targets):\n",
        "    self.inputs = inputs\n",
        "    self.targets = targets\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.inputs.shape[0]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.inputs[idx], self.targets[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56QXULMExJJ9"
      },
      "outputs": [],
      "source": [
        "train_set = LanguageModelDataset(X_train, y_train)\n",
        "valid_set = LanguageModelDataset(X_valid, y_valid)\n",
        "test_set = LanguageModelDataset(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_QgbAMixKn7",
        "outputId": "d21d619b-089b-46bd-c5c2-ea5dd0cf2a56"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([    9,  3849,  3869,   881,     9, 20000,    83,  3849,    88,     0,\n",
              "          3869,    21,   780, 28780,     2,  6182,     3,  3849,     4,     1,\n",
              "          5023,    88,    20,     2,  1837,  1018,     7,    14,  3849,  3869,\n",
              "           881,   629,   976,     2,    23,     8,  5790,   299,    12,   575,\n",
              "           232,    67,   452,    19, 13722,     5,   757,     3,  2500,    17,\n",
              "             1,  1767,  5637,     3,   155,     6,   246,   354,     6,   976,\n",
              "             2,    24,    23,     1,   237,    67,     6,     1,  3849,    93]),\n",
              " tensor([ 3849,  3869,   881,     9, 20000,    83,  3849,    88,     0,  3869,\n",
              "            21,   780, 28780,     2,  6182,     3,  3849,     4,     1,  5023,\n",
              "            88,    20,     2,  1837,  1018,     7,    14,  3849,  3869,   881,\n",
              "           629,   976,     2,    23,     8,  5790,   299,    12,   575,   232,\n",
              "            67,   452,    19, 13722,     5,   757,     3,  2500,    17,     1,\n",
              "          1767,  5637,     3,   155,     6,   246,   354,     6,   976,     2,\n",
              "            24,    23,     1,   237,    67,     6,     1,  3849,    93,     3]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "train_set[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZkza2MYxOnk"
      },
      "source": [
        "- Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gz_hP05xRt8"
      },
      "outputs": [],
      "source": [
        "set_seed(seed)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQ1eIKZLxUOz",
        "outputId": "5f52c685-6cc6-45dc-96c6-217adb0c70ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([80, 70]), torch.Size([80, 70]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "x_batch, y_batch = next(iter(train_loader))\n",
        "x_batch.shape, y_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwbPWDxTxvrO",
        "outputId": "1c3d1738-a4f2-421b-fd0d-5ac6bb6e8c24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1985) tensor(13)\n"
          ]
        }
      ],
      "source": [
        "set_seed(seed)\n",
        "\n",
        "for inputs, targets in train_loader:\n",
        "  print(inputs[0, 0], targets[0, 0])\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMYLSVQWx2W8"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def embedded_dropout(embed, words, dropout=0.1, scale=None):\n",
        "  if dropout:\n",
        "    mask = embed.weight.data.new().resize_((embed.weight.size(0), 1)).bernoulli_(1 - dropout).expand_as(\n",
        "        embed.weight) / (1 - dropout)\n",
        "    masked_embed_weight = mask * embed.weight\n",
        "  else:\n",
        "    masked_embed_weight = embed.weight\n",
        "  if scale:\n",
        "    masked_embed_weight = scale.expand_as(masked_embed_weight) * masked_embed_weight\n",
        "\n",
        "  padding_idx = embed.padding_idx\n",
        "  if padding_idx is None:\n",
        "    padding_idx = -1\n",
        "\n",
        "  embedding = torch.nn.functional.embedding(words, masked_embed_weight,\n",
        "                                            padding_idx, embed.max_norm, embed.norm_type,\n",
        "                                            embed.scale_grad_by_freq, embed.sparse)\n",
        "  return embedding"
      ],
      "metadata": {
        "id": "Strd7xNYHh5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LockedDropout(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LockedDropout, self).__init__()\n",
        "\n",
        "  def forward(self, x, dropout):\n",
        "    if not self.training or not dropout:\n",
        "      return x\n",
        "    m = x.data.new(1, x.size(1), x.size(2)).bernoulli_(1 - dropout)\n",
        "    mask = m.requires_grad_(False) / (1 - dropout)\n",
        "    mask = mask.expand_as(x)\n",
        "    return mask * x"
      ],
      "metadata": {
        "id": "vqMQxMONHiz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdlAzoEcx2FM"
      },
      "outputs": [],
      "source": [
        "class LanguageModel(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers,\n",
        "                dropoute=0.2, dropouti=0.2, dropouth=0.2, dropouto=0.2):\n",
        "    super().__init__()\n",
        "    self.num_layers = num_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.embedding_dim = embedding_dim\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.embedding.weight.data.uniform_(-0.1, 0.1)\n",
        "    # self.dropout = nn.Dropout(p=dropout_embd)\n",
        "\n",
        "    self.lstms = []\n",
        "    self.lstms.append(nn.LSTM(embedding_dim, hidden_dim, num_layers=1, dropout=0, batch_first=False))\n",
        "    self.lstms.append(nn.LSTM(hidden_dim, hidden_dim, num_layers=1, dropout=0, batch_first=False))\n",
        "    self.lstms.append(nn.LSTM(hidden_dim, embedding_dim, num_layers=1, dropout=0, batch_first=False))\n",
        "    self.lstms = nn.ModuleList(self.lstms)\n",
        "\n",
        "    self.fc = nn.Linear(embedding_dim, vocab_size)\n",
        "\n",
        "    self.fc.weight = self.embedding.weight\n",
        "\n",
        "    self.lockdrop = LockedDropout()\n",
        "    self.dropoute = dropoute\n",
        "    self.dropouti = dropouti\n",
        "    self.dropouth = dropouth\n",
        "    self.dropouto = dropouto\n",
        "\n",
        "  def forward(self, src):\n",
        "    # embedding = self.dropout(self.embedding(src))\n",
        "    embedding = embedded_dropout(self.embedding, src, dropout=self.dropoute if self.training else 0)\n",
        "    embedding = self.lockdrop(embedding, self.dropouti)\n",
        "\n",
        "    # new_hiddens = []\n",
        "    for l, lstm in enumerate(self.lstms):\n",
        "      embedding, _ = lstm(embedding)\n",
        "      if l != self.num_layers-1:\n",
        "        embedding = self.lockdrop(embedding, self.dropouth)\n",
        "\n",
        "    embedding = self.lockdrop(embedding, self.dropouto)\n",
        "\n",
        "    prediction = self.fc(embedding)\n",
        "    return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJotksm3x-cU",
        "outputId": "a0ff7dfb-6332-4207-e863-ab92bee1bf4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageModel(\n",
              "  (embedding): Embedding(28782, 400)\n",
              "  (lstms): ModuleList(\n",
              "    (0): LSTM(400, 1150)\n",
              "    (1): LSTM(1150, 1150)\n",
              "    (2): LSTM(1150, 400)\n",
              "  )\n",
              "  (fc): Linear(in_features=400, out_features=28782, bias=True)\n",
              "  (lockdrop): LockedDropout()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "set_seed(seed)\n",
        "\n",
        "model = LanguageModel(vocab_size=len(vocab),\n",
        "                      embedding_dim=embedding_dim,\n",
        "                      hidden_dim=hidden_dim,\n",
        "                      num_layers=num_layers,\n",
        "                      dropoute=dropoute, dropouti=dropouti,\n",
        "                      dropouth=dropouth, dropouto=dropouto)\n",
        "model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNdI-5pVyOKk"
      },
      "source": [
        "# Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "PGCd-Dm-yNhM",
        "outputId": "492d2c27-5cf3-4095-e398-6d17146b1bca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hd19NFFNyUFk"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "metric = tm.text.Perplexity().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6Oy3pH0RgAt"
      },
      "outputs": [],
      "source": [
        "key_file = \"/content/drive/MyDrive/LanguageModel/key.txt\"\n",
        "\n",
        "if os.path.exists(key_file):\n",
        "    with open(key_file) as f:\n",
        "        key = f.readline().strip()\n",
        "else:\n",
        "    print(\"Key file does not exist. Please create the key file with your wandb API key.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfY7_5XZc4qk",
        "outputId": "5242e7b1-8b19-44f4-d82d-57851a728f27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please input the WandB argument (run) name:embd&lock-drop\n"
          ]
        }
      ],
      "source": [
        "wandb_arg_name = input('Please input the WandB argument (run) name:')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_APSWaGyc5Iw"
      },
      "outputs": [],
      "source": [
        "# comet_ml.init(project_name=\"LM_AWD-LSTM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAsopugofMzN",
        "outputId": "406e2ba3-f1d8-4e81-b164-c42a2897c8e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/ft-azad/lm-awd-lstm/7aeb69dee61b4328a5d0c0800cd9c783\n",
            "\n"
          ]
        }
      ],
      "source": [
        "experiment = Experiment(\n",
        "  api_key=key,\n",
        "  project_name=\"LM_AWD-LSTM\",\n",
        ")\n",
        "experiment.set_name(wandb_arg_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_1sWWHVy7Kk"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxTkh6JGy9Kj"
      },
      "source": [
        "## Train and Evaluate Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1dAZfqLy850"
      },
      "outputs": [],
      "source": [
        "# Train Functions\n",
        "def train_one_epoch(model, train_loader, loss_fn, optimizer, metric, epoch=None):\n",
        "  model.train()\n",
        "  loss_train = AverageMeter()\n",
        "  metric.reset()\n",
        "\n",
        "  with tqdm.tqdm(train_loader, unit='batch') as tepoch:\n",
        "    for inputs, targets in tepoch:\n",
        "      if epoch:\n",
        "        tepoch.set_description(f'Epoch {epoch}')\n",
        "\n",
        "      inputs = inputs.t().to(device)\n",
        "      targets = targets.t().to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      loss = loss_fn(outputs.reshape(-1, outputs.shape[-1]), targets.flatten())\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      nn.utils.clip_grad.clip_grad_norm_(model.parameters(), max_norm=clip)\n",
        "\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      loss_train.update(loss.item(), n=len(targets))\n",
        "      metric.update(outputs, targets)\n",
        "\n",
        "      tepoch.set_postfix(loss=loss_train.avg, metric=metric.compute().item())\n",
        "\n",
        "  return model, loss_train.avg, metric.compute().item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ma-DFi9XzE1s"
      },
      "outputs": [],
      "source": [
        "# Evaluate Function\n",
        "def evaluate(model, test_loader, loss_fn, metric):\n",
        "  model.eval()\n",
        "  loss_eval = AverageMeter()\n",
        "  metric.reset()\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for inputs, targets in test_loader:\n",
        "      inputs = inputs.t().to(device)\n",
        "      targets = targets.t().to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      loss = loss_fn(outputs.reshape(-1, outputs.shape[-1]), targets.flatten())\n",
        "      loss_eval.update(loss.item(), n=len(targets))\n",
        "\n",
        "      metric(outputs, targets)\n",
        "\n",
        "  return loss_eval.avg, metric.compute().item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKkW_4FBz1ac"
      },
      "source": [
        "## Train Process and Tunning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FYTauriz3RL"
      },
      "source": [
        "### Finding Hyper-parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaPsJriFz4i7"
      },
      "source": [
        "- Calculating the loss for untrained model using a few batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIebaKmbz5xj",
        "outputId": "4ab612a6-f559-475f-e2b0-c1a9ea7320e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(10.2711, device='cuda:0')\n",
            "tensor(10.2717, device='cuda:0')\n",
            "tensor(10.2653, device='cuda:0')\n",
            "tensor(10.2671, device='cuda:0')\n",
            "tensor(10.2690, device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "for iter_num in range(5):\n",
        "  model = LanguageModel(len(vocab), embedding_dim=embedding_dim,\n",
        "                      hidden_dim=hidden_dim, num_layers=num_layers,\n",
        "                      dropoute=dropoute, dropouti=dropouti,\n",
        "                      dropouth=dropouth, dropouto=dropouto).to(device)\n",
        "\n",
        "  inputs, targets = next(iter(train_loader))\n",
        "  inputs = inputs.to(device)\n",
        "  targets = targets.to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    outputs = model(inputs)\n",
        "    loss = loss_fn(outputs.reshape(-1, outputs.shape[-1]), targets.flatten())\n",
        "\n",
        "  print(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14lWNR0Jz8VQ"
      },
      "source": [
        "- Train and try to overfit the model on a small subset of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pg26Lvdb0G8I"
      },
      "outputs": [],
      "source": [
        "model = LanguageModel(len(vocab), embedding_dim=embedding_dim,\n",
        "                      hidden_dim=hidden_dim, num_layers=num_layers,\n",
        "                      dropoute=dropoute, dropouti=dropouti,\n",
        "                      dropouth=dropouth, dropouto=dropouto).to(device)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.9, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2XIZjef0IG5"
      },
      "outputs": [],
      "source": [
        "mini_train_size = 1000\n",
        "_, mini_train_dataset = random_split(train_set, (len(train_set)-mini_train_size, mini_train_size))\n",
        "mini_train_loader = DataLoader(mini_train_dataset, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VEtGlnyl0JHy",
        "outputId": "3b64a994-8e4f-4ffa-e410-4dd711a0079c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:01<00:00, 26.48batch/s, loss=8.33, metric=4.15e+3]\n",
            "Epoch 1: 100%|██████████| 50/50 [00:01<00:00, 25.97batch/s, loss=7.18, metric=1.31e+3]\n",
            "Epoch 2: 100%|██████████| 50/50 [00:01<00:00, 25.92batch/s, loss=7, metric=1.1e+3]\n",
            "Epoch 3: 100%|██████████| 50/50 [00:01<00:00, 25.80batch/s, loss=6.93, metric=1.02e+3]\n",
            "Epoch 4: 100%|██████████| 50/50 [00:01<00:00, 25.78batch/s, loss=6.84, metric=937]\n",
            "Epoch 5: 100%|██████████| 50/50 [00:01<00:00, 25.14batch/s, loss=6.72, metric=832]\n",
            "Epoch 6: 100%|██████████| 50/50 [00:02<00:00, 24.81batch/s, loss=6.61, metric=740]\n",
            "Epoch 7: 100%|██████████| 50/50 [00:01<00:00, 25.30batch/s, loss=6.51, metric=672]\n",
            "Epoch 8: 100%|██████████| 50/50 [00:01<00:00, 25.30batch/s, loss=6.43, metric=619]\n",
            "Epoch 9: 100%|██████████| 50/50 [00:01<00:00, 25.16batch/s, loss=6.35, metric=572]\n",
            "Epoch 10: 100%|██████████| 50/50 [00:01<00:00, 25.14batch/s, loss=6.27, metric=529]\n",
            "Epoch 11: 100%|██████████| 50/50 [00:01<00:00, 25.29batch/s, loss=6.2, metric=493]\n",
            "Epoch 12: 100%|██████████| 50/50 [00:02<00:00, 24.81batch/s, loss=6.12, metric=456]\n",
            "Epoch 13: 100%|██████████| 50/50 [00:02<00:00, 24.73batch/s, loss=6.05, metric=426]\n",
            "Epoch 14: 100%|██████████| 50/50 [00:02<00:00, 24.76batch/s, loss=5.98, metric=396]\n",
            "Epoch 15: 100%|██████████| 50/50 [00:02<00:00, 24.74batch/s, loss=5.91, metric=367]\n",
            "Epoch 16: 100%|██████████| 50/50 [00:02<00:00, 24.94batch/s, loss=5.83, metric=339]\n",
            "Epoch 17: 100%|██████████| 50/50 [00:01<00:00, 25.20batch/s, loss=5.74, metric=312]\n",
            "Epoch 18: 100%|██████████| 50/50 [00:01<00:00, 25.08batch/s, loss=5.65, metric=283]\n",
            "Epoch 19: 100%|██████████| 50/50 [00:02<00:00, 24.73batch/s, loss=5.55, metric=257]\n",
            "Epoch 20: 100%|██████████| 50/50 [00:02<00:00, 24.73batch/s, loss=5.45, metric=234]\n",
            "Epoch 21: 100%|██████████| 50/50 [00:02<00:00, 24.90batch/s, loss=5.36, metric=213]\n",
            "Epoch 22: 100%|██████████| 50/50 [00:01<00:00, 25.25batch/s, loss=5.27, metric=194]\n",
            "Epoch 23: 100%|██████████| 50/50 [00:01<00:00, 25.29batch/s, loss=5.18, metric=178]\n",
            "Epoch 24: 100%|██████████| 50/50 [00:01<00:00, 25.29batch/s, loss=5.09, metric=162]\n",
            "Epoch 25: 100%|██████████| 50/50 [00:01<00:00, 25.38batch/s, loss=4.99, metric=146]\n",
            "Epoch 26: 100%|██████████| 50/50 [00:01<00:00, 25.51batch/s, loss=4.88, metric=132]\n",
            "Epoch 27: 100%|██████████| 50/50 [00:02<00:00, 24.77batch/s, loss=4.79, metric=121]\n",
            "Epoch 28: 100%|██████████| 50/50 [00:02<00:00, 24.55batch/s, loss=4.69, metric=109]\n",
            "Epoch 29: 100%|██████████| 50/50 [00:01<00:00, 25.48batch/s, loss=4.57, metric=97]\n",
            "Epoch 30: 100%|██████████| 50/50 [00:01<00:00, 25.48batch/s, loss=4.45, metric=86]\n",
            "Epoch 31: 100%|██████████| 50/50 [00:01<00:00, 25.58batch/s, loss=4.34, metric=76.5]\n",
            "Epoch 32: 100%|██████████| 50/50 [00:01<00:00, 25.46batch/s, loss=4.23, metric=68.8]\n",
            "Epoch 33: 100%|██████████| 50/50 [00:01<00:00, 25.51batch/s, loss=4.13, metric=62]\n",
            "Epoch 34: 100%|██████████| 50/50 [00:02<00:00, 24.97batch/s, loss=4.02, metric=55.6]\n",
            "Epoch 35: 100%|██████████| 50/50 [00:01<00:00, 25.13batch/s, loss=3.93, metric=51.1]\n",
            "Epoch 36: 100%|██████████| 50/50 [00:01<00:00, 25.71batch/s, loss=3.85, metric=47]\n",
            "Epoch 37: 100%|██████████| 50/50 [00:01<00:00, 25.54batch/s, loss=3.75, metric=42.7]\n",
            "Epoch 38: 100%|██████████| 50/50 [00:01<00:00, 25.13batch/s, loss=3.67, metric=39.2]\n",
            "Epoch 39: 100%|██████████| 50/50 [00:01<00:00, 25.34batch/s, loss=3.61, metric=37]\n",
            "Epoch 40: 100%|██████████| 50/50 [00:01<00:00, 25.20batch/s, loss=3.55, metric=34.8]\n",
            "Epoch 41: 100%|██████████| 50/50 [00:01<00:00, 25.27batch/s, loss=3.45, metric=31.5]\n",
            "Epoch 42: 100%|██████████| 50/50 [00:02<00:00, 24.61batch/s, loss=3.36, metric=28.7]\n",
            "Epoch 43: 100%|██████████| 50/50 [00:02<00:00, 24.40batch/s, loss=3.25, metric=25.7]\n",
            "Epoch 44: 100%|██████████| 50/50 [00:02<00:00, 24.98batch/s, loss=3.12, metric=22.7]\n",
            "Epoch 45: 100%|██████████| 50/50 [00:01<00:00, 25.05batch/s, loss=3.01, metric=20.2]\n",
            "Epoch 46: 100%|██████████| 50/50 [00:01<00:00, 25.55batch/s, loss=2.87, metric=17.6]\n",
            "Epoch 47: 100%|██████████| 50/50 [00:01<00:00, 25.45batch/s, loss=2.75, metric=15.6]\n",
            "Epoch 48: 100%|██████████| 50/50 [00:01<00:00, 25.30batch/s, loss=2.64, metric=14.1]\n",
            "Epoch 49: 100%|██████████| 50/50 [00:01<00:00, 25.07batch/s, loss=2.55, metric=12.7]\n",
            "Epoch 50: 100%|██████████| 50/50 [00:01<00:00, 25.28batch/s, loss=2.46, metric=11.8]\n",
            "Epoch 51: 100%|██████████| 50/50 [00:01<00:00, 25.60batch/s, loss=2.41, metric=11.2]\n",
            "Epoch 52: 100%|██████████| 50/50 [00:01<00:00, 25.61batch/s, loss=2.33, metric=10.3]\n",
            "Epoch 53: 100%|██████████| 50/50 [00:01<00:00, 25.33batch/s, loss=2.25, metric=9.44]\n",
            "Epoch 54: 100%|██████████| 50/50 [00:01<00:00, 25.53batch/s, loss=2.14, metric=8.54]\n",
            "Epoch 55: 100%|██████████| 50/50 [00:01<00:00, 25.22batch/s, loss=2.05, metric=7.77]\n",
            "Epoch 56:  62%|██████▏   | 31/50 [00:01<00:00, 24.28batch/s, loss=1.98, metric=7.23]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-7579defe06ba>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-29-870050b25dc7>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_loader, loss_fn, optimizer, metric, epoch)\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m       \u001b[0mloss_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m       \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "  model, _, _ = train_one_epoch(model, mini_train_loader, loss_fn, optimizer, metric, epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfegeAIT0L70"
      },
      "source": [
        "-  Train the model for a limited number of epochs, experimenting with various learning rates to find best value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZDUK09T0VGO"
      },
      "outputs": [],
      "source": [
        "num_epochs = 2\n",
        "\n",
        "for lr in [12, 8, 4, 2, 0.9]:\n",
        "  print(f'LR={lr}')\n",
        "\n",
        "  model = LanguageModel(len(vocab), embedding_dim=embedding_dim,\n",
        "                        hidden_dim=hidden_dim, num_layers=num_layers,\n",
        "                        dropoute=dropoute, dropouti=dropouti,\n",
        "                      dropouth=dropouth, dropouto=dropouto).to(device)\n",
        "  # model = torch.load('model.pt')\n",
        "\n",
        "  optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=momentum)\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    model, _, _ = train_one_epoch(model, train_loader, loss_fn, optimizer, metric, epoch)\n",
        "\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-dy-qYP0Zwd"
      },
      "source": [
        "- Creat a small grid search to find exact value of lr and weight decay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyxZLxkm0drG"
      },
      "outputs": [],
      "source": [
        "num_epochs = 1\n",
        "\n",
        "for lr in [7, 8, 14, 13, 12, 11, 10, 9]:\n",
        "  for wd in [1.2e-6]:\n",
        "    print(f'LR={lr}, WD={wd}')\n",
        "\n",
        "    model = LanguageModel(len(vocab), embedding_dim=embedding_dim,\n",
        "                      hidden_dim=hidden_dim, num_layers=num_layers,\n",
        "                      dropoute=dropoute, dropouti=dropouti,\n",
        "                      dropouth=dropouth, dropouto=dropouto).to(device)\n",
        "\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=0.9)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      model, _, _ = train_one_epoch(model, train_loader, loss_fn, optimizer, metric, epoch)\n",
        "\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ3Q1xfn0jft"
      },
      "source": [
        "- Train model for more epochs using the best hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUxTmYsn0lK-",
        "outputId": "8c5cf7df-80a3-4449-a4c3-6130942b8dde"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LanguageModel(\n",
              "  (embedding): Embedding(28782, 300)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (lstm): LSTM(300, 512, num_layers=2, batch_first=True, dropout=0.2)\n",
              "  (fc): Linear(in_features=512, out_features=28782, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = LanguageModel(len(vocab), embedding_dim=embedding_dim,\n",
        "                      hidden_dim=hidden_dim, num_layers=num_layers,\n",
        "                      dropoute=dropoute, dropouti=dropouti,\n",
        "                      dropouth=dropouth, dropouto=dropouto).to(device)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "0yA4xkdo0pg1",
        "outputId": "63c94ccf-65d9-4b11-f715-8ccd1426c3d3"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/model-ppl_133.pt'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-6ef75991a85f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/model-ppl_133.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/model-ppl_133.pt'"
          ]
        }
      ],
      "source": [
        "model = torch.load('/content/model-ppl_133.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsBrL69h0q89",
        "outputId": "90a0c044-163e-42fc-dc10-fc91d667d29a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SGD (\n",
              "Parameter Group 0\n",
              "    dampening: 0\n",
              "    differentiable: False\n",
              "    foreach: None\n",
              "    lr: 8\n",
              "    maximize: False\n",
              "    momentum: 0.9\n",
              "    nesterov: False\n",
              "    weight_decay: 1e-06\n",
              ")"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lr = 8\n",
        "wd = 1e-6\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=0.9)\n",
        "optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8LL1uHv0sSN"
      },
      "outputs": [],
      "source": [
        "loss_train_hist = []\n",
        "loss_valid_hist = []\n",
        "\n",
        "metric_train_hist = []\n",
        "metric_valid_hist = []\n",
        "\n",
        "best_loss_valid = torch.inf\n",
        "epoch_counter = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqRODsU90wKV"
      },
      "outputs": [],
      "source": [
        "num_epochs = 30\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "  # WandB\n",
        "  # run = wandb.init(\n",
        "  #       project=\"language-modeling-lstms\",\n",
        "  #       config={\n",
        "  #           \"learning_rate\": lr,\n",
        "  #           \"epochs\": num_epochs,\n",
        "  #       })\n",
        "\n",
        "  # Train\n",
        "  model, loss_train, metric_train = train_one_epoch(model,\n",
        "                                                    train_loader,\n",
        "                                                    loss_fn,\n",
        "                                                    optimizer,\n",
        "                                                    metric,\n",
        "                                                    epoch)\n",
        "  # Validation\n",
        "  loss_valid, metric_valid = evaluate(model,\n",
        "                                      valid_loader,\n",
        "                                      loss_fn,\n",
        "                                      metric)\n",
        "\n",
        "  loss_train_hist.append(loss_train)\n",
        "  loss_valid_hist.append(loss_valid)\n",
        "\n",
        "  metric_train_hist.append(metric_train)\n",
        "  metric_valid_hist.append(metric_valid)\n",
        "\n",
        "  if loss_valid < best_loss_valid:\n",
        "    torch.save(model, f'model.pt')\n",
        "    best_loss_valid = loss_valid\n",
        "    print('Model Saved!')\n",
        "\n",
        "  print(f'Valid: Loss = {loss_valid:.4}, Metric = {metric_valid:.4}')\n",
        "  print()\n",
        "\n",
        "  epoch_counter += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V-sSI1-02P9"
      },
      "source": [
        "### Main Train Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-H0Trq9804lf"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eu3JG-706fn"
      },
      "outputs": [],
      "source": [
        "set_seed(seed)\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFu74yBI08c9",
        "outputId": "0950938f-1abe-4079-deb0-b36c2666222f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageModel(\n",
              "  (embedding): Embedding(28782, 400)\n",
              "  (lstms): ModuleList(\n",
              "    (0): LSTM(400, 1150)\n",
              "    (1): LSTM(1150, 1150)\n",
              "    (2): LSTM(1150, 400)\n",
              "  )\n",
              "  (fc): Linear(in_features=400, out_features=28782, bias=True)\n",
              "  (lockdrop): LockedDropout()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "set_seed(seed)\n",
        "\n",
        "model = LanguageModel(len(vocab), embedding_dim=embedding_dim,\n",
        "                      hidden_dim=hidden_dim, num_layers=num_layers,\n",
        "                      dropoute=dropoute, dropouti=dropouti,\n",
        "                      dropouth=dropouth, dropouto=dropouto).to(device)\n",
        "\n",
        "# model = LanguageModel(vocab_size=len(vocab), embedding_dim=embedding_dim,\n",
        "#                       hidden_dim=hidden_dim, num_layers=num_layers,\n",
        "#                       dropoute=dropoute, dropouti=dropouti,\n",
        "#                       dropouth=dropouth, dropouto=dropouto,\n",
        "#                       weight_drop=weight_drop, pretrained=pretrained).to(device)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spHIVlf_1I_5"
      },
      "outputs": [],
      "source": [
        "model = torch.load('model.pt')\n",
        "# epoch_counter = best_epoch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil"
      ],
      "metadata": {
        "id": "a2ckN9ecdQnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "AskOAQl1HQXI",
        "outputId": "ba510d40-9649-49cb-ab4a-bb018621d50e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/LanguageModel/model-ppl100.3epoch29.pt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "shutil.copyfile(\"model.pt\", \"/content/drive/MyDrive/LanguageModel/model-ppl100.3epoch29.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ys-oQE1F1Obg",
        "outputId": "812cd278-0a8c-457a-ee35-46a9982f0ef0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGD (\n",
              "Parameter Group 0\n",
              "    dampening: 0\n",
              "    differentiable: False\n",
              "    foreach: None\n",
              "    lr: 1.25\n",
              "    maximize: False\n",
              "    momentum: 0.9\n",
              "    nesterov: False\n",
              "    weight_decay: 1e-06\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "set_seed(seed)\n",
        "\n",
        "lr = 1.25\n",
        "wd = 1e-6\n",
        "# momentum = 0.9\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=momentum)\n",
        "# optimizer = optim.SGD([{'params': model.embedding.parameters(), 'lr': 0.1*lr},\n",
        "#                        {'params': model.lstms.parameters(), 'lr': lr}],\n",
        "#                       weight_decay=wd, momentum=momentum)\n",
        "optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jgfektma1RUo"
      },
      "outputs": [],
      "source": [
        "if wandb_enable:\n",
        "\n",
        "      config={\n",
        "          'lr': lr,\n",
        "          'momentum': momentum,\n",
        "          'batch_size': batch_size,\n",
        "          'seq_len': seq_len,\n",
        "          'hidden_dim': hidden_dim,\n",
        "          'embedding_dim': embedding_dim,\n",
        "          'num_layers': num_layers,\n",
        "          # 'dropout_embd': dropout_embd,\n",
        "          # 'dropout_rnn': dropout_rnn,\n",
        "          'dropout_embed': dropoute,\n",
        "          'dropout_in_lstm': dropouti,\n",
        "          'dropout_h_lstm': dropouth,\n",
        "          'dropout_out_lstm': dropouto,\n",
        "          'clip': clip,\n",
        "      }\n",
        "\n",
        "      experiment.log_parameters(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BTiIsVt1Vc9"
      },
      "outputs": [],
      "source": [
        "loss_train_hist = []\n",
        "loss_valid_hist = []\n",
        "\n",
        "metric_train_hist = []\n",
        "metric_valid_hist = []\n",
        "\n",
        "best_loss_valid = torch.inf\n",
        "epoch_counter = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FLMefkng1X32",
        "outputId": "2a02ace7-8207-431c-c80f-a53d4f3386f3"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 367/367 [02:33<00:00,  2.39batch/s, loss=4.27, metric=71.7]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 4.522, Metric = 92.45\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 367/367 [02:33<00:00,  2.38batch/s, loss=4.21, metric=67.6]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 4.515, Metric = 91.83\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|██████████| 367/367 [02:33<00:00,  2.39batch/s, loss=4.19, metric=66]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 4.513, Metric = 91.66\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|██████████| 367/367 [02:34<00:00,  2.38batch/s, loss=4.17, metric=64.6]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 4.511, Metric = 91.47\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 367/367 [02:34<00:00,  2.38batch/s, loss=4.14, metric=62.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 4.509, Metric = 91.26\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 367/367 [02:34<00:00,  2.38batch/s, loss=4.12, metric=61.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 4.509, Metric = 91.3\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 367/367 [02:33<00:00,  2.38batch/s, loss=4.09, metric=59.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 4.51, Metric = 91.37\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 367/367 [02:33<00:00,  2.39batch/s, loss=4.07, metric=58.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 4.512, Metric = 91.54\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 367/367 [02:33<00:00,  2.39batch/s, loss=4.05, metric=57.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 4.514, Metric = 91.71\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 367/367 [02:33<00:00,  2.38batch/s, loss=4.02, metric=55.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 4.521, Metric = 92.37\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| 367/367 [02:33<00:00,  2.38batch/s, loss=3.99, metric=54.3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 4.524, Metric = 92.61\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|██████████| 367/367 [02:33<00:00,  2.38batch/s, loss=3.96, metric=52.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 4.518, Metric = 92.06\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13: 100%|██████████| 367/367 [02:34<00:00,  2.38batch/s, loss=3.93, metric=51.2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 4.529, Metric = 93.09\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14: 100%|██████████| 367/367 [02:34<00:00,  2.38batch/s, loss=3.89, metric=49.3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 4.533, Metric = 93.48\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15:   6%|▌         | 21/367 [00:09<02:31,  2.28batch/s, loss=3.8, metric=44.9]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-b136936a0c7d>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   model, loss_train, metric_train = train_one_epoch(model,\n\u001b[0m\u001b[1;32m      7\u001b[0m                                                     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                                     \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-79fae68857d3>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_loader, loss_fn, optimizer, metric, epoch)\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "set_seed(seed)\n",
        "num_epochs = 15\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "  # Train\n",
        "  model, loss_train, metric_train = train_one_epoch(model,\n",
        "                                                    train_loader,\n",
        "                                                    loss_fn,\n",
        "                                                    optimizer,\n",
        "                                                    metric,\n",
        "                                                    epoch)\n",
        "  # Validation\n",
        "  loss_valid, metric_valid = evaluate(model,\n",
        "                                      valid_loader,\n",
        "                                      loss_fn,\n",
        "                                      metric)\n",
        "\n",
        "  loss_train_hist.append(loss_train)\n",
        "  loss_valid_hist.append(loss_valid)\n",
        "\n",
        "  metric_train_hist.append(metric_train)\n",
        "  metric_valid_hist.append(metric_valid)\n",
        "\n",
        "  if loss_valid < best_loss_valid:\n",
        "    torch.save(model, f'model.pt')\n",
        "    torch.save(model, f'/content/drive/MyDrive/LanguageModel/model.pt')\n",
        "    best_loss_valid = loss_valid\n",
        "    best_epoch = epoch_counter\n",
        "    print('Model Saved!')\n",
        "\n",
        "  print(f'Valid: Loss = {loss_valid:.4}, Metric = {metric_valid:.4}')\n",
        "  print()\n",
        "\n",
        "  if wandb_enable:\n",
        "    experiment.log_metrics({\"metric_train\": metric_train, \"loss_train\": loss_train,\n",
        "                \"metric_valid\": metric_valid, \"loss_valid\": loss_valid}, epoch=epoch_counter)\n",
        "\n",
        "  epoch_counter += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQ4Y-_Uc1bSk",
        "outputId": "5bd4c726-0660-4316-f622-442246420936"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : embd&lock-drop\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/ft-azad/lm-awd-lstm/7aeb69dee61b4328a5d0c0800cd9c783\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss_train [58]   : (3.8949986699491497, 6.684415862735675)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss_valid [58]   : (4.509146775954809, 5.797027367811936)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metric_train [58] : (49.26998519897461, 800.5197143554688)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metric_valid [58] : (91.26468658447266, 330.65228271484375)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name : embd&lock-drop\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch_size       : 80\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     clip             : 0.25\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout_embed    : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout_h_lstm   : 0.3\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout_in_lstm  : 0.65\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout_out_lstm : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     embedding_dim    : 400\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hidden_dim       : 1150\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr               : 7.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum         : 0.9\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_layers       : 3\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seq_len          : 70\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n"
          ]
        }
      ],
      "source": [
        "experiment.end()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxRYKNUC1hoe"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCTHcn7t1hWO"
      },
      "outputs": [],
      "source": [
        "model_path = 'model.pt'\n",
        "model = torch.load(model_path)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELNfyJcB1oPN"
      },
      "outputs": [],
      "source": [
        "loss_valid, metric_valid = evaluate(model, valid_loader, loss_fn, metric)\n",
        "metric_valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZ6UaE8N1pQl"
      },
      "outputs": [],
      "source": [
        "loss_test, metric_test = evaluate(model, test_loader, loss_fn, metric)\n",
        "metric_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mez84S5y1roU"
      },
      "source": [
        "# Generate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTXlQSO91wyl"
      },
      "outputs": [],
      "source": [
        "model_path = 'model.pt'\n",
        "model = torch.load(model_path)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0JuNPDq15M7"
      },
      "outputs": [],
      "source": [
        "def generate(prompt, max_seq_len, temperature, model, tokenizer, vocab, seed=None):\n",
        "\n",
        "  indices = vocab(tokenizer(prompt))\n",
        "  itos = vocab.get_itos()\n",
        "\n",
        "  for i in range(max_seq_len):\n",
        "    src = torch.LongTensor(indices).to(device)\n",
        "    with torch.no_grad():\n",
        "      prediction = model(src)\n",
        "\n",
        "    # Low values like 0.1 for temperature, Makes softmax like argmax more\n",
        "    probs = torch.softmax(prediction[-1]/temperature, dim = 0)\n",
        "    idx = vocab[\"<ukn>\"]\n",
        "    while idx == vocab[\"<ukn>\"]:\n",
        "      idx = torch.multinomial(probs, num_samples =1).item()\n",
        "    indices.append(idx)\n",
        "    prompt += \" \" + itos[idx]\n",
        "    # print(prompt)\n",
        "\n",
        "    if idx == vocab[\".\"]:\n",
        "      return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9zBXRrr2C2y"
      },
      "outputs": [],
      "source": [
        "prompt = \"as i know about this subject,\"\n",
        "generate(prompt, 40, 0.5, model, tokenizer, vocab, seed=None)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "xtOFbjYdtuXS"
      ],
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}