{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "-w94hRxp2pTi"
      ],
      "gpuType": "T4",
      "mount_file_id": "1bOQm_t_04AoT_eswlRzS4oAIr_74-DQ_",
      "authorship_tag": "ABX9TyOGA8oYAwpH5sFiM7nAOoFn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ft-Azad/Language-Modeling/blob/main/LanguageModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Import Libs"
      ],
      "metadata": {
        "id": "LrWocfpm2aet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torchmetrics\n",
        "!pip install -q torchdata==0.6.1\n",
        "!pip install 'portalocker>=2.0.0'\n",
        "!pip install torchtext==0.15.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hsog-ccz2l3C",
        "outputId": "ebd8f97f-8e04-45b9-ac65-dbd34702998a",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.3.0+cu121 requires torch==2.3.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.18.0+cu121 requires torch==2.3.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting portalocker>=2.0.0\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: portalocker\n",
            "Successfully installed portalocker-2.8.2\n",
            "Collecting torchtext==0.15.1\n",
            "  Downloading torchtext-0.15.1-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.1) (4.66.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.1) (2.31.0)\n",
            "Collecting torch==2.0.0 (from torchtext==0.15.1)\n",
            "  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.1) (1.25.2)\n",
            "Collecting torchdata==0.6.0 (from torchtext==0.15.1)\n",
            "  Downloading torchdata-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (2.0.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.6.0->torchtext==0.15.1) (2.0.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchtext==0.15.1) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchtext==0.15.1) (0.43.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->torchtext==0.15.1) (3.27.9)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->torchtext==0.15.1) (18.1.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.15.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.15.1) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.15.1) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0->torchtext==0.15.1) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0->torchtext==0.15.1) (1.3.0)\n",
            "Installing collected packages: torch, torchdata, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1\n",
            "    Uninstalling torch-2.0.1:\n",
            "      Successfully uninstalled torch-2.0.1\n",
            "  Attempting uninstall: torchdata\n",
            "    Found existing installation: torchdata 0.6.1\n",
            "    Uninstalling torchdata-0.6.1:\n",
            "      Successfully uninstalled torchdata-0.6.1\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.18.0\n",
            "    Uninstalling torchtext-0.18.0:\n",
            "      Successfully uninstalled torchtext-0.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.3.0+cu121 requires torch==2.3.0, but you have torch 2.0.0 which is incompatible.\n",
            "torchvision 0.18.0+cu121 requires torch==2.3.0, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.0.0 torchdata-0.6.0 torchtext-0.15.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dQ1anJGt2Mpy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torchtext\n",
        "from torchtext.datasets import WikiText2\n",
        "from torchdata.datapipes.iter import IterableWrapper, Mapper\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "\n",
        "from torch import optim\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import tqdm\n",
        "import torchmetrics as tm\n",
        "\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for lib in [np, torch, torchtext, tqdm]:\n",
        "  print(lib.__name__, '-->', lib.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvWpZ1HX_bSA",
        "outputId": "f58f60cd-62da-461b-9e4a-f47d219caac6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy --> 1.25.2\n",
            "torch --> 2.0.0+cu117\n",
            "torchtext --> 0.15.1+cpu\n",
            "tqdm --> 4.66.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "-w94hRxp2pTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/ft-Azad/Language-Modeling"
      ],
      "metadata": {
        "id": "4_LL1lCDbqJG"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd .."
      ],
      "metadata": {
        "id": "zUQ--C2pbwxA"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %ls"
      ],
      "metadata": {
        "id": "r0sXUc8bb1Dt"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "metadata": {
        "id": "Ij8w30J-2tnS"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def num_trainable_params(model):\n",
        "  nums = sum(p.numel() for p in model.parameters() if p.requires_grad)/1e6\n",
        "  return nums"
      ],
      "metadata": {
        "id": "26kq60x63kob"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset"
      ],
      "metadata": {
        "id": "74jt_Yh33n5b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Dataset and Build Vocab"
      ],
      "metadata": {
        "id": "iydE_C3PJJ7n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Loading Iterable Data"
      ],
      "metadata": {
        "id": "TiMde3clWmRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train_iter, valid_iter, test_iter = WikiText2('/content/')"
      ],
      "metadata": {
        "id": "sLLLrs3MSrs4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "bypjg0BrVsUS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8203150d-768b-453a-cd09-b0f45e2bc9ba"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q \"/content/drive/MyDrive/LanguageModel/Data/wikitext-2-v1.zip\" -d '/content/'"
      ],
      "metadata": {
        "id": "LWLs34TRVuSh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/wikitext-2/wiki.train.tokens', 'r') as file:\n",
        "    train_iter = file.read().splitlines()\n",
        "\n",
        "with open('/content/wikitext-2/wiki.test.tokens', 'r') as file:\n",
        "    test_iter = file.read().splitlines()\n",
        "\n",
        "with open('/content/wikitext-2/wiki.valid.tokens', 'r') as file:\n",
        "    valid_iter = file.read().splitlines()\n",
        "\n",
        "train_iter = IterableWrapper(train_iter)\n",
        "test_iter = IterableWrapper(test_iter)\n",
        "valid_iter = IterableWrapper(valid_iter)"
      ],
      "metadata": {
        "id": "CUxmY_-YV6Uh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter_ = iter(train_iter)\n",
        "train_iter_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wfCsHfKUaS6",
        "outputId": "2f8d6beb-23e8-4d4b-9643-7ec6f3a1149d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object IterableWrapperIterDataPipe.__iter__ at 0x798415ddfae0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(train_iter_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "8EUQiZ4vUbp0",
        "outputId": "ecde173c-a1a2-4e52-e288-d7d13f65d327"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Build Vocabulary"
      ],
      "metadata": {
        "id": "8Wxz-msVWt_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "txt = ['@Azad hi Azad! 1 n2 3 #45', 'how are are you?']\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "[tokenizer(line) for line in txt]\n",
        "list(map(tokenizer, txt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQl8SjQnWvUs",
        "outputId": "6d83a7be-dbc7-48eb-d999-4f8b1c86fbb9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['@azad', 'hi', 'azad', '!', '1', 'n2', '3', '#45'],\n",
              " ['how', 'are', 'are', 'you', '?']]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = build_vocab_from_iterator(map(tokenizer, txt), specials=['<ukn>'], min_freq=1)\n",
        "vocab.set_default_index(vocab['<ukn>'])\n",
        "vocab.get_stoi()"
      ],
      "metadata": {
        "id": "_foahipTWzhG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30bb51b9-ae0a-4ef1-8f97-9f603eebff85"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n2': 11,\n",
              " 'how': 10,\n",
              " 'you': 12,\n",
              " 'hi': 9,\n",
              " 'azad': 8,\n",
              " '@azad': 7,\n",
              " '?': 6,\n",
              " '3': 5,\n",
              " '1': 4,\n",
              " '#45': 3,\n",
              " '!': 2,\n",
              " 'are': 1,\n",
              " '<ukn>': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab(['hi', 'azad', '<ukn>', 'hello', 'Hi'.lower()])"
      ],
      "metadata": {
        "id": "BqZ1FMgNW1S5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e51d66b9-7ecb-445e-e34d-958e79bcc210"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[9, 8, 0, 0, 9]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = get_tokenizer('basic_english')\n",
        "vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=['<unk>'])\n",
        "vocab.set_default_index(vocab['<unk>'])\n",
        "vocab.append_token(\"<eos>\")"
      ],
      "metadata": {
        "id": "umEf8CYR708R"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33uGKNRm9sbH",
        "outputId": "a38f5cd3-50ee-4f85-8aaf-13b72c8578a2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28783"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(vocab, 'vocab.pt')\n",
        "torch.save(vocab, '/content/drive/MyDrive/LanguageModel/vocab.pt')"
      ],
      "metadata": {
        "id": "GRaq3bHc9vBT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Properties (EDA)\n"
      ],
      "metadata": {
        "id": "7Bt_IQRqJeM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_sentence_count = 0\n",
        "total_sentence_length = 0\n",
        "\n",
        "for line in train_iter:\n",
        "    sentences = line.split('.')\n",
        "\n",
        "    for sentence in sentences:\n",
        "        tokens = sentence.strip().split()\n",
        "        sentence_length = len(tokens)\n",
        "\n",
        "        if sentence_length > 0:\n",
        "            total_sentence_count += 1\n",
        "            total_sentence_length += sentence_length\n",
        "\n",
        "mean_sentence_length = total_sentence_length / total_sentence_count\n",
        "\n",
        "print(f'Mean sentence length in Wikitext-2: {mean_sentence_length:.2f}')"
      ],
      "metadata": {
        "id": "WzIcSUrvIKRn",
        "outputId": "495fa8a9-4b62-40dc-dd33-7faf017fbd23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean sentence length in Wikitext-2: 21.69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freqs = Counter()\n",
        "for tokens in map(tokenizer, train_iter):\n",
        "  freqs.update(tokens)"
      ],
      "metadata": {
        "id": "Uul73nXgNtGi"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freqs.most_common()[:50]"
      ],
      "metadata": {
        "id": "ZgYuzdVDN9Z6",
        "outputId": "468eef2a-e0a4-4fd6-8b65-83272848ab7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 130768),\n",
              " (',', 102615),\n",
              " ('.', 83397),\n",
              " ('of', 57030),\n",
              " ('<unk>', 54625),\n",
              " ('and', 50735),\n",
              " ('in', 45015),\n",
              " ('to', 39521),\n",
              " ('a', 36523),\n",
              " ('=', 29570),\n",
              " ('was', 21008),\n",
              " (\"'\", 18484),\n",
              " ('@-@', 16906),\n",
              " ('on', 15140),\n",
              " ('as', 15058),\n",
              " ('s', 14936),\n",
              " ('that', 14351),\n",
              " ('for', 13794),\n",
              " ('with', 13012),\n",
              " ('by', 12718),\n",
              " (')', 12004),\n",
              " ('(', 11992),\n",
              " ('@', 11786),\n",
              " ('is', 11691),\n",
              " ('it', 9273),\n",
              " ('from', 9229),\n",
              " ('at', 9070),\n",
              " ('his', 9019),\n",
              " ('he', 8706),\n",
              " ('were', 7334),\n",
              " ('an', 6250),\n",
              " ('had', 5707),\n",
              " ('which', 5546),\n",
              " ('be', 4859),\n",
              " ('are', 4714),\n",
              " ('this', 4560),\n",
              " ('their', 4290),\n",
              " ('first', 4242),\n",
              " ('but', 4233),\n",
              " ('not', 4006),\n",
              " ('–', 3934),\n",
              " ('one', 3910),\n",
              " ('they', 3894),\n",
              " ('its', 3877),\n",
              " ('also', 3842),\n",
              " ('after', 3749),\n",
              " ('her', 3670),\n",
              " ('or', 3655),\n",
              " ('two', 3565),\n",
              " ('have', 3470)]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freqs.most_common()[::-1][:50]"
      ],
      "metadata": {
        "id": "6Q5AEGOuOBXL",
        "outputId": "dbc38b39-3f68-420a-bc6b-0df7863d1fd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('gallinae', 3),\n",
              " ('intergrades', 3),\n",
              " ('northeasterly', 3),\n",
              " ('tuscola', 3),\n",
              " ('roundabouts', 3),\n",
              " ('zoromski', 3),\n",
              " ('forrester', 3),\n",
              " ('kreutzer', 3),\n",
              " ('prefaced', 3),\n",
              " ('philipp', 3),\n",
              " ('chants', 3),\n",
              " ('sonatine', 3),\n",
              " ('mineurs', 3),\n",
              " ('étude', 3),\n",
              " ('caprices', 3),\n",
              " ('lewenthal', 3),\n",
              " ('spruces', 3),\n",
              " ('secretion', 3),\n",
              " ('tomentum', 3),\n",
              " ('yellowwoods', 3),\n",
              " ('echinodontium', 3),\n",
              " ('urocerus', 3),\n",
              " ('γ', 3),\n",
              " ('2γ', 3),\n",
              " ('2e', 3),\n",
              " ('tauri', 3),\n",
              " ('supergiants', 3),\n",
              " ('flamsteed', 3),\n",
              " ('novae', 3),\n",
              " ('sn', 3),\n",
              " ('hipparchus', 3),\n",
              " ('radiative', 3),\n",
              " ('dope', 3),\n",
              " ('shaggy', 3),\n",
              " ('utsler', 3),\n",
              " ('psychopathic', 3),\n",
              " ('brunette', 3),\n",
              " ('aar', 3),\n",
              " ('gigalitres', 3),\n",
              " ('jodidio', 3),\n",
              " ('barco', 3),\n",
              " ('puckering', 3),\n",
              " ('saic', 3),\n",
              " ('krueck', 3),\n",
              " ('squirtle', 3),\n",
              " ('schauenburg', 3),\n",
              " ('mechtshausen', 3),\n",
              " ('drunkards', 3),\n",
              " ('schopenhauer', 3),\n",
              " ('kremplsetzer', 3)]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Prepreation"
      ],
      "metadata": {
        "id": "s0PpL09pVN-5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Creat Target Array"
      ],
      "metadata": {
        "id": "F9G2WfByYIIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_process(raw_text_iter, seq_len):\n",
        "  data = torch.cat([torch.LongTensor(vocab(tokenizer(line)) + vocab([\"<eos>\"])) for line in raw_text_iter])\n",
        "\n",
        "  M = len(data) // seq_len\n",
        "\n",
        "  r = len(data) % seq_len\n",
        "  data = torch.cat((data, torch.LongTensor([0]))) if r==0 else data\n",
        "\n",
        "  inputs = data[:M*seq_len]\n",
        "  inputs = inputs.reshape(-1, seq_len)\n",
        "\n",
        "  targets = data[1:M*seq_len+1]\n",
        "  targets = targets.reshape(-1, seq_len)\n",
        "\n",
        "  return inputs, targets"
      ],
      "metadata": {
        "id": "SzNNcm12YBHJ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs, targets = data_process(train_iter, seq_len=65)\n",
        "inputs.shape, targets.shape"
      ],
      "metadata": {
        "id": "OdFAEKcwY0Fy",
        "outputId": "3b2a5fb7-16c2-41a7-8ed3-b583a99366bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32103, 65]), torch.Size([32103, 65]))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len = 35\n",
        "\n",
        "X_train, y_train = data_process(train_iter, seq_len)\n",
        "X_valid, y_valid = data_process(valid_iter, seq_len)\n",
        "X_test, y_test = data_process(test_iter, seq_len)\n",
        "\n",
        "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape, X_test.shape, y_test.shape"
      ],
      "metadata": {
        "id": "RUgan896Y_CK",
        "outputId": "331551c7-0756-4f57-9702-fdc04779eee0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([59620, 35]),\n",
              " torch.Size([59620, 35]),\n",
              " torch.Size([6233, 35]),\n",
              " torch.Size([6233, 35]),\n",
              " torch.Size([7034, 35]),\n",
              " torch.Size([7034, 35]))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Custom Dataset Class Definition\n",
        "  - (Map custom dataset used instead of iterable custom dataset because of small dataset length)"
      ],
      "metadata": {
        "id": "dPwnMNzRaBkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LanguageModelDataset(Dataset):\n",
        "\n",
        "  def __init__(self, inputs, targets):\n",
        "    self.inputs = inputs\n",
        "    self.targets = targets\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.inputs.shape[0]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.inputs[idx], self.targets[idx]"
      ],
      "metadata": {
        "id": "QzxqLeZ8aFcy"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = LanguageModelDataset(X_train, y_train)\n",
        "valid_set = LanguageModelDataset(X_valid, y_valid)\n",
        "test_set = LanguageModelDataset(X_test, y_test)"
      ],
      "metadata": {
        "id": "g7v1XHmqaIMX"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set[0]"
      ],
      "metadata": {
        "id": "NzWyetF0aMmB",
        "outputId": "8580637d-036f-438f-a693-7adfe98ddb1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([28782,     9,  3849,  3869,   881,     9, 28782, 28782, 20000,    83,\n",
              "          3849,    88,     0,  3869,    21,   780, 28780,     2,  6182,     3,\n",
              "          3849,     4,     1,  5023,    88,    20,     2,  1837,  1018,     7,\n",
              "            14,  3849,  3869,   881,   629]),\n",
              " tensor([    9,  3849,  3869,   881,     9, 28782, 28782, 20000,    83,  3849,\n",
              "            88,     0,  3869,    21,   780, 28780,     2,  6182,     3,  3849,\n",
              "             4,     1,  5023,    88,    20,     2,  1837,  1018,     7,    14,\n",
              "          3849,  3869,   881,   629,   976]))"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Data Loader"
      ],
      "metadata": {
        "id": "lVZr9EC2a9Q-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 20\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "jx0jsfNna7jw"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_batch, y_batch = next(iter(train_loader))\n",
        "x_batch.shape, y_batch.shape"
      ],
      "metadata": {
        "id": "UjsIn1HhbFbA",
        "outputId": "962aebc6-9efb-4433-9976-1e296cb176fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([20, 35]), torch.Size([20, 35]))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "xket0SftlL2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LanguageModel(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers,\n",
        "                dropout_embd=0.5, dropout_rnn=0.5):\n",
        "    super().__init__()\n",
        "    self.num_layers = num_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.embedding_dim = embedding_dim\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.embedding.weight.data.uniform_(-0.1, 0.1)\n",
        "    self.dropout = nn.Dropout(p=dropout_embd)\n",
        "\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers,\n",
        "                        dropout=dropout_rnn, batch_first=True)\n",
        "\n",
        "    self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "  def forward(self, src):\n",
        "    embedding = self.dropout(self.embedding(src))\n",
        "    output, hidden = self.lstm(embedding)\n",
        "    prediction = self.fc(output)\n",
        "    return prediction"
      ],
      "metadata": {
        "id": "FztWG0volNI9"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LanguageModel(vocab_size=len(vocab),\n",
        "                      embedding_dim=300,\n",
        "                      hidden_dim=512,\n",
        "                      num_layers=2,\n",
        "                      dropout_embd=0.65,\n",
        "                      dropout_rnn=0.5)\n",
        "model"
      ],
      "metadata": {
        "id": "vJ7WkV4ylPQd",
        "outputId": "36d83fec-324b-4fbb-9ebf-eb3a683fdaef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageModel(\n",
              "  (embedding): Embedding(28783, 300)\n",
              "  (dropout): Dropout(p=0.65, inplace=False)\n",
              "  (lstm): LSTM(300, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (fc): Linear(in_features=512, out_features=28783, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab), x_batch.shape, model(x_batch).shape"
      ],
      "metadata": {
        "id": "0ULB8-yDnBh2",
        "outputId": "23e6312d-8b67-49f8-df18-4642400ddf1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28783, torch.Size([20, 35]), torch.Size([20, 35, 28783]))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_trainable_params(model.embedding), num_trainable_params(model.lstm), num_trainable_params(model.fc)"
      ],
      "metadata": {
        "id": "kUkCVcJB_3GY",
        "outputId": "5d49a858-17f1-4a26-abc3-b64ec7dfee9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.6349, 3.76832, 14.765679)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuration"
      ],
      "metadata": {
        "id": "hvFUYkaR_99_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "id": "mH-ll-a3ABzv",
        "outputId": "0a3e08ba-98f6-4256-ad47-20c841861d9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab)\n",
        "embedding_dim = 300\n",
        "hidden_dim = 512\n",
        "num_layers = 2\n",
        "dropout_embd = 0.5\n",
        "dropout_rnn = 0.2\n",
        "\n",
        "model = LanguageModel(vocab_size, embedding_dim,\n",
        "                      hidden_dim, num_layers,\n",
        "                      dropout_embd, dropout_rnn).to(device)"
      ],
      "metadata": {
        "id": "2qefqKGHAENI"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.5, weight_decay=0, momentum=0.9, nesterov=True)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "metric = tm.text.Perplexity().to(device)"
      ],
      "metadata": {
        "id": "np8qNxCeAIEu"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clip = 0.25"
      ],
      "metadata": {
        "id": "wabnifRtAKuN"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "FxxqwtuHAPSM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and Evaluate Functions"
      ],
      "metadata": {
        "id": "yCXGRHSqARgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Functions\n",
        "def train_one_epoch(model, train_loader, loss_fn, optimizer, metric, epoch=None):\n",
        "  model.train()\n",
        "  loss_train = AverageMeter()\n",
        "  metric.reset()\n",
        "\n",
        "  with tqdm.tqdm(train_loader, unit='batch') as tepoch:\n",
        "    for inputs, targets in tepoch:\n",
        "      if epoch:\n",
        "        tepoch.set_description(f'Epoch {epoch}')\n",
        "\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      loss = loss_fn(outputs.reshape(-1, outputs.shape[-1]), targets.flatten())\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      nn.utils.clip_grad.clip_grad_norm_(model.parameters(), max_norm=clip)\n",
        "\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      loss_train.update(loss.item(), n=len(targets))\n",
        "      metric.update(outputs, targets)\n",
        "\n",
        "      tepoch.set_postfix(loss=loss_train.avg, metric=metric.compute().item())\n",
        "\n",
        "  return model, loss_train.avg, metric.compute().item()"
      ],
      "metadata": {
        "id": "wsh7lCOsAUf2"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Function\n",
        "def evaluate(model, test_loader, loss_fn, metric):\n",
        "  model.eval()\n",
        "  loss_eval = AverageMeter()\n",
        "  metric.reset()\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for inputs, targets in test_loader:\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      loss = loss_fn(outputs.reshape(-1, outputs.shape[-1]), targets.flatten())\n",
        "      loss_eval.update(loss.item(), n=len(targets))\n",
        "\n",
        "      metric(outputs, targets)\n",
        "\n",
        "  return loss_eval.avg, metric.compute().item()"
      ],
      "metadata": {
        "id": "mLvO6J2_BDbl"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Process and Tunning"
      ],
      "metadata": {
        "id": "mM5EA457BS5d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding Hyper-parameters"
      ],
      "metadata": {
        "id": "rOmBi5wVCTH1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Calculating the loss for untrained model using a few batches"
      ],
      "metadata": {
        "id": "OwesNxCICjdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for iter_num in range(5):\n",
        "  model = LanguageModel(len(vocab), embedding_dim=300,\n",
        "                        hidden_dim=512, num_layers=2,\n",
        "                        dropout_embd=0.5, dropout_rnn=0.2).to(device)\n",
        "\n",
        "  inputs, targets = next(iter(train_loader))\n",
        "  inputs = inputs.to(device)\n",
        "  targets = targets.to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    outputs = model(inputs)\n",
        "    loss = loss_fn(outputs.reshape(-1, outputs.shape[-1]), targets.flatten())\n",
        "\n",
        "  print(loss)"
      ],
      "metadata": {
        "id": "NaG9OAonBg2b",
        "outputId": "ef331aae-9e6d-4476-9f13-0d8775f4a749",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.2716, device='cuda:0')\n",
            "tensor(10.2680, device='cuda:0')\n",
            "tensor(10.2713, device='cuda:0')\n",
            "tensor(10.2687, device='cuda:0')\n",
            "tensor(10.2679, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Train and try to overfit the model on a small subset of the dataset."
      ],
      "metadata": {
        "id": "g4sjp-iPClmv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LanguageModel(len(vocab), embedding_dim=300,\n",
        "                      hidden_dim=512, num_layers=2,\n",
        "                      dropout_embd=0.5, dropout_rnn=0.2).to(device)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.9, momentum=0.9)"
      ],
      "metadata": {
        "id": "VXXqI6UXCbbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mini_train_size = 1000\n",
        "_, mini_train_dataset = random_split(train_set, (len(train_set)-mini_train_size, mini_train_size))\n",
        "mini_train_loader = DataLoader(mini_train_dataset, 20)"
      ],
      "metadata": {
        "id": "xQ5wEy6UCtPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "  model, _, _ = train_one_epoch(model, mini_train_loader, loss_fn, optimizer, metric, epoch)"
      ],
      "metadata": {
        "id": "K6xKuwZgCuz0",
        "outputId": "8654e917-33da-4e4f-cc01-45912f6b8574",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:02<00:00, 23.06batch/s, loss=8.36, metric=4.27e+3]\n",
            "Epoch 1: 100%|██████████| 50/50 [00:01<00:00, 26.91batch/s, loss=7.17, metric=1.3e+3]\n",
            "Epoch 2: 100%|██████████| 50/50 [00:01<00:00, 26.77batch/s, loss=6.97, metric=1.07e+3]\n",
            "Epoch 3: 100%|██████████| 50/50 [00:01<00:00, 26.41batch/s, loss=6.84, metric=934]\n",
            "Epoch 4: 100%|██████████| 50/50 [00:01<00:00, 26.04batch/s, loss=6.71, metric=817]\n",
            "Epoch 5: 100%|██████████| 50/50 [00:01<00:00, 26.39batch/s, loss=6.58, metric=720]\n",
            "Epoch 6: 100%|██████████| 50/50 [00:01<00:00, 26.43batch/s, loss=6.47, metric=645]\n",
            "Epoch 7: 100%|██████████| 50/50 [00:01<00:00, 26.27batch/s, loss=6.37, metric=586]\n",
            "Epoch 8: 100%|██████████| 50/50 [00:01<00:00, 26.23batch/s, loss=6.28, metric=536]\n",
            "Epoch 9: 100%|██████████| 50/50 [00:01<00:00, 26.28batch/s, loss=6.2, metric=493]\n",
            "Epoch 10: 100%|██████████| 50/50 [00:01<00:00, 26.03batch/s, loss=6.12, metric=453]\n",
            "Epoch 11: 100%|██████████| 50/50 [00:01<00:00, 25.75batch/s, loss=6.04, metric=418]\n",
            "Epoch 12: 100%|██████████| 50/50 [00:01<00:00, 25.31batch/s, loss=5.95, metric=384]\n",
            "Epoch 13: 100%|██████████| 50/50 [00:01<00:00, 25.80batch/s, loss=5.88, metric=357]\n",
            "Epoch 14: 100%|██████████| 50/50 [00:01<00:00, 25.94batch/s, loss=5.79, metric=328]\n",
            "Epoch 15: 100%|██████████| 50/50 [00:01<00:00, 25.97batch/s, loss=5.71, metric=302]\n",
            "Epoch 16: 100%|██████████| 50/50 [00:01<00:00, 25.70batch/s, loss=5.63, metric=278]\n",
            "Epoch 17: 100%|██████████| 50/50 [00:01<00:00, 25.34batch/s, loss=5.55, metric=256]\n",
            "Epoch 18: 100%|██████████| 50/50 [00:02<00:00, 24.78batch/s, loss=5.49, metric=241]\n",
            "Epoch 19: 100%|██████████| 50/50 [00:02<00:00, 24.82batch/s, loss=5.4, metric=222]\n",
            "Epoch 20: 100%|██████████| 50/50 [00:01<00:00, 25.58batch/s, loss=5.29, metric=199]\n",
            "Epoch 21: 100%|██████████| 50/50 [00:01<00:00, 25.50batch/s, loss=5.19, metric=180]\n",
            "Epoch 22: 100%|██████████| 50/50 [00:01<00:00, 25.75batch/s, loss=5.09, metric=162]\n",
            "Epoch 23: 100%|██████████| 50/50 [00:01<00:00, 25.29batch/s, loss=5, metric=149]\n",
            "Epoch 24: 100%|██████████| 50/50 [00:01<00:00, 25.39batch/s, loss=4.92, metric=136]\n",
            "Epoch 25: 100%|██████████| 50/50 [00:02<00:00, 24.87batch/s, loss=4.85, metric=127]\n",
            "Epoch 26: 100%|██████████| 50/50 [00:02<00:00, 24.93batch/s, loss=4.81, metric=122]\n",
            "Epoch 27: 100%|██████████| 50/50 [00:01<00:00, 25.76batch/s, loss=4.71, metric=111]\n",
            "Epoch 28: 100%|██████████| 50/50 [00:01<00:00, 25.92batch/s, loss=4.6, metric=100]\n",
            "Epoch 29: 100%|██████████| 50/50 [00:01<00:00, 25.94batch/s, loss=4.5, metric=90.2]\n",
            "Epoch 30: 100%|██████████| 50/50 [00:01<00:00, 25.96batch/s, loss=4.39, metric=80.7]\n",
            "Epoch 31: 100%|██████████| 50/50 [00:01<00:00, 25.92batch/s, loss=4.29, metric=72.9]\n",
            "Epoch 32: 100%|██████████| 50/50 [00:01<00:00, 25.02batch/s, loss=4.19, metric=66.2]\n",
            "Epoch 33: 100%|██████████| 50/50 [00:01<00:00, 25.40batch/s, loss=4.08, metric=59.1]\n",
            "Epoch 34: 100%|██████████| 50/50 [00:01<00:00, 25.84batch/s, loss=3.99, metric=53.8]\n",
            "Epoch 35: 100%|██████████| 50/50 [00:01<00:00, 26.16batch/s, loss=3.91, metric=50.1]\n",
            "Epoch 36: 100%|██████████| 50/50 [00:01<00:00, 26.12batch/s, loss=3.84, metric=46.7]\n",
            "Epoch 37: 100%|██████████| 50/50 [00:01<00:00, 25.78batch/s, loss=3.78, metric=44]\n",
            "Epoch 38: 100%|██████████| 50/50 [00:01<00:00, 26.03batch/s, loss=3.7, metric=40.5]\n",
            "Epoch 39: 100%|██████████| 50/50 [00:01<00:00, 25.78batch/s, loss=3.6, metric=36.5]\n",
            "Epoch 40: 100%|██████████| 50/50 [00:01<00:00, 25.24batch/s, loss=3.49, metric=32.7]\n",
            "Epoch 41: 100%|██████████| 50/50 [00:01<00:00, 25.69batch/s, loss=3.36, metric=28.9]\n",
            "Epoch 42: 100%|██████████| 50/50 [00:01<00:00, 26.06batch/s, loss=3.24, metric=25.5]\n",
            "Epoch 43: 100%|██████████| 50/50 [00:01<00:00, 26.18batch/s, loss=3.12, metric=22.6]\n",
            "Epoch 44: 100%|██████████| 50/50 [00:01<00:00, 25.97batch/s, loss=3.03, metric=20.7]\n",
            "Epoch 45: 100%|██████████| 50/50 [00:01<00:00, 26.10batch/s, loss=2.93, metric=18.6]\n",
            "Epoch 46: 100%|██████████| 50/50 [00:01<00:00, 26.01batch/s, loss=2.85, metric=17.3]\n",
            "Epoch 47: 100%|██████████| 50/50 [00:01<00:00, 25.40batch/s, loss=2.76, metric=15.7]\n",
            "Epoch 48: 100%|██████████| 50/50 [00:01<00:00, 25.90batch/s, loss=2.65, metric=14.2]\n",
            "Epoch 49: 100%|██████████| 50/50 [00:01<00:00, 26.18batch/s, loss=2.57, metric=13]\n",
            "Epoch 50: 100%|██████████| 50/50 [00:01<00:00, 25.98batch/s, loss=2.48, metric=12]\n",
            "Epoch 51: 100%|██████████| 50/50 [00:01<00:00, 25.99batch/s, loss=2.41, metric=11.2]\n",
            "Epoch 52: 100%|██████████| 50/50 [00:01<00:00, 26.00batch/s, loss=2.4, metric=11]\n",
            "Epoch 53: 100%|██████████| 50/50 [00:01<00:00, 26.02batch/s, loss=2.38, metric=10.8]\n",
            "Epoch 54: 100%|██████████| 50/50 [00:01<00:00, 25.31batch/s, loss=2.28, metric=9.79]\n",
            "Epoch 55: 100%|██████████| 50/50 [00:01<00:00, 25.22batch/s, loss=2.18, metric=8.84]\n",
            "Epoch 56: 100%|██████████| 50/50 [00:01<00:00, 25.88batch/s, loss=2.07, metric=7.94]\n",
            "Epoch 57: 100%|██████████| 50/50 [00:01<00:00, 25.80batch/s, loss=2.01, metric=7.46]\n",
            "Epoch 58: 100%|██████████| 50/50 [00:01<00:00, 26.03batch/s, loss=1.94, metric=6.96]\n",
            "Epoch 59: 100%|██████████| 50/50 [00:01<00:00, 26.15batch/s, loss=1.88, metric=6.52]\n",
            "Epoch 60: 100%|██████████| 50/50 [00:01<00:00, 25.97batch/s, loss=1.8, metric=6.05]\n",
            "Epoch 61: 100%|██████████| 50/50 [00:01<00:00, 25.29batch/s, loss=1.73, metric=5.63]\n",
            "Epoch 62: 100%|██████████| 50/50 [00:01<00:00, 25.46batch/s, loss=1.67, metric=5.33]\n",
            "Epoch 63: 100%|██████████| 50/50 [00:01<00:00, 25.82batch/s, loss=1.59, metric=4.9]\n",
            "Epoch 64: 100%|██████████| 50/50 [00:01<00:00, 25.76batch/s, loss=1.54, metric=4.67]\n",
            "Epoch 65: 100%|██████████| 50/50 [00:01<00:00, 25.84batch/s, loss=1.47, metric=4.35]\n",
            "Epoch 66: 100%|██████████| 50/50 [00:01<00:00, 26.03batch/s, loss=1.4, metric=4.06]\n",
            "Epoch 67: 100%|██████████| 50/50 [00:01<00:00, 25.95batch/s, loss=1.32, metric=3.75]\n",
            "Epoch 68: 100%|██████████| 50/50 [00:01<00:00, 25.35batch/s, loss=1.26, metric=3.51]\n",
            "Epoch 69: 100%|██████████| 50/50 [00:01<00:00, 25.45batch/s, loss=1.17, metric=3.24]\n",
            "Epoch 70: 100%|██████████| 50/50 [00:01<00:00, 25.55batch/s, loss=1.1, metric=3.01]\n",
            "Epoch 71: 100%|██████████| 50/50 [00:01<00:00, 25.74batch/s, loss=1, metric=2.73]\n",
            "Epoch 72: 100%|██████████| 50/50 [00:01<00:00, 25.86batch/s, loss=0.938, metric=2.56]\n",
            "Epoch 73: 100%|██████████| 50/50 [00:01<00:00, 25.92batch/s, loss=0.87, metric=2.39]\n",
            "Epoch 74: 100%|██████████| 50/50 [00:01<00:00, 25.70batch/s, loss=0.8, metric=2.23]\n",
            "Epoch 75: 100%|██████████| 50/50 [00:01<00:00, 25.65batch/s, loss=0.747, metric=2.11]\n",
            "Epoch 76: 100%|██████████| 50/50 [00:01<00:00, 25.62batch/s, loss=0.717, metric=2.05]\n",
            "Epoch 77: 100%|██████████| 50/50 [00:01<00:00, 25.29batch/s, loss=0.665, metric=1.94]\n",
            "Epoch 78: 100%|██████████| 50/50 [00:01<00:00, 25.84batch/s, loss=0.625, metric=1.87]\n",
            "Epoch 79: 100%|██████████| 50/50 [00:01<00:00, 26.09batch/s, loss=0.601, metric=1.82]\n",
            "Epoch 80: 100%|██████████| 50/50 [00:01<00:00, 25.79batch/s, loss=0.574, metric=1.78]\n",
            "Epoch 81: 100%|██████████| 50/50 [00:01<00:00, 25.87batch/s, loss=0.547, metric=1.73]\n",
            "Epoch 82: 100%|██████████| 50/50 [00:01<00:00, 25.69batch/s, loss=0.527, metric=1.69]\n",
            "Epoch 83: 100%|██████████| 50/50 [00:01<00:00, 25.34batch/s, loss=0.51, metric=1.66]\n",
            "Epoch 84: 100%|██████████| 50/50 [00:01<00:00, 25.01batch/s, loss=0.49, metric=1.63]\n",
            "Epoch 85: 100%|██████████| 50/50 [00:01<00:00, 26.15batch/s, loss=0.462, metric=1.59]\n",
            "Epoch 86: 100%|██████████| 50/50 [00:01<00:00, 26.04batch/s, loss=0.454, metric=1.57]\n",
            "Epoch 87: 100%|██████████| 50/50 [00:01<00:00, 26.01batch/s, loss=0.443, metric=1.56]\n",
            "Epoch 88: 100%|██████████| 50/50 [00:01<00:00, 25.96batch/s, loss=0.417, metric=1.52]\n",
            "Epoch 89: 100%|██████████| 50/50 [00:01<00:00, 26.06batch/s, loss=0.39, metric=1.48]\n",
            "Epoch 90: 100%|██████████| 50/50 [00:01<00:00, 25.73batch/s, loss=0.375, metric=1.46]\n",
            "Epoch 91: 100%|██████████| 50/50 [00:01<00:00, 25.48batch/s, loss=0.346, metric=1.41]\n",
            "Epoch 92: 100%|██████████| 50/50 [00:01<00:00, 25.81batch/s, loss=0.323, metric=1.38]\n",
            "Epoch 93: 100%|██████████| 50/50 [00:01<00:00, 25.83batch/s, loss=0.306, metric=1.36]\n",
            "Epoch 94: 100%|██████████| 50/50 [00:01<00:00, 25.77batch/s, loss=0.296, metric=1.34]\n",
            "Epoch 95: 100%|██████████| 50/50 [00:01<00:00, 25.71batch/s, loss=0.281, metric=1.32]\n",
            "Epoch 96: 100%|██████████| 50/50 [00:01<00:00, 25.76batch/s, loss=0.27, metric=1.31]\n",
            "Epoch 97: 100%|██████████| 50/50 [00:01<00:00, 25.02batch/s, loss=0.264, metric=1.3]\n",
            "Epoch 98: 100%|██████████| 50/50 [00:01<00:00, 25.36batch/s, loss=0.252, metric=1.29]\n",
            "Epoch 99: 100%|██████████| 50/50 [00:01<00:00, 25.68batch/s, loss=0.247, metric=1.28]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  Train the model for a limited number of epochs, experimenting with various learning rates to find best value"
      ],
      "metadata": {
        "id": "1rpWRYL8EKGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 1\n",
        "\n",
        "for lr in [8, 5, 2, 0.7, 0.5, 0.2]:\n",
        "  print(f'LR={lr}')\n",
        "\n",
        "  model = LanguageModel(len(vocab), embedding_dim=300,\n",
        "                      hidden_dim=512, num_layers=2,\n",
        "                      dropout_embd=0.5, dropout_rnn=0.2).to(device)\n",
        "  # model = torch.load('/content/model-ppl_147.pt')\n",
        "\n",
        "  # optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=0, momentum=0.9)\n",
        "  optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=1e-6, momentum=0.9)\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    model, _, _ = train_one_epoch(model, train_loader, loss_fn, optimizer, metric, epoch)\n",
        "\n",
        "  print()"
      ],
      "metadata": {
        "id": "rRw-nmIRD5a0",
        "outputId": "268319e2-0603-4351-f8bc-12d63386b53b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR=8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2981/2981 [01:56<00:00, 25.67batch/s, loss=5.75, metric=314]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LR=5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2981/2981 [01:59<00:00, 24.88batch/s, loss=5.75, metric=315]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LR=2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 2614/2981 [01:42<00:14, 25.45batch/s, loss=5.95, metric=382]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-57a541a2b1a6>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-59-870050b25dc7>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_loader, loss_fn, optimizer, metric, epoch)\u001b[0m\n\u001b[1;32m     27\u001b[0m       \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m       \u001b[0mtepoch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mset_postfix\u001b[0;34m(self, ordered_dict, refresh, **kwargs)\u001b[0m\n\u001b[1;32m   1429\u001b[0m                                  for key in postfix.keys())\n\u001b[1;32m   1430\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrefresh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_postfix_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mrefresh\u001b[0;34m(self, nolock, lock_args)\u001b[0m\n\u001b[1;32m   1345\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1348\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnolock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(self, msg, pos)\u001b[0m\n\u001b[1;32m   1493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1495\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mprint_status\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mprint_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0mlen_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisp_len\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m             \u001b[0mfp_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\r'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_len\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m             \u001b[0mlast_len\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen_s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mfp_write\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfp_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m             \u001b[0mfp_flush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/utils.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;31m# mp.Pool cannot be trusted to flush promptly (or ever),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    618\u001b[0m                 )\n\u001b[1;32m    619\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     def send_multipart(\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Creat a small grid search to find exact value of lr and weight decay"
      ],
      "metadata": {
        "id": "Fc4ggzJrETOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 2\n",
        "\n",
        "for lr in [8.]:\n",
        "  for wd in [1e-6, 1e-5, 1e-4]:\n",
        "    print(f'LR={lr}, WD={wd}')\n",
        "\n",
        "    model = LanguageModel(len(vocab), embedding_dim=300,\n",
        "                      hidden_dim=512, num_layers=2,\n",
        "                      dropout_embd=0.5, dropout_rnn=0.2).to(device)\n",
        "\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=0.9)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      model, _, _ = train_one_epoch(model, train_loader, loss_fn, optimizer, metric, epoch)\n",
        "\n",
        "    print()"
      ],
      "metadata": {
        "id": "g-TuGszbEPtW",
        "outputId": "5eba232a-9671-423a-d23a-d6f04bfd2071",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR=8.0, WD=1e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2981/2981 [01:57<00:00, 25.40batch/s, loss=5.76, metric=316]\n",
            "Epoch 1: 100%|██████████| 2981/2981 [02:00<00:00, 24.67batch/s, loss=5.34, metric=209]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LR=8.0, WD=1e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2981/2981 [01:54<00:00, 25.98batch/s, loss=5.83, metric=339]\n",
            "Epoch 1: 100%|██████████| 2981/2981 [01:59<00:00, 24.98batch/s, loss=5.48, metric=239]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LR=8.0, WD=0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2981/2981 [01:54<00:00, 26.14batch/s, loss=6.36, metric=576]\n",
            "Epoch 1: 100%|██████████| 2981/2981 [01:58<00:00, 25.07batch/s, loss=6.27, metric=528]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Train model for more epochs using the best hyperparameters"
      ],
      "metadata": {
        "id": "LBhtQUjHEaxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LanguageModel(len(vocab), embedding_dim=300,\n",
        "                      hidden_dim=512, num_layers=2,\n",
        "                      dropout_embd=0.5, dropout_rnn=0.5).to(device)"
      ],
      "metadata": {
        "id": "wzuhcj6pEXlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 8\n",
        "wd = 1e-6\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=0.9)"
      ],
      "metadata": {
        "id": "jZezO_4mEftc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_train_hist = []\n",
        "loss_valid_hist = []\n",
        "\n",
        "metric_train_hist = []\n",
        "metric_valid_hist = []\n",
        "\n",
        "best_loss_valid = torch.inf\n",
        "epoch_counter = 0\n",
        "best_loss_epoch = None"
      ],
      "metadata": {
        "id": "2MTINOHHEhb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "  # Train\n",
        "  model, loss_train, metric_train = train_one_epoch(model,\n",
        "                                                    train_loader,\n",
        "                                                    loss_fn,\n",
        "                                                    optimizer,\n",
        "                                                    metric,\n",
        "                                                    epoch)\n",
        "  # Validation\n",
        "  loss_valid, metric_valid = evaluate(model,\n",
        "                                      valid_loader,\n",
        "                                      loss_fn,\n",
        "                                      metric)\n",
        "\n",
        "  loss_train_hist.append(loss_train)\n",
        "  loss_valid_hist.append(loss_valid)\n",
        "\n",
        "  metric_train_hist.append(metric_train)\n",
        "  metric_valid_hist.append(metric_valid)\n",
        "\n",
        "  if loss_valid < best_loss_valid:\n",
        "    torch.save(model, f'modelpt')\n",
        "    best_loss_valid = loss_valid\n",
        "    best_loss_epoch = epoch\n",
        "    print('Model Saved!')\n",
        "\n",
        "  print(f'Valid: Loss = {loss_valid:.4}, Metric = {metric_valid:.4}')\n",
        "  print()\n",
        "\n",
        "  epoch_counter += 1"
      ],
      "metadata": {
        "id": "cnZeh15xEkcl",
        "outputId": "ff161f20-f0f7-4ad6-8b66-2c30e2fd2de0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 2981/2981 [01:59<00:00, 24.99batch/s, loss=5.84, metric=345]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 5.394, Metric = 220.1\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 2981/2981 [01:59<00:00, 24.92batch/s, loss=5.51, metric=248]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 5.297, Metric = 199.7\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 2981/2981 [01:59<00:00, 24.99batch/s, loss=5.39, metric=220]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 5.253, Metric = 191.2\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 2981/2981 [01:59<00:00, 25.05batch/s, loss=5.3, metric=201]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 5.218, Metric = 184.5\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 2981/2981 [02:00<00:00, 24.83batch/s, loss=5.23, metric=188]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 5.222, Metric = 185.3\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 2981/2981 [02:00<00:00, 24.73batch/s, loss=5.18, metric=177]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 5.162, Metric = 174.4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 2981/2981 [02:00<00:00, 24.83batch/s, loss=5.13, metric=169]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 5.159, Metric = 174.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 2981/2981 [01:59<00:00, 24.88batch/s, loss=5.09, metric=162]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 5.164, Metric = 174.9\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 2981/2981 [01:59<00:00, 24.96batch/s, loss=5.05, metric=157]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 5.165, Metric = 175.1\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 2981/2981 [01:59<00:00, 25.04batch/s, loss=5.02, metric=152]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 5.198, Metric = 180.9\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| 2981/2981 [01:59<00:00, 25.03batch/s, loss=5, metric=148]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 5.154, Metric = 173.1\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12:  77%|███████▋  | 2288/2981 [01:31<00:27, 24.99batch/s, loss=4.95, metric=141]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-2e13ec4bfef0>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   model, loss_train, metric_train = train_one_epoch(model,\n\u001b[0m\u001b[1;32m      6\u001b[0m                                                     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                                     \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-59-870050b25dc7>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_loader, loss_fn, optimizer, metric, epoch)\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m       \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouped_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforeach\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mforeach\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_has_foreach_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_mul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_coef_clamped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-overload]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mforeach\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'foreach=True was passed, but can\\'t use the foreach API on {device.type} tensors'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main Train Loop"
      ],
      "metadata": {
        "id": "e0dMrsH6E_Qq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('/content/model-135.pt')\n",
        "# torch.save(model, f'model.pt')\n",
        "shutil.copyfile(\"model-135.pt\", \"/content/drive/MyDrive/LanguageModel/model-135.pt\")"
      ],
      "metadata": {
        "id": "lrxajJVlFAtt",
        "outputId": "6764b6b4-8f79-4cf3-e00e-be3c8d185151",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/LanguageModel/model-135.pt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "# shutil.copyfile(\"model-145.pt\", \"/content/drive/MyDrive/LanguageModel/model-145.pt\")"
      ],
      "metadata": {
        "id": "RQlBQwWYWhwx"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.35\n",
        "wd = 1e-6\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=0.9)"
      ],
      "metadata": {
        "id": "OuK52y5bFCNi"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_train_hist = []\n",
        "loss_valid_hist = []\n",
        "\n",
        "metric_train_hist = []\n",
        "metric_valid_hist = []\n",
        "\n",
        "best_loss_valid = torch.inf\n",
        "epoch_counter = 0"
      ],
      "metadata": {
        "id": "QczG3kJzFDnT"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  # Train\n",
        "  model, loss_train, metric_train = train_one_epoch(model,\n",
        "                                                    train_loader,\n",
        "                                                    loss_fn,\n",
        "                                                    optimizer,\n",
        "                                                    metric,\n",
        "                                                    epoch)\n",
        "  # Validation\n",
        "  loss_valid, metric_valid = evaluate(model,\n",
        "                                      valid_loader,\n",
        "                                      loss_fn,\n",
        "                                      metric)\n",
        "\n",
        "\n",
        "  loss_train_hist.append(loss_train)\n",
        "  loss_valid_hist.append(loss_valid)\n",
        "\n",
        "  metric_train_hist.append(metric_train)\n",
        "  metric_valid_hist.append(metric_valid)\n",
        "\n",
        "  if loss_valid < best_loss_valid:\n",
        "    torch.save(model, f'model.pt')\n",
        "    best_loss_valid = loss_valid\n",
        "    best_loss_epoch = epoch\n",
        "    print('Model Saved!')\n",
        "\n",
        "  print(f'Valid: Loss = {loss_valid:.4}, Metric = {metric_valid:.4}')\n",
        "  print()\n",
        "\n",
        "  epoch_counter += 1"
      ],
      "metadata": {
        "id": "FCFiP3saFFCL",
        "outputId": "5aaf63ac-f216-4776-bdc6-89e2d6e532df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2981/2981 [01:55<00:00, 25.90batch/s, loss=3.96, metric=52.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 4.908, Metric = 135.4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 2981/2981 [01:58<00:00, 25.15batch/s, loss=3.95, metric=51.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 4.908, Metric = 135.4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 2981/2981 [01:58<00:00, 25.09batch/s, loss=3.93, metric=51]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 4.916, Metric = 136.5\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 2981/2981 [01:59<00:00, 25.03batch/s, loss=3.92, metric=50.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 4.909, Metric = 135.6\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 2981/2981 [01:58<00:00, 25.17batch/s, loss=3.91, metric=49.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 4.914, Metric = 136.2\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 2981/2981 [01:58<00:00, 25.15batch/s, loss=3.9, metric=49.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 4.912, Metric = 135.9\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 2981/2981 [01:58<00:00, 25.18batch/s, loss=3.89, metric=48.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 4.917, Metric = 136.6\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 2981/2981 [01:58<00:00, 25.17batch/s, loss=3.88, metric=48.3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 4.917, Metric = 136.6\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 2981/2981 [01:59<00:00, 24.94batch/s, loss=3.87, metric=47.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 4.922, Metric = 137.3\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 2981/2981 [01:58<00:00, 25.18batch/s, loss=3.86, metric=47.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 4.926, Metric = 137.8\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 2981/2981 [01:58<00:00, 25.22batch/s, loss=3.85, metric=46.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 4.921, Metric = 137.1\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| 2981/2981 [01:59<00:00, 25.03batch/s, loss=3.84, metric=46.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 4.929, Metric = 138.2\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|██████████| 2981/2981 [01:58<00:00, 25.21batch/s, loss=3.83, metric=46]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 4.922, Metric = 137.3\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13: 100%|██████████| 2981/2981 [01:58<00:00, 25.22batch/s, loss=3.82, metric=45.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 4.925, Metric = 137.7\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14: 100%|██████████| 2981/2981 [01:58<00:00, 25.23batch/s, loss=3.81, metric=45.2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 4.931, Metric = 138.5\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15: 100%|██████████| 2981/2981 [01:58<00:00, 25.22batch/s, loss=3.8, metric=44.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 4.934, Metric = 138.9\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16: 100%|██████████| 2981/2981 [01:58<00:00, 25.21batch/s, loss=3.79, metric=44.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 4.932, Metric = 138.7\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17: 100%|██████████| 2981/2981 [01:57<00:00, 25.30batch/s, loss=3.78, metric=44]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 4.939, Metric = 139.6\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18: 100%|██████████| 2981/2981 [01:57<00:00, 25.37batch/s, loss=3.78, metric=43.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 4.942, Metric = 140.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19: 100%|██████████| 2981/2981 [01:57<00:00, 25.37batch/s, loss=3.77, metric=43.2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 4.945, Metric = 140.5\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot Learning Curve"
      ],
      "metadata": {
        "id": "OCU-cdlzEyQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "plt.plot(range(epoch_counter), loss_train_hist, 'r-', label='Train')\n",
        "plt.plot(range(epoch_counter), loss_valid_hist, 'b-', label='Validation')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.grid(True)\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "_JvsLg3UEzoL",
        "outputId": "0ed4c32a-33a4-4866-d433-74d792a9b4cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x798415f79e10>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "IPrmksmuTgNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/drive/MyDrive/LanguageModel/Model-ppl134.pt'\n",
        "model = torch.load(model_path)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "LE8dVVq7Tf1A",
        "outputId": "3e093d3f-cf89-4522-e5d7-d448f338e69f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageModel(\n",
              "  (embedding): Embedding(28783, 300)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (lstm): LSTM(300, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (fc): Linear(in_features=512, out_features=28783, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_test, metric_test = evaluate(model, test_loader, loss_fn, metric)\n",
        "loss_test, metric_test"
      ],
      "metadata": {
        "id": "jx6ZVuKATrZb",
        "outputId": "72bd7c7e-76a2-4086-ad10-642f0c8ce9f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4.840373967430759, 126.516845703125)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate"
      ],
      "metadata": {
        "id": "Ua8iuf06UpDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/drive/MyDrive/LanguageModel/Model-ppl134.pt'\n",
        "model = torch.load(model_path)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "Lp-UXAISUta6",
        "outputId": "81b9445e-50b8-477e-f016-57140a2e808e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageModel(\n",
              "  (embedding): Embedding(28783, 300)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (lstm): LSTM(300, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (fc): Linear(in_features=512, out_features=28783, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(prompt, max_seq_len, temperature, model, tokenizer, vocab, seed=None):\n",
        "\n",
        "  indices = vocab(tokenizer(prompt))\n",
        "  itos = vocab.get_itos()\n",
        "\n",
        "  for i in range(max_seq_len):\n",
        "    src = torch.LongTensor(indices).to(device)\n",
        "    with torch.no_grad():\n",
        "      prediction = model(src)\n",
        "\n",
        "    # Low values like 0.1 for temperature, Makes softmax like argmax more\n",
        "    probs = torch.softmax(prediction[-1]/temperature, dim = 0)\n",
        "    idx = vocab[\"<ukn>\"]\n",
        "    while idx == vocab[\"<ukn>\"]:\n",
        "      idx = torch.multinomial(probs, num_samples =1).item()\n",
        "    indices.append(idx)\n",
        "    prompt += \" \" + itos[idx]\n",
        "    # print(prompt)\n",
        "\n",
        "    if idx == vocab[\".\"]:\n",
        "      return prompt"
      ],
      "metadata": {
        "id": "4SZR5XALiwl0"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"as i know about this subject,\"\n",
        "generate(prompt, 40, 0.5, model, tokenizer, vocab, seed=None)"
      ],
      "metadata": {
        "id": "jgsHMaf4jWCg",
        "outputId": "da0519d3-6647-49c9-df6b-37f7986227cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'as i know about this subject, my life is not necessarily understood , but it is not my own .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    }
  ]
}