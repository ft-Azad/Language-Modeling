{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "-w94hRxp2pTi"
      ],
      "gpuType": "T4",
      "mount_file_id": "1bOQm_t_04AoT_eswlRzS4oAIr_74-DQ_",
      "authorship_tag": "ABX9TyPwxzwbi5tcMK1XZZfYxZXO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ft-Azad/Language-Modeling/blob/main/LanguageModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Import Libs"
      ],
      "metadata": {
        "id": "LrWocfpm2aet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torchmetrics\n",
        "!pip install -q torchdata==0.6.1\n",
        "!pip install 'portalocker>=2.0.0'\n",
        "!pip install torchtext==0.15.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hsog-ccz2l3C",
        "outputId": "ff730710-8aac-4877-cbe3-1f11d7df288b",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.3.0+cu121 requires torch==2.3.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.18.0+cu121 requires torch==2.3.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting portalocker>=2.0.0\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: portalocker\n",
            "Successfully installed portalocker-2.8.2\n",
            "Collecting torchtext==0.15.1\n",
            "  Downloading torchtext-0.15.1-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.1) (4.66.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.1) (2.31.0)\n",
            "Collecting torch==2.0.0 (from torchtext==0.15.1)\n",
            "  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.1) (1.25.2)\n",
            "Collecting torchdata==0.6.0 (from torchtext==0.15.1)\n",
            "  Downloading torchdata-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m103.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (2.0.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.6.0->torchtext==0.15.1) (2.0.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchtext==0.15.1) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchtext==0.15.1) (0.43.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->torchtext==0.15.1) (3.27.9)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->torchtext==0.15.1) (18.1.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.15.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.15.1) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.15.1) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0->torchtext==0.15.1) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0->torchtext==0.15.1) (1.3.0)\n",
            "Installing collected packages: torch, torchdata, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1\n",
            "    Uninstalling torch-2.0.1:\n",
            "      Successfully uninstalled torch-2.0.1\n",
            "  Attempting uninstall: torchdata\n",
            "    Found existing installation: torchdata 0.6.1\n",
            "    Uninstalling torchdata-0.6.1:\n",
            "      Successfully uninstalled torchdata-0.6.1\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.18.0\n",
            "    Uninstalling torchtext-0.18.0:\n",
            "      Successfully uninstalled torchtext-0.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.3.0+cu121 requires torch==2.3.0, but you have torch 2.0.0 which is incompatible.\n",
            "torchvision 0.18.0+cu121 requires torch==2.3.0, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.0.0 torchdata-0.6.0 torchtext-0.15.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "dQ1anJGt2Mpy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torchtext\n",
        "from torchtext.datasets import WikiText2\n",
        "from torchdata.datapipes.iter import IterableWrapper, Mapper\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "\n",
        "from torch import optim\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import tqdm\n",
        "import torchmetrics as tm\n",
        "\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for lib in [np, torch, torchtext, tqdm]:\n",
        "  print(lib.__name__, '-->', lib.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvWpZ1HX_bSA",
        "outputId": "e6da869e-6d9c-4f61-c28e-2265c1434189"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy --> 1.25.2\n",
            "torch --> 2.0.0+cu117\n",
            "torchtext --> 0.15.1+cpu\n",
            "tqdm --> 4.66.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "-w94hRxp2pTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/ft-Azad/Language-Modeling"
      ],
      "metadata": {
        "id": "4_LL1lCDbqJG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd .."
      ],
      "metadata": {
        "id": "zUQ--C2pbwxA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %ls"
      ],
      "metadata": {
        "id": "r0sXUc8bb1Dt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "metadata": {
        "id": "Ij8w30J-2tnS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def num_trainable_params(model):\n",
        "  nums = sum(p.numel() for p in model.parameters() if p.requires_grad)/1e6\n",
        "  return nums"
      ],
      "metadata": {
        "id": "26kq60x63kob"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset"
      ],
      "metadata": {
        "id": "74jt_Yh33n5b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Dataset and Build Vocab"
      ],
      "metadata": {
        "id": "iydE_C3PJJ7n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Loading Iterable Data"
      ],
      "metadata": {
        "id": "TiMde3clWmRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train_iter, valid_iter, test_iter = WikiText2('/content/')"
      ],
      "metadata": {
        "id": "sLLLrs3MSrs4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "bypjg0BrVsUS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d082ee88-a94a-4446-af40-6aaf112f2f0b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q \"/content/drive/MyDrive/LanguageModel/Data/wikitext-2-v1.zip\" -d '/content/'"
      ],
      "metadata": {
        "id": "LWLs34TRVuSh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/wikitext-2/wiki.train.tokens', 'r') as file:\n",
        "    train_iter = file.read().splitlines()\n",
        "\n",
        "with open('/content/wikitext-2/wiki.test.tokens', 'r') as file:\n",
        "    test_iter = file.read().splitlines()\n",
        "\n",
        "with open('/content/wikitext-2/wiki.valid.tokens', 'r') as file:\n",
        "    valid_iter = file.read().splitlines()\n",
        "\n",
        "train_iter = IterableWrapper(train_iter)\n",
        "test_iter = IterableWrapper(test_iter)\n",
        "valid_iter = IterableWrapper(valid_iter)"
      ],
      "metadata": {
        "id": "CUxmY_-YV6Uh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter_ = iter(train_iter)\n",
        "train_iter_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wfCsHfKUaS6",
        "outputId": "e595b20c-875b-44ce-b4a6-291b5462ef1b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object IterableWrapperIterDataPipe.__iter__ at 0x79d8503d23b0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(train_iter_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "8EUQiZ4vUbp0",
        "outputId": "f90d15eb-d34b-469e-f5b4-b610cc09c286"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Build Vocabulary"
      ],
      "metadata": {
        "id": "8Wxz-msVWt_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "txt = ['@Azad hi Azad! 1 n2 3 #45', 'how are are you?']\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "[tokenizer(line) for line in txt]\n",
        "list(map(tokenizer, txt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQl8SjQnWvUs",
        "outputId": "fd3b2936-2123-4bbb-a381-ce5ce53ec9ff"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['@azad', 'hi', 'azad', '!', '1', 'n2', '3', '#45'],\n",
              " ['how', 'are', 'are', 'you', '?']]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = build_vocab_from_iterator(map(tokenizer, txt), specials=['<ukn>'], min_freq=1)\n",
        "vocab.set_default_index(vocab['<ukn>'])\n",
        "vocab.get_stoi()"
      ],
      "metadata": {
        "id": "_foahipTWzhG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ebb8d24-5dfe-49c3-d527-f4b7cc31c2c5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n2': 11,\n",
              " 'how': 10,\n",
              " 'you': 12,\n",
              " 'hi': 9,\n",
              " 'azad': 8,\n",
              " '@azad': 7,\n",
              " '?': 6,\n",
              " '3': 5,\n",
              " '1': 4,\n",
              " '#45': 3,\n",
              " '!': 2,\n",
              " 'are': 1,\n",
              " '<ukn>': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab(['hi', 'azad', '<ukn>', 'hello', 'Hi'.lower()])"
      ],
      "metadata": {
        "id": "BqZ1FMgNW1S5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cdf6963-2bb2-48ef-f95f-4e30578f266c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[9, 8, 0, 0, 9]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = get_tokenizer('basic_english')\n",
        "vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=['<unk>'])\n",
        "vocab.set_default_index(vocab['<unk>'])\n",
        "vocab.append_token(\"<eos>\")"
      ],
      "metadata": {
        "id": "umEf8CYR708R"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33uGKNRm9sbH",
        "outputId": "980feddc-cee2-48dc-86c3-866fa0efe1c4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28783"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(vocab, 'vocab.pt')\n",
        "torch.save(vocab, '/content/drive/MyDrive/LanguageModel/vocab.pt')"
      ],
      "metadata": {
        "id": "GRaq3bHc9vBT"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Properties (EDA)\n"
      ],
      "metadata": {
        "id": "7Bt_IQRqJeM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_sentence_count = 0\n",
        "total_sentence_length = 0\n",
        "\n",
        "for line in train_iter:\n",
        "    sentences = line.split('.')\n",
        "\n",
        "    for sentence in sentences:\n",
        "        tokens = sentence.strip().split()\n",
        "        sentence_length = len(tokens)\n",
        "\n",
        "        if sentence_length > 0:\n",
        "            total_sentence_count += 1\n",
        "            total_sentence_length += sentence_length\n",
        "\n",
        "mean_sentence_length = total_sentence_length / total_sentence_count\n",
        "\n",
        "print(f'Mean sentence length in Wikitext-2: {mean_sentence_length:.2f}')"
      ],
      "metadata": {
        "id": "WzIcSUrvIKRn",
        "outputId": "a4ba53f2-a67a-4217-8e70-6e4a8b8a04bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean sentence length in Wikitext-2: 21.69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freqs = Counter()\n",
        "for tokens in map(tokenizer, train_iter):\n",
        "  freqs.update(tokens)"
      ],
      "metadata": {
        "id": "Uul73nXgNtGi"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freqs.most_common()[:50]"
      ],
      "metadata": {
        "id": "ZgYuzdVDN9Z6",
        "outputId": "b11db208-d2e3-40e2-8a8c-5fb0f5d45579",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 130768),\n",
              " (',', 102615),\n",
              " ('.', 83397),\n",
              " ('of', 57030),\n",
              " ('<unk>', 54625),\n",
              " ('and', 50735),\n",
              " ('in', 45015),\n",
              " ('to', 39521),\n",
              " ('a', 36523),\n",
              " ('=', 29570),\n",
              " ('was', 21008),\n",
              " (\"'\", 18484),\n",
              " ('@-@', 16906),\n",
              " ('on', 15140),\n",
              " ('as', 15058),\n",
              " ('s', 14936),\n",
              " ('that', 14351),\n",
              " ('for', 13794),\n",
              " ('with', 13012),\n",
              " ('by', 12718),\n",
              " (')', 12004),\n",
              " ('(', 11992),\n",
              " ('@', 11786),\n",
              " ('is', 11691),\n",
              " ('it', 9273),\n",
              " ('from', 9229),\n",
              " ('at', 9070),\n",
              " ('his', 9019),\n",
              " ('he', 8706),\n",
              " ('were', 7334),\n",
              " ('an', 6250),\n",
              " ('had', 5707),\n",
              " ('which', 5546),\n",
              " ('be', 4859),\n",
              " ('are', 4714),\n",
              " ('this', 4560),\n",
              " ('their', 4290),\n",
              " ('first', 4242),\n",
              " ('but', 4233),\n",
              " ('not', 4006),\n",
              " ('–', 3934),\n",
              " ('one', 3910),\n",
              " ('they', 3894),\n",
              " ('its', 3877),\n",
              " ('also', 3842),\n",
              " ('after', 3749),\n",
              " ('her', 3670),\n",
              " ('or', 3655),\n",
              " ('two', 3565),\n",
              " ('have', 3470)]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freqs.most_common()[::-1][:50]"
      ],
      "metadata": {
        "id": "6Q5AEGOuOBXL",
        "outputId": "0dfe3af4-0356-4276-8686-f3ebf489063d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('gallinae', 3),\n",
              " ('intergrades', 3),\n",
              " ('northeasterly', 3),\n",
              " ('tuscola', 3),\n",
              " ('roundabouts', 3),\n",
              " ('zoromski', 3),\n",
              " ('forrester', 3),\n",
              " ('kreutzer', 3),\n",
              " ('prefaced', 3),\n",
              " ('philipp', 3),\n",
              " ('chants', 3),\n",
              " ('sonatine', 3),\n",
              " ('mineurs', 3),\n",
              " ('étude', 3),\n",
              " ('caprices', 3),\n",
              " ('lewenthal', 3),\n",
              " ('spruces', 3),\n",
              " ('secretion', 3),\n",
              " ('tomentum', 3),\n",
              " ('yellowwoods', 3),\n",
              " ('echinodontium', 3),\n",
              " ('urocerus', 3),\n",
              " ('γ', 3),\n",
              " ('2γ', 3),\n",
              " ('2e', 3),\n",
              " ('tauri', 3),\n",
              " ('supergiants', 3),\n",
              " ('flamsteed', 3),\n",
              " ('novae', 3),\n",
              " ('sn', 3),\n",
              " ('hipparchus', 3),\n",
              " ('radiative', 3),\n",
              " ('dope', 3),\n",
              " ('shaggy', 3),\n",
              " ('utsler', 3),\n",
              " ('psychopathic', 3),\n",
              " ('brunette', 3),\n",
              " ('aar', 3),\n",
              " ('gigalitres', 3),\n",
              " ('jodidio', 3),\n",
              " ('barco', 3),\n",
              " ('puckering', 3),\n",
              " ('saic', 3),\n",
              " ('krueck', 3),\n",
              " ('squirtle', 3),\n",
              " ('schauenburg', 3),\n",
              " ('mechtshausen', 3),\n",
              " ('drunkards', 3),\n",
              " ('schopenhauer', 3),\n",
              " ('kremplsetzer', 3)]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Prepreation"
      ],
      "metadata": {
        "id": "s0PpL09pVN-5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Creat Target Array"
      ],
      "metadata": {
        "id": "F9G2WfByYIIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_process(raw_text_iter, seq_len):\n",
        "  data = torch.cat([torch.LongTensor(vocab(tokenizer(line)) + vocab([\"<eos>\"])) for line in raw_text_iter])\n",
        "\n",
        "  M = len(data) // seq_len\n",
        "\n",
        "  r = len(data) % seq_len\n",
        "  data = torch.cat((data, torch.LongTensor([0]))) if r==0 else data\n",
        "\n",
        "  inputs = data[:M*seq_len]\n",
        "  inputs = inputs.reshape(-1, seq_len)\n",
        "\n",
        "  targets = data[1:M*seq_len+1]\n",
        "  targets = targets.reshape(-1, seq_len)\n",
        "\n",
        "  return inputs, targets"
      ],
      "metadata": {
        "id": "SzNNcm12YBHJ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs, targets = data_process(train_iter, seq_len=65)\n",
        "inputs.shape, targets.shape"
      ],
      "metadata": {
        "id": "OdFAEKcwY0Fy",
        "outputId": "959db2f0-d714-4a15-adb6-37dad4d7346d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32103, 65]), torch.Size([32103, 65]))"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len = 35\n",
        "\n",
        "X_train, y_train = data_process(train_iter, seq_len)\n",
        "X_valid, y_valid = data_process(valid_iter, seq_len)\n",
        "X_test, y_test = data_process(test_iter, seq_len)\n",
        "\n",
        "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape, X_test.shape, y_test.shape"
      ],
      "metadata": {
        "id": "RUgan896Y_CK",
        "outputId": "f923cbc1-4575-480c-d35d-93805c8e4f72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([59620, 35]),\n",
              " torch.Size([59620, 35]),\n",
              " torch.Size([6233, 35]),\n",
              " torch.Size([6233, 35]),\n",
              " torch.Size([7034, 35]),\n",
              " torch.Size([7034, 35]))"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Custom Dataset Class Definition\n",
        "  - (Map custom dataset used instead of iterable custom dataset because of small dataset length)"
      ],
      "metadata": {
        "id": "dPwnMNzRaBkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LanguageModelDataset(Dataset):\n",
        "\n",
        "  def __init__(self, inputs, targets):\n",
        "    self.inputs = inputs\n",
        "    self.targets = targets\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.inputs.shape[0]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.inputs[idx], self.targets[idx]"
      ],
      "metadata": {
        "id": "QzxqLeZ8aFcy"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = LanguageModelDataset(X_train, y_train)\n",
        "valid_set = LanguageModelDataset(X_valid, y_valid)\n",
        "test_set = LanguageModelDataset(X_test, y_test)"
      ],
      "metadata": {
        "id": "g7v1XHmqaIMX"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set[0]"
      ],
      "metadata": {
        "id": "NzWyetF0aMmB",
        "outputId": "de8bf9e7-581f-492a-9271-59452b978bb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([28782,     9,  3849,  3869,   881,     9, 28782, 28782, 20000,    83,\n",
              "          3849,    88,     0,  3869,    21,   780, 28780,     2,  6182,     3,\n",
              "          3849,     4,     1,  5023,    88,    20,     2,  1837,  1018,     7,\n",
              "            14,  3849,  3869,   881,   629]),\n",
              " tensor([    9,  3849,  3869,   881,     9, 28782, 28782, 20000,    83,  3849,\n",
              "            88,     0,  3869,    21,   780, 28780,     2,  6182,     3,  3849,\n",
              "             4,     1,  5023,    88,    20,     2,  1837,  1018,     7,    14,\n",
              "          3849,  3869,   881,   629,   976]))"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Data Loader"
      ],
      "metadata": {
        "id": "lVZr9EC2a9Q-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 20\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "jx0jsfNna7jw"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_batch, y_batch = next(iter(train_loader))\n",
        "x_batch.shape, y_batch.shape"
      ],
      "metadata": {
        "id": "UjsIn1HhbFbA",
        "outputId": "9601b66f-a441-463e-d996-2caac3d12191",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([20, 35]), torch.Size([20, 35]))"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "xket0SftlL2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LanguageModel(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers,\n",
        "                dropout_embd=0.5, dropout_rnn=0.5):\n",
        "    super().__init__()\n",
        "    self.num_layers = num_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.embedding_dim = embedding_dim\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.embedding.weight.data.uniform_(-0.1, 0.1)\n",
        "    self.dropout = nn.Dropout(p=dropout_embd)\n",
        "\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers,\n",
        "                        dropout=dropout_rnn, batch_first=True)\n",
        "\n",
        "    self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "  def forward(self, src):\n",
        "    embedding = self.dropout(self.embedding(src))\n",
        "    output, hidden = self.lstm(embedding)\n",
        "    prediction = self.fc(output)\n",
        "    return prediction"
      ],
      "metadata": {
        "id": "FztWG0volNI9"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LanguageModel(vocab_size=len(vocab),\n",
        "                      embedding_dim=300,\n",
        "                      hidden_dim=512,\n",
        "                      num_layers=2,\n",
        "                      dropout_embd=0.65,\n",
        "                      dropout_rnn=0.5)\n",
        "model"
      ],
      "metadata": {
        "id": "vJ7WkV4ylPQd",
        "outputId": "f2615906-090f-43bf-9164-ab659e39ff97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageModel(\n",
              "  (embedding): Embedding(28783, 300)\n",
              "  (dropout): Dropout(p=0.65, inplace=False)\n",
              "  (lstm): LSTM(300, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (fc): Linear(in_features=512, out_features=28783, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab), x_batch.shape, model(x_batch).shape"
      ],
      "metadata": {
        "id": "0ULB8-yDnBh2",
        "outputId": "83936b2f-0d36-4c27-c51a-58594b84bd2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28783, torch.Size([20, 35]), torch.Size([20, 35, 28783]))"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_trainable_params(model.embedding), num_trainable_params(model.lstm), num_trainable_params(model.fc)"
      ],
      "metadata": {
        "id": "kUkCVcJB_3GY",
        "outputId": "06713e88-5823-43db-c673-ebf4788d4854",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.6349, 3.76832, 14.765679)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuration"
      ],
      "metadata": {
        "id": "hvFUYkaR_99_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "id": "mH-ll-a3ABzv",
        "outputId": "2e51b6f0-0916-4e2f-8239-bd25c241447c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab)\n",
        "embedding_dim = 300\n",
        "hidden_dim = 512\n",
        "num_layers = 2\n",
        "dropout_embd = 0.5\n",
        "dropout_rnn = 0.2\n",
        "\n",
        "model = LanguageModel(vocab_size, embedding_dim,\n",
        "                      hidden_dim, num_layers,\n",
        "                      dropout_embd, dropout_rnn).to(device)"
      ],
      "metadata": {
        "id": "2qefqKGHAENI"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.5, weight_decay=0, momentum=0.9, nesterov=True)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "metric = tm.text.Perplexity().to(device)"
      ],
      "metadata": {
        "id": "np8qNxCeAIEu"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clip = 0.25"
      ],
      "metadata": {
        "id": "wabnifRtAKuN"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "FxxqwtuHAPSM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and Evaluate Functions"
      ],
      "metadata": {
        "id": "yCXGRHSqARgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Functions\n",
        "def train_one_epoch(model, train_loader, loss_fn, optimizer, metric, epoch=None):\n",
        "  model.train()\n",
        "  loss_train = AverageMeter()\n",
        "  metric.reset()\n",
        "\n",
        "  with tqdm.tqdm(train_loader, unit='batch') as tepoch:\n",
        "    for inputs, targets in tepoch:\n",
        "      if epoch:\n",
        "        tepoch.set_description(f'Epoch {epoch}')\n",
        "\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      loss = loss_fn(outputs.reshape(-1, outputs.shape[-1]), targets.flatten())\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      nn.utils.clip_grad.clip_grad_norm_(model.parameters(), max_norm=clip)\n",
        "\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      loss_train.update(loss.item(), n=len(targets))\n",
        "      metric.update(outputs, targets)\n",
        "\n",
        "      tepoch.set_postfix(loss=loss_train.avg, metric=metric.compute().item())\n",
        "\n",
        "  return model, loss_train.avg, metric.compute().item()"
      ],
      "metadata": {
        "id": "wsh7lCOsAUf2"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Function\n",
        "def evaluate(model, test_loader, loss_fn, metric):\n",
        "  model.eval()\n",
        "  loss_eval = AverageMeter()\n",
        "  metric.reset()\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for inputs, targets in test_loader:\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      loss = loss_fn(outputs.reshape(-1, outputs.shape[-1]), targets.flatten())\n",
        "      loss_eval.update(loss.item(), n=len(targets))\n",
        "\n",
        "      metric(outputs, targets)\n",
        "\n",
        "  return loss_eval.avg, metric.compute().item()"
      ],
      "metadata": {
        "id": "mLvO6J2_BDbl"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Process and Tunning"
      ],
      "metadata": {
        "id": "mM5EA457BS5d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding Hyper-parameters"
      ],
      "metadata": {
        "id": "rOmBi5wVCTH1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Calculating the loss for untrained model using a few batches"
      ],
      "metadata": {
        "id": "OwesNxCICjdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for iter_num in range(5):\n",
        "  model = LanguageModel(len(vocab), embedding_dim=300,\n",
        "                        hidden_dim=512, num_layers=2,\n",
        "                        dropout_embd=0.5, dropout_rnn=0.2).to(device)\n",
        "\n",
        "  inputs, targets = next(iter(train_loader))\n",
        "  inputs = inputs.to(device)\n",
        "  targets = targets.to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    outputs = model(inputs)\n",
        "    loss = loss_fn(outputs.reshape(-1, outputs.shape[-1]), targets.flatten())\n",
        "\n",
        "  print(loss)"
      ],
      "metadata": {
        "id": "NaG9OAonBg2b",
        "outputId": "ef331aae-9e6d-4476-9f13-0d8775f4a749",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.2716, device='cuda:0')\n",
            "tensor(10.2680, device='cuda:0')\n",
            "tensor(10.2713, device='cuda:0')\n",
            "tensor(10.2687, device='cuda:0')\n",
            "tensor(10.2679, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Train and try to overfit the model on a small subset of the dataset."
      ],
      "metadata": {
        "id": "g4sjp-iPClmv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LanguageModel(len(vocab), embedding_dim=300,\n",
        "                      hidden_dim=512, num_layers=2,\n",
        "                      dropout_embd=0.5, dropout_rnn=0.2).to(device)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.9, momentum=0.9)"
      ],
      "metadata": {
        "id": "VXXqI6UXCbbu"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mini_train_size = 1000\n",
        "_, mini_train_dataset = random_split(train_set, (len(train_set)-mini_train_size, mini_train_size))\n",
        "mini_train_loader = DataLoader(mini_train_dataset, 20)"
      ],
      "metadata": {
        "id": "xQ5wEy6UCtPj"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "  model, _, _ = train_one_epoch(model, mini_train_loader, loss_fn, optimizer, metric, epoch)"
      ],
      "metadata": {
        "id": "K6xKuwZgCuz0",
        "outputId": "8654e917-33da-4e4f-cc01-45912f6b8574",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:02<00:00, 23.06batch/s, loss=8.36, metric=4.27e+3]\n",
            "Epoch 1: 100%|██████████| 50/50 [00:01<00:00, 26.91batch/s, loss=7.17, metric=1.3e+3]\n",
            "Epoch 2: 100%|██████████| 50/50 [00:01<00:00, 26.77batch/s, loss=6.97, metric=1.07e+3]\n",
            "Epoch 3: 100%|██████████| 50/50 [00:01<00:00, 26.41batch/s, loss=6.84, metric=934]\n",
            "Epoch 4: 100%|██████████| 50/50 [00:01<00:00, 26.04batch/s, loss=6.71, metric=817]\n",
            "Epoch 5: 100%|██████████| 50/50 [00:01<00:00, 26.39batch/s, loss=6.58, metric=720]\n",
            "Epoch 6: 100%|██████████| 50/50 [00:01<00:00, 26.43batch/s, loss=6.47, metric=645]\n",
            "Epoch 7: 100%|██████████| 50/50 [00:01<00:00, 26.27batch/s, loss=6.37, metric=586]\n",
            "Epoch 8: 100%|██████████| 50/50 [00:01<00:00, 26.23batch/s, loss=6.28, metric=536]\n",
            "Epoch 9: 100%|██████████| 50/50 [00:01<00:00, 26.28batch/s, loss=6.2, metric=493]\n",
            "Epoch 10: 100%|██████████| 50/50 [00:01<00:00, 26.03batch/s, loss=6.12, metric=453]\n",
            "Epoch 11: 100%|██████████| 50/50 [00:01<00:00, 25.75batch/s, loss=6.04, metric=418]\n",
            "Epoch 12: 100%|██████████| 50/50 [00:01<00:00, 25.31batch/s, loss=5.95, metric=384]\n",
            "Epoch 13: 100%|██████████| 50/50 [00:01<00:00, 25.80batch/s, loss=5.88, metric=357]\n",
            "Epoch 14: 100%|██████████| 50/50 [00:01<00:00, 25.94batch/s, loss=5.79, metric=328]\n",
            "Epoch 15: 100%|██████████| 50/50 [00:01<00:00, 25.97batch/s, loss=5.71, metric=302]\n",
            "Epoch 16: 100%|██████████| 50/50 [00:01<00:00, 25.70batch/s, loss=5.63, metric=278]\n",
            "Epoch 17: 100%|██████████| 50/50 [00:01<00:00, 25.34batch/s, loss=5.55, metric=256]\n",
            "Epoch 18: 100%|██████████| 50/50 [00:02<00:00, 24.78batch/s, loss=5.49, metric=241]\n",
            "Epoch 19: 100%|██████████| 50/50 [00:02<00:00, 24.82batch/s, loss=5.4, metric=222]\n",
            "Epoch 20: 100%|██████████| 50/50 [00:01<00:00, 25.58batch/s, loss=5.29, metric=199]\n",
            "Epoch 21: 100%|██████████| 50/50 [00:01<00:00, 25.50batch/s, loss=5.19, metric=180]\n",
            "Epoch 22: 100%|██████████| 50/50 [00:01<00:00, 25.75batch/s, loss=5.09, metric=162]\n",
            "Epoch 23: 100%|██████████| 50/50 [00:01<00:00, 25.29batch/s, loss=5, metric=149]\n",
            "Epoch 24: 100%|██████████| 50/50 [00:01<00:00, 25.39batch/s, loss=4.92, metric=136]\n",
            "Epoch 25: 100%|██████████| 50/50 [00:02<00:00, 24.87batch/s, loss=4.85, metric=127]\n",
            "Epoch 26: 100%|██████████| 50/50 [00:02<00:00, 24.93batch/s, loss=4.81, metric=122]\n",
            "Epoch 27: 100%|██████████| 50/50 [00:01<00:00, 25.76batch/s, loss=4.71, metric=111]\n",
            "Epoch 28: 100%|██████████| 50/50 [00:01<00:00, 25.92batch/s, loss=4.6, metric=100]\n",
            "Epoch 29: 100%|██████████| 50/50 [00:01<00:00, 25.94batch/s, loss=4.5, metric=90.2]\n",
            "Epoch 30: 100%|██████████| 50/50 [00:01<00:00, 25.96batch/s, loss=4.39, metric=80.7]\n",
            "Epoch 31: 100%|██████████| 50/50 [00:01<00:00, 25.92batch/s, loss=4.29, metric=72.9]\n",
            "Epoch 32: 100%|██████████| 50/50 [00:01<00:00, 25.02batch/s, loss=4.19, metric=66.2]\n",
            "Epoch 33: 100%|██████████| 50/50 [00:01<00:00, 25.40batch/s, loss=4.08, metric=59.1]\n",
            "Epoch 34: 100%|██████████| 50/50 [00:01<00:00, 25.84batch/s, loss=3.99, metric=53.8]\n",
            "Epoch 35: 100%|██████████| 50/50 [00:01<00:00, 26.16batch/s, loss=3.91, metric=50.1]\n",
            "Epoch 36: 100%|██████████| 50/50 [00:01<00:00, 26.12batch/s, loss=3.84, metric=46.7]\n",
            "Epoch 37: 100%|██████████| 50/50 [00:01<00:00, 25.78batch/s, loss=3.78, metric=44]\n",
            "Epoch 38: 100%|██████████| 50/50 [00:01<00:00, 26.03batch/s, loss=3.7, metric=40.5]\n",
            "Epoch 39: 100%|██████████| 50/50 [00:01<00:00, 25.78batch/s, loss=3.6, metric=36.5]\n",
            "Epoch 40: 100%|██████████| 50/50 [00:01<00:00, 25.24batch/s, loss=3.49, metric=32.7]\n",
            "Epoch 41: 100%|██████████| 50/50 [00:01<00:00, 25.69batch/s, loss=3.36, metric=28.9]\n",
            "Epoch 42: 100%|██████████| 50/50 [00:01<00:00, 26.06batch/s, loss=3.24, metric=25.5]\n",
            "Epoch 43: 100%|██████████| 50/50 [00:01<00:00, 26.18batch/s, loss=3.12, metric=22.6]\n",
            "Epoch 44: 100%|██████████| 50/50 [00:01<00:00, 25.97batch/s, loss=3.03, metric=20.7]\n",
            "Epoch 45: 100%|██████████| 50/50 [00:01<00:00, 26.10batch/s, loss=2.93, metric=18.6]\n",
            "Epoch 46: 100%|██████████| 50/50 [00:01<00:00, 26.01batch/s, loss=2.85, metric=17.3]\n",
            "Epoch 47: 100%|██████████| 50/50 [00:01<00:00, 25.40batch/s, loss=2.76, metric=15.7]\n",
            "Epoch 48: 100%|██████████| 50/50 [00:01<00:00, 25.90batch/s, loss=2.65, metric=14.2]\n",
            "Epoch 49: 100%|██████████| 50/50 [00:01<00:00, 26.18batch/s, loss=2.57, metric=13]\n",
            "Epoch 50: 100%|██████████| 50/50 [00:01<00:00, 25.98batch/s, loss=2.48, metric=12]\n",
            "Epoch 51: 100%|██████████| 50/50 [00:01<00:00, 25.99batch/s, loss=2.41, metric=11.2]\n",
            "Epoch 52: 100%|██████████| 50/50 [00:01<00:00, 26.00batch/s, loss=2.4, metric=11]\n",
            "Epoch 53: 100%|██████████| 50/50 [00:01<00:00, 26.02batch/s, loss=2.38, metric=10.8]\n",
            "Epoch 54: 100%|██████████| 50/50 [00:01<00:00, 25.31batch/s, loss=2.28, metric=9.79]\n",
            "Epoch 55: 100%|██████████| 50/50 [00:01<00:00, 25.22batch/s, loss=2.18, metric=8.84]\n",
            "Epoch 56: 100%|██████████| 50/50 [00:01<00:00, 25.88batch/s, loss=2.07, metric=7.94]\n",
            "Epoch 57: 100%|██████████| 50/50 [00:01<00:00, 25.80batch/s, loss=2.01, metric=7.46]\n",
            "Epoch 58: 100%|██████████| 50/50 [00:01<00:00, 26.03batch/s, loss=1.94, metric=6.96]\n",
            "Epoch 59: 100%|██████████| 50/50 [00:01<00:00, 26.15batch/s, loss=1.88, metric=6.52]\n",
            "Epoch 60: 100%|██████████| 50/50 [00:01<00:00, 25.97batch/s, loss=1.8, metric=6.05]\n",
            "Epoch 61: 100%|██████████| 50/50 [00:01<00:00, 25.29batch/s, loss=1.73, metric=5.63]\n",
            "Epoch 62: 100%|██████████| 50/50 [00:01<00:00, 25.46batch/s, loss=1.67, metric=5.33]\n",
            "Epoch 63: 100%|██████████| 50/50 [00:01<00:00, 25.82batch/s, loss=1.59, metric=4.9]\n",
            "Epoch 64: 100%|██████████| 50/50 [00:01<00:00, 25.76batch/s, loss=1.54, metric=4.67]\n",
            "Epoch 65: 100%|██████████| 50/50 [00:01<00:00, 25.84batch/s, loss=1.47, metric=4.35]\n",
            "Epoch 66: 100%|██████████| 50/50 [00:01<00:00, 26.03batch/s, loss=1.4, metric=4.06]\n",
            "Epoch 67: 100%|██████████| 50/50 [00:01<00:00, 25.95batch/s, loss=1.32, metric=3.75]\n",
            "Epoch 68: 100%|██████████| 50/50 [00:01<00:00, 25.35batch/s, loss=1.26, metric=3.51]\n",
            "Epoch 69: 100%|██████████| 50/50 [00:01<00:00, 25.45batch/s, loss=1.17, metric=3.24]\n",
            "Epoch 70: 100%|██████████| 50/50 [00:01<00:00, 25.55batch/s, loss=1.1, metric=3.01]\n",
            "Epoch 71: 100%|██████████| 50/50 [00:01<00:00, 25.74batch/s, loss=1, metric=2.73]\n",
            "Epoch 72: 100%|██████████| 50/50 [00:01<00:00, 25.86batch/s, loss=0.938, metric=2.56]\n",
            "Epoch 73: 100%|██████████| 50/50 [00:01<00:00, 25.92batch/s, loss=0.87, metric=2.39]\n",
            "Epoch 74: 100%|██████████| 50/50 [00:01<00:00, 25.70batch/s, loss=0.8, metric=2.23]\n",
            "Epoch 75: 100%|██████████| 50/50 [00:01<00:00, 25.65batch/s, loss=0.747, metric=2.11]\n",
            "Epoch 76: 100%|██████████| 50/50 [00:01<00:00, 25.62batch/s, loss=0.717, metric=2.05]\n",
            "Epoch 77: 100%|██████████| 50/50 [00:01<00:00, 25.29batch/s, loss=0.665, metric=1.94]\n",
            "Epoch 78: 100%|██████████| 50/50 [00:01<00:00, 25.84batch/s, loss=0.625, metric=1.87]\n",
            "Epoch 79: 100%|██████████| 50/50 [00:01<00:00, 26.09batch/s, loss=0.601, metric=1.82]\n",
            "Epoch 80: 100%|██████████| 50/50 [00:01<00:00, 25.79batch/s, loss=0.574, metric=1.78]\n",
            "Epoch 81: 100%|██████████| 50/50 [00:01<00:00, 25.87batch/s, loss=0.547, metric=1.73]\n",
            "Epoch 82: 100%|██████████| 50/50 [00:01<00:00, 25.69batch/s, loss=0.527, metric=1.69]\n",
            "Epoch 83: 100%|██████████| 50/50 [00:01<00:00, 25.34batch/s, loss=0.51, metric=1.66]\n",
            "Epoch 84: 100%|██████████| 50/50 [00:01<00:00, 25.01batch/s, loss=0.49, metric=1.63]\n",
            "Epoch 85: 100%|██████████| 50/50 [00:01<00:00, 26.15batch/s, loss=0.462, metric=1.59]\n",
            "Epoch 86: 100%|██████████| 50/50 [00:01<00:00, 26.04batch/s, loss=0.454, metric=1.57]\n",
            "Epoch 87: 100%|██████████| 50/50 [00:01<00:00, 26.01batch/s, loss=0.443, metric=1.56]\n",
            "Epoch 88: 100%|██████████| 50/50 [00:01<00:00, 25.96batch/s, loss=0.417, metric=1.52]\n",
            "Epoch 89: 100%|██████████| 50/50 [00:01<00:00, 26.06batch/s, loss=0.39, metric=1.48]\n",
            "Epoch 90: 100%|██████████| 50/50 [00:01<00:00, 25.73batch/s, loss=0.375, metric=1.46]\n",
            "Epoch 91: 100%|██████████| 50/50 [00:01<00:00, 25.48batch/s, loss=0.346, metric=1.41]\n",
            "Epoch 92: 100%|██████████| 50/50 [00:01<00:00, 25.81batch/s, loss=0.323, metric=1.38]\n",
            "Epoch 93: 100%|██████████| 50/50 [00:01<00:00, 25.83batch/s, loss=0.306, metric=1.36]\n",
            "Epoch 94: 100%|██████████| 50/50 [00:01<00:00, 25.77batch/s, loss=0.296, metric=1.34]\n",
            "Epoch 95: 100%|██████████| 50/50 [00:01<00:00, 25.71batch/s, loss=0.281, metric=1.32]\n",
            "Epoch 96: 100%|██████████| 50/50 [00:01<00:00, 25.76batch/s, loss=0.27, metric=1.31]\n",
            "Epoch 97: 100%|██████████| 50/50 [00:01<00:00, 25.02batch/s, loss=0.264, metric=1.3]\n",
            "Epoch 98: 100%|██████████| 50/50 [00:01<00:00, 25.36batch/s, loss=0.252, metric=1.29]\n",
            "Epoch 99: 100%|██████████| 50/50 [00:01<00:00, 25.68batch/s, loss=0.247, metric=1.28]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  Train the model for a limited number of epochs, experimenting with various learning rates to find best value"
      ],
      "metadata": {
        "id": "1rpWRYL8EKGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 1\n",
        "\n",
        "for lr in [8, 5, 2, 0.7, 0.5, 0.2]:\n",
        "  print(f'LR={lr}')\n",
        "\n",
        "  model = LanguageModel(len(vocab), embedding_dim=300,\n",
        "                      hidden_dim=512, num_layers=2,\n",
        "                      dropout_embd=0.5, dropout_rnn=0.2).to(device)\n",
        "  # model = torch.load('/content/model-ppl_147.pt')\n",
        "\n",
        "  # optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=0, momentum=0.9)\n",
        "  optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=1e-6, momentum=0.9)\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    model, _, _ = train_one_epoch(model, train_loader, loss_fn, optimizer, metric, epoch)\n",
        "\n",
        "  print()"
      ],
      "metadata": {
        "id": "rRw-nmIRD5a0",
        "outputId": "268319e2-0603-4351-f8bc-12d63386b53b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR=8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2981/2981 [01:56<00:00, 25.67batch/s, loss=5.75, metric=314]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LR=5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2981/2981 [01:59<00:00, 24.88batch/s, loss=5.75, metric=315]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LR=2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 2614/2981 [01:42<00:14, 25.45batch/s, loss=5.95, metric=382]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-57a541a2b1a6>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-59-870050b25dc7>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_loader, loss_fn, optimizer, metric, epoch)\u001b[0m\n\u001b[1;32m     27\u001b[0m       \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m       \u001b[0mtepoch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mset_postfix\u001b[0;34m(self, ordered_dict, refresh, **kwargs)\u001b[0m\n\u001b[1;32m   1429\u001b[0m                                  for key in postfix.keys())\n\u001b[1;32m   1430\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrefresh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_postfix_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mrefresh\u001b[0;34m(self, nolock, lock_args)\u001b[0m\n\u001b[1;32m   1345\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1348\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnolock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(self, msg, pos)\u001b[0m\n\u001b[1;32m   1493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1495\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mprint_status\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mprint_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0mlen_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisp_len\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m             \u001b[0mfp_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\r'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_len\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m             \u001b[0mlast_len\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen_s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mfp_write\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfp_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m             \u001b[0mfp_flush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/utils.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;31m# mp.Pool cannot be trusted to flush promptly (or ever),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    618\u001b[0m                 )\n\u001b[1;32m    619\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     def send_multipart(\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Creat a small grid search to find exact value of lr and weight decay"
      ],
      "metadata": {
        "id": "Fc4ggzJrETOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 2\n",
        "\n",
        "for lr in [8.]:\n",
        "  for wd in [1e-6, 1e-5, 1e-4]:\n",
        "    print(f'LR={lr}, WD={wd}')\n",
        "\n",
        "    model = LanguageModel(len(vocab), embedding_dim=300,\n",
        "                      hidden_dim=512, num_layers=2,\n",
        "                      dropout_embd=0.5, dropout_rnn=0.2).to(device)\n",
        "\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=0.9)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      model, _, _ = train_one_epoch(model, train_loader, loss_fn, optimizer, metric, epoch)\n",
        "\n",
        "    print()"
      ],
      "metadata": {
        "id": "g-TuGszbEPtW",
        "outputId": "5eba232a-9671-423a-d23a-d6f04bfd2071",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR=8.0, WD=1e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2981/2981 [01:57<00:00, 25.40batch/s, loss=5.76, metric=316]\n",
            "Epoch 1: 100%|██████████| 2981/2981 [02:00<00:00, 24.67batch/s, loss=5.34, metric=209]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LR=8.0, WD=1e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2981/2981 [01:54<00:00, 25.98batch/s, loss=5.83, metric=339]\n",
            "Epoch 1: 100%|██████████| 2981/2981 [01:59<00:00, 24.98batch/s, loss=5.48, metric=239]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LR=8.0, WD=0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2981/2981 [01:54<00:00, 26.14batch/s, loss=6.36, metric=576]\n",
            "Epoch 1: 100%|██████████| 2981/2981 [01:58<00:00, 25.07batch/s, loss=6.27, metric=528]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Train model for more epochs using the best hyperparameters"
      ],
      "metadata": {
        "id": "LBhtQUjHEaxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LanguageModel(len(vocab), embedding_dim=300,\n",
        "                      hidden_dim=512, num_layers=2,\n",
        "                      dropout_embd=0.5, dropout_rnn=0.5).to(device)"
      ],
      "metadata": {
        "id": "wzuhcj6pEXlL"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 8\n",
        "wd = 1e-6\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=0.9)"
      ],
      "metadata": {
        "id": "jZezO_4mEftc"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_train_hist = []\n",
        "loss_valid_hist = []\n",
        "\n",
        "metric_train_hist = []\n",
        "metric_valid_hist = []\n",
        "\n",
        "best_loss_valid = torch.inf\n",
        "epoch_counter = 0\n",
        "best_loss_epoch = None"
      ],
      "metadata": {
        "id": "2MTINOHHEhb4"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "  # Train\n",
        "  model, loss_train, metric_train = train_one_epoch(model,\n",
        "                                                    train_loader,\n",
        "                                                    loss_fn,\n",
        "                                                    optimizer,\n",
        "                                                    metric,\n",
        "                                                    epoch)\n",
        "  # Validation\n",
        "  loss_valid, metric_valid = evaluate(model,\n",
        "                                      valid_loader,\n",
        "                                      loss_fn,\n",
        "                                      metric)\n",
        "\n",
        "  loss_train_hist.append(loss_train)\n",
        "  loss_valid_hist.append(loss_valid)\n",
        "\n",
        "  metric_train_hist.append(metric_train)\n",
        "  metric_valid_hist.append(metric_valid)\n",
        "\n",
        "  if loss_valid < best_loss_valid:\n",
        "    torch.save(model, f'modelpt')\n",
        "    best_loss_valid = loss_valid\n",
        "    best_loss_epoch = epoch\n",
        "    print('Model Saved!')\n",
        "\n",
        "  print(f'Valid: Loss = {loss_valid:.4}, Metric = {metric_valid:.4}')\n",
        "  print()\n",
        "\n",
        "  epoch_counter += 1"
      ],
      "metadata": {
        "id": "cnZeh15xEkcl",
        "outputId": "ff161f20-f0f7-4ad6-8b66-2c30e2fd2de0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 2981/2981 [01:59<00:00, 24.99batch/s, loss=5.84, metric=345]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 5.394, Metric = 220.1\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 2981/2981 [01:59<00:00, 24.92batch/s, loss=5.51, metric=248]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 5.297, Metric = 199.7\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 2981/2981 [01:59<00:00, 24.99batch/s, loss=5.39, metric=220]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 5.253, Metric = 191.2\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 2981/2981 [01:59<00:00, 25.05batch/s, loss=5.3, metric=201]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 5.218, Metric = 184.5\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 2981/2981 [02:00<00:00, 24.83batch/s, loss=5.23, metric=188]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 5.222, Metric = 185.3\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 2981/2981 [02:00<00:00, 24.73batch/s, loss=5.18, metric=177]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 5.162, Metric = 174.4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 2981/2981 [02:00<00:00, 24.83batch/s, loss=5.13, metric=169]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 5.159, Metric = 174.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 2981/2981 [01:59<00:00, 24.88batch/s, loss=5.09, metric=162]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 5.164, Metric = 174.9\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 2981/2981 [01:59<00:00, 24.96batch/s, loss=5.05, metric=157]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 5.165, Metric = 175.1\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 2981/2981 [01:59<00:00, 25.04batch/s, loss=5.02, metric=152]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 5.198, Metric = 180.9\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| 2981/2981 [01:59<00:00, 25.03batch/s, loss=5, metric=148]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 5.154, Metric = 173.1\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12:  77%|███████▋  | 2288/2981 [01:31<00:27, 24.99batch/s, loss=4.95, metric=141]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-2e13ec4bfef0>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   model, loss_train, metric_train = train_one_epoch(model,\n\u001b[0m\u001b[1;32m      6\u001b[0m                                                     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                                     \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-59-870050b25dc7>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_loader, loss_fn, optimizer, metric, epoch)\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m       \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouped_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforeach\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mforeach\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_has_foreach_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_mul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_coef_clamped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-overload]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mforeach\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'foreach=True was passed, but can\\'t use the foreach API on {device.type} tensors'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main Train Loop"
      ],
      "metadata": {
        "id": "e0dMrsH6E_Qq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('/content/model-174.pt')\n",
        "torch.save(model, f'model.pt')\n",
        "shutil.copyfile(\"model-174.pt\", \"/content/drive/MyDrive/LanguageModel/model-174.pt\")"
      ],
      "metadata": {
        "id": "lrxajJVlFAtt"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.copyfile(\"model-145.pt\", \"/content/drive/MyDrive/LanguageModel/model-145.pt\")"
      ],
      "metadata": {
        "id": "RQlBQwWYWhwx",
        "outputId": "e93e3334-a0a4-4a77-b561-a186219182df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/LanguageModel/model-145.pt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 3\n",
        "wd = 1e-6\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=0.9)"
      ],
      "metadata": {
        "id": "OuK52y5bFCNi"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_train_hist = []\n",
        "loss_valid_hist = []\n",
        "\n",
        "metric_train_hist = []\n",
        "metric_valid_hist = []\n",
        "\n",
        "best_loss_valid = torch.inf\n",
        "epoch_counter = 0"
      ],
      "metadata": {
        "id": "QczG3kJzFDnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  # Train\n",
        "  model, loss_train, metric_train = train_one_epoch(model,\n",
        "                                                    train_loader,\n",
        "                                                    loss_fn,\n",
        "                                                    optimizer,\n",
        "                                                    metric,\n",
        "                                                    epoch)\n",
        "  # Validation\n",
        "  loss_valid, metric_valid = evaluate(model,\n",
        "                                      valid_loader,\n",
        "                                      loss_fn,\n",
        "                                      metric)\n",
        "\n",
        "\n",
        "  loss_train_hist.append(loss_train)\n",
        "  loss_valid_hist.append(loss_valid)\n",
        "\n",
        "  metric_train_hist.append(metric_train)\n",
        "  metric_valid_hist.append(metric_valid)\n",
        "\n",
        "  if loss_valid < best_loss_valid:\n",
        "    torch.save(model, f'model.pt')\n",
        "    best_loss_valid = loss_valid\n",
        "    best_loss_epoch = epoch\n",
        "    print('Model Saved!')\n",
        "\n",
        "  print(f'Valid: Loss = {loss_valid:.4}, Metric = {metric_valid:.4}')\n",
        "  print()\n",
        "\n",
        "  epoch_counter += 1"
      ],
      "metadata": {
        "id": "FCFiP3saFFCL",
        "outputId": "92b26d1b-bee3-4741-c137-2b091b307452",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 860
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2981/2981 [01:56<00:00, 25.60batch/s, loss=4.66, metric=106]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 5.004, Metric = 149.1\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 2981/2981 [02:00<00:00, 24.75batch/s, loss=4.59, metric=98.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 4.989, Metric = 146.8\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 2981/2981 [02:00<00:00, 24.74batch/s, loss=4.53, metric=93.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 4.978, Metric = 145.2\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 2981/2981 [02:00<00:00, 24.75batch/s, loss=4.49, metric=88.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 4.979, Metric = 145.4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 2981/2981 [01:59<00:00, 24.91batch/s, loss=4.44, metric=85.2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 4.979, Metric = 145.4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 2981/2981 [02:00<00:00, 24.82batch/s, loss=4.41, metric=82]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "Valid: Loss = 4.977, Metric = 145.1\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 2981/2981 [02:01<00:00, 24.62batch/s, loss=4.37, metric=79.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: Loss = 4.989, Metric = 146.8\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7:   3%|▎         | 87/2981 [00:03<01:57, 24.60batch/s, loss=4.22, metric=67.9]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-6fd372c8659d>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   model, loss_train, metric_train = train_one_epoch(model,\n\u001b[0m\u001b[1;32m      6\u001b[0m                                                     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                                     \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-59-870050b25dc7>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_loader, loss_fn, optimizer, metric, epoch)\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m       \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouped_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforeach\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mforeach\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_has_foreach_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_mul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_coef_clamped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-overload]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mforeach\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'foreach=True was passed, but can\\'t use the foreach API on {device.type} tensors'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot Learning Curve"
      ],
      "metadata": {
        "id": "OCU-cdlzEyQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "plt.plot(range(epoch_counter), loss_train_hist, 'r-', label='Train')\n",
        "plt.plot(range(epoch_counter), loss_valid_hist, 'b-', label='Validation')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.grid(True)\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "_JvsLg3UEzoL",
        "outputId": "3e026ad9-6675-4f2b-ea66-6264d2a90628",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x79d7df1a0bb0>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}